[
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Namespace",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "RawDescriptionHelpFormatter",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "collections.abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections.abc",
        "description": "collections.abc",
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "MutableMapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "http",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "http",
        "description": "http",
        "detail": "http",
        "documentation": {}
    },
    {
        "label": "HTTPStatus",
        "importPath": "http",
        "description": "http",
        "isExtraImport": true,
        "detail": "http",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "PurePath",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing",
        "description": "typing",
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ContextManager",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ContextManager",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "DefaultDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Deque",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeAlias",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TextIO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Final",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NoReturn",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "asyncio,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio.",
        "description": "asyncio.",
        "detail": "asyncio.",
        "documentation": {}
    },
    {
        "label": "aiohttp,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiohttp.",
        "description": "aiohttp.",
        "detail": "aiohttp.",
        "documentation": {}
    },
    {
        "label": "bound_contextvars",
        "importPath": "structlog.contextvars",
        "description": "structlog.contextvars",
        "isExtraImport": true,
        "detail": "structlog.contextvars",
        "documentation": {}
    },
    {
        "label": "bound_contextvars",
        "importPath": "structlog.contextvars",
        "description": "structlog.contextvars",
        "isExtraImport": true,
        "detail": "structlog.contextvars",
        "documentation": {}
    },
    {
        "label": "lxml.etree",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "lxml.etree",
        "description": "lxml.etree",
        "detail": "lxml.etree",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "stdout",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "exit",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "click",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "click",
        "description": "click",
        "detail": "click",
        "documentation": {}
    },
    {
        "label": "utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "utils",
        "description": "utils",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "binascii",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "binascii",
        "description": "binascii",
        "detail": "binascii",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "json",
        "description": "json",
        "isExtraImport": true,
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "dumps",
        "importPath": "json",
        "description": "json",
        "isExtraImport": true,
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "dump",
        "importPath": "json",
        "description": "json",
        "isExtraImport": true,
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "urllib.parse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "parse_qs",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "bs4",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bs4",
        "description": "bs4",
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "NavigableString",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "Tag",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jinja2",
        "description": "jinja2",
        "detail": "jinja2",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "total_ordering",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "run",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "run",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "run",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "get",
        "importPath": "requests",
        "description": "requests",
        "isExtraImport": true,
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "get",
        "importPath": "requests",
        "description": "requests",
        "isExtraImport": true,
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "PyQuery",
        "importPath": "pyquery",
        "description": "pyquery",
        "isExtraImport": true,
        "detail": "pyquery",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "urllib.error",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.error",
        "description": "urllib.error",
        "detail": "urllib.error",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "importPath": "urllib.error",
        "description": "urllib.error",
        "isExtraImport": true,
        "detail": "urllib.error",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "xml.etree.ElementTree",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xml.etree.ElementTree",
        "description": "xml.etree.ElementTree",
        "detail": "xml.etree.ElementTree",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "UTC",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.dummy",
        "description": "multiprocessing.dummy",
        "isExtraImport": true,
        "detail": "multiprocessing.dummy",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.dummy",
        "description": "multiprocessing.dummy",
        "isExtraImport": true,
        "detail": "multiprocessing.dummy",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "NamedTemporaryFile",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "NamedTemporaryFile",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "NamedTemporaryFile",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "TemporaryDirectory",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "git",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "git",
        "description": "git",
        "detail": "git",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "rmtree",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractclassmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "ExitStack",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "_GeneratorContextManager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "hashlib,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib.",
        "description": "hashlib.",
        "detail": "hashlib.",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "importPath": "test_driver.logger",
        "description": "test_driver.logger",
        "isExtraImport": true,
        "detail": "test_driver.logger",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "importPath": "test_driver.logger",
        "description": "test_driver.logger",
        "isExtraImport": true,
        "detail": "test_driver.logger",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "importPath": "test_driver.logger",
        "description": "test_driver.logger",
        "isExtraImport": true,
        "detail": "test_driver.logger",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "importPath": "test_driver.logger",
        "description": "test_driver.logger",
        "isExtraImport": true,
        "detail": "test_driver.logger",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "importPath": "test_driver.logger",
        "description": "test_driver.logger",
        "isExtraImport": true,
        "detail": "test_driver.logger",
        "documentation": {}
    },
    {
        "label": "Machine",
        "importPath": "test_driver.machine",
        "description": "test_driver.machine",
        "isExtraImport": true,
        "detail": "test_driver.machine",
        "documentation": {}
    },
    {
        "label": "NixStartScript",
        "importPath": "test_driver.machine",
        "description": "test_driver.machine",
        "isExtraImport": true,
        "detail": "test_driver.machine",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "test_driver.machine",
        "description": "test_driver.machine",
        "isExtraImport": true,
        "detail": "test_driver.machine",
        "documentation": {}
    },
    {
        "label": "Machine",
        "importPath": "test_driver.machine",
        "description": "test_driver.machine",
        "isExtraImport": true,
        "detail": "test_driver.machine",
        "documentation": {}
    },
    {
        "label": "PollingCondition",
        "importPath": "test_driver.polling_condition",
        "description": "test_driver.polling_condition",
        "isExtraImport": true,
        "detail": "test_driver.polling_condition",
        "documentation": {}
    },
    {
        "label": "VLan",
        "importPath": "test_driver.vlan",
        "description": "test_driver.vlan",
        "isExtraImport": true,
        "detail": "test_driver.vlan",
        "documentation": {}
    },
    {
        "label": "VLan",
        "importPath": "test_driver.vlan",
        "description": "test_driver.vlan",
        "isExtraImport": true,
        "detail": "test_driver.vlan",
        "documentation": {}
    },
    {
        "label": "atexit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "atexit",
        "description": "atexit",
        "detail": "atexit",
        "documentation": {}
    },
    {
        "label": "codecs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "codecs",
        "description": "codecs",
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "iterdecode",
        "importPath": "codecs",
        "description": "codecs",
        "isExtraImport": true,
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "iterdecode",
        "importPath": "codecs",
        "description": "codecs",
        "isExtraImport": true,
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "iterdecode",
        "importPath": "codecs",
        "description": "codecs",
        "isExtraImport": true,
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "queue",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "queue",
        "description": "queue",
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Empty",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "xml.sax.saxutils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xml.sax.saxutils",
        "description": "xml.sax.saxutils",
        "detail": "xml.sax.saxutils",
        "documentation": {}
    },
    {
        "label": "XMLGenerator",
        "importPath": "xml.sax.saxutils",
        "description": "xml.sax.saxutils",
        "isExtraImport": true,
        "detail": "xml.sax.saxutils",
        "documentation": {}
    },
    {
        "label": "AttributesImpl",
        "importPath": "xml.sax.xmlreader",
        "description": "xml.sax.xmlreader",
        "isExtraImport": true,
        "detail": "xml.sax.xmlreader",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "junit_xml",
        "description": "junit_xml",
        "isExtraImport": true,
        "detail": "junit_xml",
        "documentation": {}
    },
    {
        "label": "TestSuite",
        "importPath": "junit_xml",
        "description": "junit_xml",
        "isExtraImport": true,
        "detail": "junit_xml",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "select",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "select",
        "description": "select",
        "detail": "select",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "isfinite",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pty",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pty",
        "description": "pty",
        "detail": "pty",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "Driver",
        "importPath": "test_driver.driver",
        "description": "test_driver.driver",
        "isExtraImport": true,
        "detail": "test_driver.driver",
        "documentation": {}
    },
    {
        "label": "Protocol",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "grp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "grp",
        "description": "grp",
        "detail": "grp",
        "documentation": {}
    },
    {
        "label": "pwd",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pwd",
        "description": "pwd",
        "detail": "pwd",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "gi,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gi.",
        "description": "gi.",
        "detail": "gi.",
        "documentation": {}
    },
    {
        "label": "AccountsService",
        "importPath": "gi.repository",
        "description": "gi.repository",
        "isExtraImport": true,
        "detail": "gi.repository",
        "documentation": {}
    },
    {
        "label": "GLib",
        "importPath": "gi.repository",
        "description": "gi.repository",
        "isExtraImport": true,
        "detail": "gi.repository",
        "documentation": {}
    },
    {
        "label": "OrderedSet",
        "importPath": "ordered_set",
        "description": "ordered_set",
        "isExtraImport": true,
        "detail": "ordered_set",
        "documentation": {}
    },
    {
        "label": "ctypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ctypes",
        "description": "ctypes",
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "errno",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "errno",
        "description": "errno",
        "detail": "errno",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "splitext",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "splitext",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "normpath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "normpath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "basename",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "normpath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "sha1",
        "importPath": "hashlib",
        "description": "hashlib",
        "isExtraImport": true,
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "BaseHTTPRequestHandler",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "HTTPServer",
        "importPath": "http.server",
        "description": "http.server",
        "isExtraImport": true,
        "detail": "http.server",
        "documentation": {}
    },
    {
        "label": "Row",
        "importPath": "pyspark.sql",
        "description": "pyspark.sql",
        "isExtraImport": true,
        "detail": "pyspark.sql",
        "documentation": {}
    },
    {
        "label": "SparkSession",
        "importPath": "pyspark.sql",
        "description": "pyspark.sql",
        "isExtraImport": true,
        "detail": "pyspark.sql",
        "documentation": {}
    },
    {
        "label": "functions",
        "importPath": "pyspark.sql",
        "description": "pyspark.sql",
        "isExtraImport": true,
        "detail": "pyspark.sql",
        "documentation": {}
    },
    {
        "label": "udf",
        "importPath": "pyspark.sql.functions",
        "description": "pyspark.sql.functions",
        "isExtraImport": true,
        "detail": "pyspark.sql.functions",
        "documentation": {}
    },
    {
        "label": "explode",
        "importPath": "pyspark.sql.functions",
        "description": "pyspark.sql.functions",
        "isExtraImport": true,
        "detail": "pyspark.sql.functions",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pyspark.sql.types",
        "description": "pyspark.sql.types",
        "isExtraImport": true,
        "detail": "pyspark.sql.types",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "TextWrapper",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "xmltodict",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xmltodict",
        "description": "xmltodict",
        "detail": "xmltodict",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "xmltodict",
        "description": "xmltodict",
        "isExtraImport": true,
        "detail": "xmltodict",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "packaging",
        "description": "packaging",
        "isExtraImport": true,
        "detail": "packaging",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "packaging",
        "description": "packaging",
        "isExtraImport": true,
        "detail": "packaging",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "packaging",
        "description": "packaging",
        "isExtraImport": true,
        "detail": "packaging",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "packaging",
        "description": "packaging",
        "isExtraImport": true,
        "detail": "packaging",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "packaging",
        "description": "packaging",
        "isExtraImport": true,
        "detail": "packaging",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "pluginupdate",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pluginupdate",
        "description": "pluginupdate",
        "detail": "pluginupdate",
        "documentation": {}
    },
    {
        "label": "run_nix_expr",
        "importPath": "pluginupdate",
        "description": "pluginupdate",
        "isExtraImport": true,
        "detail": "pluginupdate",
        "documentation": {}
    },
    {
        "label": "PluginDesc",
        "importPath": "pluginupdate",
        "description": "pluginupdate",
        "isExtraImport": true,
        "detail": "pluginupdate",
        "documentation": {}
    },
    {
        "label": "update_plugins",
        "importPath": "pluginupdate",
        "description": "pluginupdate",
        "isExtraImport": true,
        "detail": "pluginupdate",
        "documentation": {}
    },
    {
        "label": "FetchConfig",
        "importPath": "pluginupdate",
        "description": "pluginupdate",
        "isExtraImport": true,
        "detail": "pluginupdate",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "treesitter",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "treesitter",
        "description": "treesitter",
        "detail": "treesitter",
        "documentation": {}
    },
    {
        "label": "bpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bpy",
        "description": "bpy",
        "detail": "bpy",
        "documentation": {}
    },
    {
        "label": "feedparser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "feedparser",
        "description": "feedparser",
        "detail": "feedparser",
        "documentation": {}
    },
    {
        "label": "LooseVersion",
        "importPath": "distutils.version",
        "description": "distutils.version",
        "isExtraImport": true,
        "detail": "distutils.version",
        "documentation": {}
    },
    {
        "label": "urllib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib",
        "description": "urllib",
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "Packages",
        "importPath": "debian.deb822",
        "description": "debian.deb822",
        "isExtraImport": true,
        "detail": "debian.deb822",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "debian.debian_support",
        "description": "debian.debian_support",
        "isExtraImport": true,
        "detail": "debian.debian_support",
        "documentation": {}
    },
    {
        "label": "collections,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections.",
        "description": "collections.",
        "detail": "collections.",
        "documentation": {}
    },
    {
        "label": "click_log",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "click_log",
        "description": "click_log",
        "detail": "click_log",
        "documentation": {}
    },
    {
        "label": "packaging.version",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "packaging.version",
        "description": "packaging.version",
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "InvalidVersion",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "InvalidVersion",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "unpack",
        "importPath": "struct",
        "description": "struct",
        "isExtraImport": true,
        "detail": "struct",
        "documentation": {}
    },
    {
        "label": "pack",
        "importPath": "struct",
        "description": "struct",
        "isExtraImport": true,
        "detail": "struct",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "ZipFile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "netrc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "netrc",
        "description": "netrc",
        "detail": "netrc",
        "documentation": {}
    },
    {
        "label": "ssl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ssl",
        "description": "ssl",
        "detail": "ssl",
        "documentation": {}
    },
    {
        "label": "HTMLParser",
        "importPath": "html.parser",
        "description": "html.parser",
        "isExtraImport": true,
        "detail": "html.parser",
        "documentation": {}
    },
    {
        "label": "HTMLParser",
        "importPath": "html.parser",
        "description": "html.parser",
        "isExtraImport": true,
        "detail": "html.parser",
        "documentation": {}
    },
    {
        "label": "HTMLParser",
        "importPath": "html.parser",
        "description": "html.parser",
        "isExtraImport": true,
        "detail": "html.parser",
        "documentation": {}
    },
    {
        "label": "HTMLParser",
        "importPath": "html.parser",
        "description": "html.parser",
        "isExtraImport": true,
        "detail": "html.parser",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "toml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "toml",
        "description": "toml",
        "detail": "toml",
        "documentation": {}
    },
    {
        "label": "tomli",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tomli",
        "description": "tomli",
        "detail": "tomli",
        "documentation": {}
    },
    {
        "label": "tomli_w",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tomli_w",
        "description": "tomli_w",
        "detail": "tomli_w",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "importPath": "fnmatch",
        "description": "fnmatch",
        "isExtraImport": true,
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "ELFError",
        "importPath": "elftools.common.exceptions",
        "description": "elftools.common.exceptions",
        "isExtraImport": true,
        "detail": "elftools.common.exceptions",
        "documentation": {}
    },
    {
        "label": "DynamicSection",
        "importPath": "elftools.elf.dynamic",
        "description": "elftools.elf.dynamic",
        "isExtraImport": true,
        "detail": "elftools.elf.dynamic",
        "documentation": {}
    },
    {
        "label": "ELFFile",
        "importPath": "elftools.elf.elffile",
        "description": "elftools.elf.elffile",
        "isExtraImport": true,
        "detail": "elftools.elf.elffile",
        "documentation": {}
    },
    {
        "label": "ENUM_E_TYPE",
        "importPath": "elftools.elf.enums",
        "description": "elftools.elf.enums",
        "isExtraImport": true,
        "detail": "elftools.elf.enums",
        "documentation": {}
    },
    {
        "label": "ENUM_EI_OSABI",
        "importPath": "elftools.elf.enums",
        "description": "elftools.elf.enums",
        "isExtraImport": true,
        "detail": "elftools.elf.enums",
        "documentation": {}
    },
    {
        "label": "waybackpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "waybackpy",
        "description": "waybackpy",
        "detail": "waybackpy",
        "documentation": {}
    },
    {
        "label": "backgroundremover.utilities",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "backgroundremover.utilities",
        "description": "backgroundremover.utilities",
        "detail": "backgroundremover.utilities",
        "documentation": {}
    },
    {
        "label": "bg",
        "importPath": "backgroundremover",
        "description": "backgroundremover",
        "isExtraImport": true,
        "detail": "backgroundremover",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "libversion",
        "description": "libversion",
        "isExtraImport": true,
        "detail": "libversion",
        "documentation": {}
    },
    {
        "label": "OptionParser",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "fileinput",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fileinput",
        "description": "fileinput",
        "detail": "fileinput",
        "documentation": {}
    },
    {
        "label": "importlib.metadata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib.metadata",
        "description": "importlib.metadata",
        "detail": "importlib.metadata",
        "documentation": {}
    },
    {
        "label": "PathDistribution",
        "importPath": "importlib.metadata",
        "description": "importlib.metadata",
        "isExtraImport": true,
        "detail": "importlib.metadata",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "Metadata",
        "importPath": "packaging.metadata",
        "description": "packaging.metadata",
        "isExtraImport": true,
        "detail": "packaging.metadata",
        "documentation": {}
    },
    {
        "label": "parse_email",
        "importPath": "packaging.metadata",
        "description": "packaging.metadata",
        "isExtraImport": true,
        "detail": "packaging.metadata",
        "documentation": {}
    },
    {
        "label": "Requirement",
        "importPath": "packaging.requirements",
        "description": "packaging.requirements",
        "isExtraImport": true,
        "detail": "packaging.requirements",
        "documentation": {}
    },
    {
        "label": "Requirement",
        "importPath": "packaging.requirements",
        "description": "packaging.requirements",
        "isExtraImport": true,
        "detail": "packaging.requirements",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "setuptools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "setuptools",
        "description": "setuptools",
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "SpecifierSet",
        "importPath": "packaging.specifiers",
        "description": "packaging.specifiers",
        "isExtraImport": true,
        "detail": "packaging.specifiers",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tokenize",
        "description": "tokenize",
        "detail": "tokenize",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "dag",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dag",
        "description": "dag",
        "detail": "dag",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "util",
        "description": "util",
        "detail": "util",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "bpycv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bpycv",
        "description": "bpycv",
        "detail": "bpycv",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "pytest_runtest_makereport",
        "importPath": "_pytest.runner",
        "description": "_pytest.runner",
        "isExtraImport": true,
        "detail": "_pytest.runner",
        "documentation": {}
    },
    {
        "label": "urllib3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib3",
        "description": "urllib3",
        "detail": "urllib3",
        "documentation": {}
    },
    {
        "label": "websockets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "websockets",
        "description": "websockets",
        "detail": "websockets",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "WatermarkDecoder",
        "importPath": "imwatermark",
        "description": "imwatermark",
        "isExtraImport": true,
        "detail": "imwatermark",
        "documentation": {}
    },
    {
        "label": "WatermarkEncoder",
        "importPath": "imwatermark",
        "description": "imwatermark",
        "isExtraImport": true,
        "detail": "imwatermark",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "distutils.core",
        "description": "distutils.core",
        "isExtraImport": true,
        "detail": "distutils.core",
        "documentation": {}
    },
    {
        "label": "Parallel",
        "importPath": "joblib",
        "description": "joblib",
        "isExtraImport": true,
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "delayed",
        "importPath": "joblib",
        "description": "joblib",
        "isExtraImport": true,
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "Memory",
        "importPath": "joblib",
        "description": "joblib",
        "isExtraImport": true,
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "gclient_eval",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gclient_eval",
        "description": "gclient_eval",
        "detail": "gclient_eval",
        "documentation": {}
    },
    {
        "label": "gclient_utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gclient_utils",
        "description": "gclient_utils",
        "detail": "gclient_utils",
        "documentation": {}
    },
    {
        "label": "DataClassJsonMixin",
        "importPath": "dataclasses_json",
        "description": "dataclasses_json",
        "isExtraImport": true,
        "detail": "dataclasses_json",
        "documentation": {}
    },
    {
        "label": "LetterCase",
        "importPath": "dataclasses_json",
        "description": "dataclasses_json",
        "isExtraImport": true,
        "detail": "dataclasses_json",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "dataclasses_json",
        "description": "dataclasses_json",
        "isExtraImport": true,
        "detail": "dataclasses_json",
        "documentation": {}
    },
    {
        "label": "fields",
        "importPath": "marshmallow",
        "description": "marshmallow",
        "isExtraImport": true,
        "detail": "marshmallow",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "FedoraPathNamespace",
        "importPath": "ipaplatform.fedora.paths",
        "description": "ipaplatform.fedora.paths",
        "isExtraImport": true,
        "detail": "ipaplatform.fedora.paths",
        "documentation": {}
    },
    {
        "label": "Github",
        "importPath": "github",
        "description": "github",
        "isExtraImport": true,
        "detail": "github",
        "documentation": {}
    },
    {
        "label": "GitRelease",
        "importPath": "github.GitRelease",
        "description": "github.GitRelease",
        "isExtraImport": true,
        "detail": "github.GitRelease",
        "documentation": {}
    },
    {
        "label": "re,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re.",
        "description": "re.",
        "detail": "re.",
        "documentation": {}
    },
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "xml.sax",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xml.sax",
        "description": "xml.sax",
        "detail": "xml.sax",
        "documentation": {}
    },
    {
        "label": "importlib_metadata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib_metadata",
        "description": "importlib_metadata",
        "detail": "importlib_metadata",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "Table",
        "importPath": "rich.table",
        "description": "rich.table",
        "isExtraImport": true,
        "detail": "rich.table",
        "documentation": {}
    },
    {
        "label": "aiohttp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiohttp",
        "description": "aiohttp",
        "detail": "aiohttp",
        "documentation": {}
    },
    {
        "label": "ClientSession",
        "importPath": "aiohttp",
        "description": "aiohttp",
        "isExtraImport": true,
        "detail": "aiohttp",
        "documentation": {}
    },
    {
        "label": "stat",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "stat",
        "description": "stat",
        "detail": "stat",
        "documentation": {}
    },
    {
        "label": "semver",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "semver",
        "description": "semver",
        "detail": "semver",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "xkeysnail.transform",
        "description": "xkeysnail.transform",
        "isExtraImport": true,
        "detail": "xkeysnail.transform",
        "documentation": {}
    },
    {
        "label": "html",
        "importPath": "lxml",
        "description": "lxml",
        "isExtraImport": true,
        "detail": "lxml",
        "documentation": {}
    },
    {
        "label": "fetch_sources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fetch_sources",
        "description": "fetch_sources",
        "detail": "fetch_sources",
        "documentation": {}
    },
    {
        "label": "ruamel.yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ruamel.yaml",
        "description": "ruamel.yaml",
        "detail": "ruamel.yaml",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "markdown_it.token",
        "description": "markdown_it.token",
        "isExtraImport": true,
        "detail": "markdown_it.token",
        "documentation": {}
    },
    {
        "label": "html",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "html",
        "description": "html",
        "detail": "html",
        "documentation": {}
    },
    {
        "label": "escape",
        "importPath": "html",
        "description": "html",
        "isExtraImport": true,
        "detail": "html",
        "documentation": {}
    },
    {
        "label": "markdown_it",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "markdown_it",
        "description": "markdown_it",
        "detail": "markdown_it",
        "documentation": {}
    },
    {
        "label": "OptionsDict",
        "importPath": "markdown_it.utils",
        "description": "markdown_it.utils",
        "isExtraImport": true,
        "detail": "markdown_it.utils",
        "documentation": {}
    },
    {
        "label": "container_plugin",
        "importPath": "mdit_py_plugins.container",
        "description": "mdit_py_plugins.container",
        "isExtraImport": true,
        "detail": "mdit_py_plugins.container",
        "documentation": {}
    },
    {
        "label": "deflist_plugin",
        "importPath": "mdit_py_plugins.deflist",
        "description": "mdit_py_plugins.deflist",
        "isExtraImport": true,
        "detail": "mdit_py_plugins.deflist",
        "documentation": {}
    },
    {
        "label": "footnote_plugin",
        "importPath": "mdit_py_plugins.footnote",
        "description": "mdit_py_plugins.footnote",
        "isExtraImport": true,
        "detail": "mdit_py_plugins.footnote",
        "documentation": {}
    },
    {
        "label": "myst_role_plugin",
        "importPath": "mdit_py_plugins.myst_role",
        "description": "mdit_py_plugins.myst_role",
        "isExtraImport": true,
        "detail": "mdit_py_plugins.myst_role",
        "documentation": {}
    },
    {
        "label": "nixos_render_docs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nixos_render_docs",
        "description": "nixos_render_docs",
        "detail": "nixos_render_docs",
        "documentation": {}
    },
    {
        "label": "sample1",
        "importPath": "sample_md",
        "description": "sample_md",
        "isExtraImport": true,
        "detail": "sample_md",
        "documentation": {}
    },
    {
        "label": "sample1",
        "importPath": "sample_md",
        "description": "sample_md",
        "isExtraImport": true,
        "detail": "sample_md",
        "documentation": {}
    },
    {
        "label": "sample1",
        "importPath": "sample_md",
        "description": "sample_md",
        "isExtraImport": true,
        "detail": "sample_md",
        "documentation": {}
    },
    {
        "label": "sample1",
        "importPath": "sample_md",
        "description": "sample_md",
        "isExtraImport": true,
        "detail": "sample_md",
        "documentation": {}
    },
    {
        "label": "HTMLConverter",
        "importPath": "nixos_render_docs.manual",
        "description": "nixos_render_docs.manual",
        "isExtraImport": true,
        "detail": "nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "HTMLParameters",
        "importPath": "nixos_render_docs.manual",
        "description": "nixos_render_docs.manual",
        "isExtraImport": true,
        "detail": "nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "Converter",
        "importPath": "nixos_render_docs.md",
        "description": "nixos_render_docs.md",
        "isExtraImport": true,
        "detail": "nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "tomlkit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tomlkit",
        "description": "tomlkit",
        "detail": "tomlkit",
        "documentation": {}
    },
    {
        "label": "de_core_news_sm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "de_core_news_sm",
        "description": "de_core_news_sm",
        "detail": "de_core_news_sm",
        "documentation": {}
    },
    {
        "label": "cpu_count",
        "importPath": "posix",
        "description": "posix",
        "isExtraImport": true,
        "detail": "posix",
        "documentation": {}
    },
    {
        "label": "cpu_count",
        "importPath": "posix",
        "description": "posix",
        "isExtraImport": true,
        "detail": "posix",
        "documentation": {}
    },
    {
        "label": "pynixutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pynixutil",
        "description": "pynixutil",
        "detail": "pynixutil",
        "documentation": {}
    },
    {
        "label": "SUPPORTED_EXTENSIONS",
        "importPath": "poetry.packages.utils.utils",
        "description": "poetry.packages.utils.utils",
        "isExtraImport": true,
        "detail": "poetry.packages.utils.utils",
        "documentation": {}
    },
    {
        "label": "SUPPORTED_EXTENSIONS",
        "importPath": "poetry.packages.utils.utils",
        "description": "poetry.packages.utils.utils",
        "isExtraImport": true,
        "detail": "poetry.packages.utils.utils",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "peekOfCode": "def parse_args(args: Optional[Sequence[str]] = None) -> Namespace:\n    parser = ArgumentParser(\n        prog = 'check-manpage-urls',\n        description = 'Check the validity of the manpage URLs linked in the nixpkgs manual',\n    )\n    parser.add_argument(\n        '-l', '--log-level',\n        default = os.getenv('LOG_LEVEL', 'INFO'),\n        type = lambda s: LogLevel[s],\n        choices = list(LogLevel),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "documentation": {}
    },
    {
        "label": "LogLevel",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "peekOfCode": "LogLevel = IntEnum('LogLevel', {\n    lvl: getattr(logging, lvl)\n    for lvl in ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\n})\nLogLevel.__str__ = lambda self: self.name\nEXPECTED_STATUS=frozenset((\n    HTTPStatus.OK, HTTPStatus.FOUND,\n    HTTPStatus.NOT_FOUND,\n))\nasync def check(session: aiohttp.ClientSession, manpage: str, url: str) -> HTTPStatus:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "documentation": {}
    },
    {
        "label": "LogLevel.__str__",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "peekOfCode": "LogLevel.__str__ = lambda self: self.name\nEXPECTED_STATUS=frozenset((\n    HTTPStatus.OK, HTTPStatus.FOUND,\n    HTTPStatus.NOT_FOUND,\n))\nasync def check(session: aiohttp.ClientSession, manpage: str, url: str) -> HTTPStatus:\n    with log_context(manpage=manpage, url=url):\n        logger.debug(\"Checking\")\n        async with session.head(url) as resp:\n            st = HTTPStatus(resp.status)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.doc.tests.manpage-urls",
        "documentation": {}
    },
    {
        "label": "replace_element_by_text",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "def replace_element_by_text(el: ET.Element, text: str) -> None:\n    \"\"\"\n    Author: bernulf\n    Source: https://stackoverflow.com/a/10520552/160386\n    SPDX-License-Identifier: CC-BY-SA-3.0\n    \"\"\"\n    text = text + (el.tail or \"\")\n    parent = el.getparent()\n    if parent is not None:\n        previous = el.getprevious()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "remove_xmlns",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "def remove_xmlns(match: re.Match) -> str:\n    \"\"\"\n    Removes xmlns attributes.\n    Expects a match containing an opening tag.\n    \"\"\"\n    return XMLNS_REGEX.sub('', match.group(0))\nif __name__ == '__main__':\n    assert len(sys.argv) >= 3, \"usage: escape-code-markup.py <input> <output>\"\n    tree = ET.parse(sys.argv[1])\n    name_predicate = \" or \".join([f\"local-name()='{el}'\" for el in code_elements])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "DOCBOOK_NS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "DOCBOOK_NS = \"http://docbook.org/ns/docbook\"\n# List of elements that pandocs DocBook reader strips markup from.\n# https://github.com/jgm/pandoc/blob/master/src/Text/Pandoc/Readers/DocBook.hs\ncode_elements = [\n    # CodeBlock\n    \"literallayout\",\n    \"screen\",\n    \"programlisting\",\n    # Code (inline)\n    \"classname\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "code_elements",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "code_elements = [\n    # CodeBlock\n    \"literallayout\",\n    \"screen\",\n    \"programlisting\",\n    # Code (inline)\n    \"classname\",\n    \"code\",\n    \"filename\",\n    \"envar\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "XMLNS_REGEX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "XMLNS_REGEX = re.compile(r'\\s+xmlns(?::[^=]+)?=\"[^\"]*\"')\nROOT_ELEMENT_REGEX = re.compile(r'^\\s*<[^>]+>')\ndef remove_xmlns(match: re.Match) -> str:\n    \"\"\"\n    Removes xmlns attributes.\n    Expects a match containing an opening tag.\n    \"\"\"\n    return XMLNS_REGEX.sub('', match.group(0))\nif __name__ == '__main__':\n    assert len(sys.argv) >= 3, \"usage: escape-code-markup.py <input> <output>\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "ROOT_ELEMENT_REGEX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "peekOfCode": "ROOT_ELEMENT_REGEX = re.compile(r'^\\s*<[^>]+>')\ndef remove_xmlns(match: re.Match) -> str:\n    \"\"\"\n    Removes xmlns attributes.\n    Expects a match containing an opening tag.\n    \"\"\"\n    return XMLNS_REGEX.sub('', match.group(0))\nif __name__ == '__main__':\n    assert len(sys.argv) >= 3, \"usage: escape-code-markup.py <input> <output>\"\n    tree = ET.parse(sys.argv[1])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.escape-code-markup",
        "documentation": {}
    },
    {
        "label": "XLINK_NS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "peekOfCode": "XLINK_NS = \"http://www.w3.org/1999/xlink\"\nns = {\n    \"db\": \"http://docbook.org/ns/docbook\",\n}\nif __name__ == '__main__':\n    assert len(sys.argv) >= 3, \"usage: replace-xrefs-by-empty-links.py <input> <output>\"\n    tree = ET.parse(sys.argv[1])\n    for xref in tree.findall(\".//db:xref\", ns):\n        text = ET.tostring(xref, encoding=str)\n        parent = xref.getparent()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "documentation": {}
    },
    {
        "label": "ns",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "peekOfCode": "ns = {\n    \"db\": \"http://docbook.org/ns/docbook\",\n}\nif __name__ == '__main__':\n    assert len(sys.argv) >= 3, \"usage: replace-xrefs-by-empty-links.py <input> <output>\"\n    tree = ET.parse(sys.argv[1])\n    for xref in tree.findall(\".//db:xref\", ns):\n        text = ET.tostring(xref, encoding=str)\n        parent = xref.getparent()\n        link = parent.makeelement('link')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.doc.replace-xrefs-by-empty-links",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-metadata",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-metadata",
        "peekOfCode": "def main(repo_metadata: pathlib.Path, nixpkgs: pathlib.Path, unstable: bool):\n    metadata = utils.KDERepoMetadata.from_repo_metadata_checkout(repo_metadata, unstable)\n    out_dir = nixpkgs / \"pkgs/kde/generated\"\n    metadata.write_json(out_dir)\nif __name__ == \"__main__\":\n    main()  # type: ignore",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-metadata",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "peekOfCode": "def main():\n    here = pathlib.Path(__file__).parent.parent.parent.parent\n    logs = (here / \"logs\").glob(\"*.log\")\n    for log in sorted(logs):\n        pname = log.stem\n        missing = []\n        is_in_block = False\n        with log.open(errors=\"replace\") as fd:\n            for line in fd:\n                line = line.strip()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "documentation": {}
    },
    {
        "label": "OK_MISSING",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "peekOfCode": "OK_MISSING = {\n    # we don't use precompiled QML\n    'Qt6QuickCompiler',\n    'Qt6QmlCompilerPlusPrivate',\n    # usually used for version numbers\n    'Git',\n    # useless by itself, will warn if something else is not found\n    'PkgConfig',\n    # license verification\n    'ReuseTool',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "documentation": {}
    },
    {
        "label": "OK_MISSING_BY_PACKAGE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "peekOfCode": "OK_MISSING_BY_PACKAGE = {\n    \"angelfish\": {\n        \"Qt6Feedback\",  # we don't have it\n    },\n    \"attica\": {\n        \"Python3\",  # only used for license checks\n    },\n    \"discover\": {\n        \"rpm-ostree-1\",  # we don't have rpm-ostree (duh)\n        \"Snapd\",  # we don't have snaps and probably never will",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.collect-missing-deps",
        "documentation": {}
    },
    {
        "label": "to_sri",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "peekOfCode": "def to_sri(hash):\n    raw = binascii.unhexlify(hash)\n    b64 = base64.b64encode(raw).decode()\n    return f\"sha256-{b64}\"\n@click.command\n@click.argument(\n    \"set\",\n    type=click.Choice([\"frameworks\", \"gear\", \"plasma\"]),\n    required=True\n)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "peekOfCode": "def main(set: str, version: str, nixpkgs: pathlib.Path, sources_url: Optional[str]):\n    root_dir = nixpkgs / \"pkgs/kde\"\n    set_dir = root_dir / set\n    generated_dir = root_dir / \"generated\"\n    metadata = utils.KDERepoMetadata.from_json(generated_dir)\n    if sources_url is None:\n        set_url = {\n            \"frameworks\": \"kf\",\n            \"gear\": \"releases\",\n            \"plasma\": \"plasma\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "documentation": {}
    },
    {
        "label": "LEAF_TEMPLATE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "peekOfCode": "LEAF_TEMPLATE = jinja2.Template('''\n{mkKdeDerivation}:\nmkKdeDerivation {\n  pname = \"{{ pname }}\";\n}\n'''.strip())\nROOT_TEMPLATE = jinja2.Template('''\n{callPackage}: {\n  {%- for p in packages %}\n  {{ p }} = callPackage ./{{ p }} {};",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "documentation": {}
    },
    {
        "label": "ROOT_TEMPLATE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "peekOfCode": "ROOT_TEMPLATE = jinja2.Template('''\n{callPackage}: {\n  {%- for p in packages %}\n  {{ p }} = callPackage ./{{ p }} {};\n  {%- endfor %}\n}\n'''.strip());\ndef to_sri(hash):\n    raw = binascii.unhexlify(hash)\n    b64 = base64.b64encode(raw).decode()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.generate-sources",
        "documentation": {}
    },
    {
        "label": "DataclassEncoder",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "class DataclassEncoder(json.JSONEncoder):\n    def default(self, it):\n        if dataclasses.is_dataclass(it):\n            return dataclasses.asdict(it)\n        return super().default(it)\n@dataclasses.dataclass\nclass Project:\n    name: str\n    description: str | None\n    project_path: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "Project",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "class Project:\n    name: str\n    description: str | None\n    project_path: str\n    repo_path: str | None\n    def __hash__(self) -> int:\n        return hash(self.name)\n    @classmethod\n    def from_yaml(cls, path: pathlib.Path):\n        data = yaml.safe_load(path.open())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "KDERepoMetadata",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "class KDERepoMetadata:\n    version: str\n    projects: list[Project]\n    dep_graph: dict[Project, set[Project]]\n    @functools.cached_property\n    def projects_by_name(self):\n        return {p.name: p for p in self.projects}\n    @functools.cached_property\n    def projects_by_path(self):\n        return {p.project_path: p for p in self.projects}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "get_git_commit",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "def get_git_commit(path: pathlib.Path):\n    return subprocess.check_output([\"git\", \"-C\", path, \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\ndef validate_unique(projects: list[Project], attr: str):\n    seen = set()\n    for item in projects:\n        attr_value = getattr(item, attr)\n        if attr_value in seen:\n            raise Exception(f\"Duplicate {attr}: {attr_value}\")\n        seen.add(attr_value)\nTHIRD_PARTY = {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "validate_unique",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "def validate_unique(projects: list[Project], attr: str):\n    seen = set()\n    for item in projects:\n        attr_value = getattr(item, attr)\n        if attr_value in seen:\n            raise Exception(f\"Duplicate {attr}: {attr_value}\")\n        seen.add(attr_value)\nTHIRD_PARTY = {\n    \"third-party/appstream\": \"appstream-qt\",\n    \"third-party/cmark\": \"cmark\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "THIRD_PARTY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "THIRD_PARTY = {\n    \"third-party/appstream\": \"appstream-qt\",\n    \"third-party/cmark\": \"cmark\",\n    \"third-party/gpgme\": \"gpgme\",\n    \"third-party/kdsoap\": \"kdsoap\",\n    \"third-party/libaccounts-qt\": \"accounts-qt\",\n    \"third-party/libgpg-error\": \"libgpg-error\",\n    \"third-party/libquotient\": \"libquotient\",\n    \"third-party/packagekit-qt\": \"packagekit-qt\",\n    \"third-party/poppler\": \"poppler\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "IGNORE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "IGNORE = {\n    \"kdesupport/phonon-directshow\",\n    \"kdesupport/phonon-mmf\",\n    \"kdesupport/phonon-mplayer\",\n    \"kdesupport/phonon-quicktime\",\n    \"kdesupport/phonon-waveout\",\n    \"kdesupport/phonon-xine\"\n}\nWARNED = set()\n@dataclasses.dataclass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "WARNED",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "peekOfCode": "WARNED = set()\n@dataclasses.dataclass\nclass KDERepoMetadata:\n    version: str\n    projects: list[Project]\n    dep_graph: dict[Project, set[Project]]\n    @functools.cached_property\n    def projects_by_name(self):\n        return {p.name: p for p in self.projects}\n    @functools.cached_property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.kde.utils",
        "documentation": {}
    },
    {
        "label": "map_dic",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def map_dict (f, d):\n    for k,v in d.items():\n        d[k] = f(v)\nmaintainers_json = subprocess.check_output([\n    'nix-instantiate', '-A', 'lib.maintainers', '--eval', '--strict', '--json'\n])\nmaintainers = json.loads(maintainers_json)\nMAINTAINERS = map_dict(lambda v: v.get('github', None), maintainers)\ndef get_response_text(url):\n    return pq(requests.get(url).text)  # IO",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "get_response_text",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def get_response_text(url):\n    return pq(requests.get(url).text)  # IO\nEVAL_FILE = {\n    'nixos': 'nixos/release.nix',\n    'nixpkgs': 'pkgs/top-level/release.nix',\n}\ndef get_maintainers(attr_name):\n    try:\n        nixname = attr_name.split('.')\n        meta_json = subprocess.check_output([",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "get_maintainers",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def get_maintainers(attr_name):\n    try:\n        nixname = attr_name.split('.')\n        meta_json = subprocess.check_output([\n            'nix-instantiate',\n            '--eval',\n            '--strict',\n            '-A',\n            '.'.join(nixname[1:]) + '.meta',\n            EVAL_FILE[nixname[0]],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "filter_github_users",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def filter_github_users(maintainers):\n    github_only = []\n    for i in maintainers:\n        if i.get('github'):\n            github_only.append(i)\n    return github_only\ndef print_build(table_row):\n    a = pq(table_row)('a')[1]\n    print(\"- [ ] [{}]({})\".format(a.text, a.get('href')), flush=True)\n    job_maintainers = filter_github_users(get_maintainers(a.text))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "print_build",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def print_build(table_row):\n    a = pq(table_row)('a')[1]\n    print(\"- [ ] [{}]({})\".format(a.text, a.get('href')), flush=True)\n    job_maintainers = filter_github_users(get_maintainers(a.text))\n    if job_maintainers:\n        print(\"  - maintainers: {}\".format(\" \".join(map(lambda u: '@' + u.get('github'), job_maintainers))))\n    # TODO: print last three persons that touched this file\n    # TODO: pinpoint the diff that broke this build, or maybe it's transient or maybe it never worked?\n    sys.stdout.flush()\n@click.command()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "def cli(jobset):\n    \"\"\"\n    Given a Hydra project, inspect latest evaluation\n    and print a summary of failed builds\n    \"\"\"\n    url = \"https://hydra.nixos.org/jobset/{}\".format(jobset)\n    # get the last evaluation\n    click.echo(click.style(\n        'Getting latest evaluation for {}'.format(url), fg='green'))\n    d = get_response_text(url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "maintainers_json",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "maintainers_json = subprocess.check_output([\n    'nix-instantiate', '-A', 'lib.maintainers', '--eval', '--strict', '--json'\n])\nmaintainers = json.loads(maintainers_json)\nMAINTAINERS = map_dict(lambda v: v.get('github', None), maintainers)\ndef get_response_text(url):\n    return pq(requests.get(url).text)  # IO\nEVAL_FILE = {\n    'nixos': 'nixos/release.nix',\n    'nixpkgs': 'pkgs/top-level/release.nix',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "maintainers",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "maintainers = json.loads(maintainers_json)\nMAINTAINERS = map_dict(lambda v: v.get('github', None), maintainers)\ndef get_response_text(url):\n    return pq(requests.get(url).text)  # IO\nEVAL_FILE = {\n    'nixos': 'nixos/release.nix',\n    'nixpkgs': 'pkgs/top-level/release.nix',\n}\ndef get_maintainers(attr_name):\n    try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "MAINTAINERS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "MAINTAINERS = map_dict(lambda v: v.get('github', None), maintainers)\ndef get_response_text(url):\n    return pq(requests.get(url).text)  # IO\nEVAL_FILE = {\n    'nixos': 'nixos/release.nix',\n    'nixpkgs': 'pkgs/top-level/release.nix',\n}\ndef get_maintainers(attr_name):\n    try:\n        nixname = attr_name.split('.')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "EVAL_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "peekOfCode": "EVAL_FILE = {\n    'nixos': 'nixos/release.nix',\n    'nixpkgs': 'pkgs/top-level/release.nix',\n}\ndef get_maintainers(attr_name):\n    try:\n        nixname = attr_name.split('.')\n        meta_json = subprocess.check_output([\n            'nix-instantiate',\n            '--eval',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.hydra-eval-failures",
        "documentation": {}
    },
    {
        "label": "FetchConfig",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class FetchConfig:\n    proc: int\n    github_token: str\ndef make_request(url: str, token=None) -> urllib.request.Request:\n    headers = {}\n    if token is not None:\n        headers[\"Authorization\"] = f\"token {token}\"\n    return urllib.request.Request(url, headers=headers)\n# a dictionary of plugins and their new repositories\nRedirects = Dict[\"PluginDesc\", \"Repo\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "Repo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class Repo:\n    def __init__(self, uri: str, branch: str) -> None:\n        self.uri = uri\n        \"\"\"Url to the repo\"\"\"\n        self._branch = branch\n        # Redirect is the new Repo to use\n        self.redirect: Optional[\"Repo\"] = None\n        self.token = \"dummy_token\"\n    @property\n    def name(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "RepoGitHub",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class RepoGitHub(Repo):\n    def __init__(self, owner: str, repo: str, branch: str) -> None:\n        self.owner = owner\n        self.repo = repo\n        self.token = None\n        \"\"\"Url to the repo\"\"\"\n        super().__init__(self.url(\"\"), branch)\n        log.debug(\n            \"Instantiating github repo owner=%s and repo=%s\", self.owner, self.repo\n        )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "PluginDesc",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class PluginDesc:\n    repo: Repo\n    branch: str\n    alias: Optional[str]\n    @property\n    def name(self):\n        if self.alias is None:\n            return self.repo.name\n        else:\n            return self.alias",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "Plugin",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class Plugin:\n    name: str\n    commit: str\n    has_submodules: bool\n    sha256: str\n    date: Optional[datetime] = None\n    @property\n    def normalized_name(self) -> str:\n        return self.name.replace(\".\", \"-\")\n    @property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "Editor",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class Editor:\n    \"\"\"The configuration of the update script.\"\"\"\n    def __init__(\n        self,\n        name: str,\n        root: Path,\n        get_plugins: str,\n        default_in: Optional[Path] = None,\n        default_out: Optional[Path] = None,\n        deprecated: Optional[Path] = None,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "CleanEnvironment",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class CleanEnvironment(object):\n    def __init__(self, nixpkgs):\n        self.local_pkgs = nixpkgs\n    def __enter__(self) -> str:\n        \"\"\"\n        local_pkgs = str(Path(__file__).parent.parent.parent)\n        \"\"\"\n        self.old_environ = os.environ.copy()\n        self.empty_config = NamedTemporaryFile()\n        self.empty_config.write(b\"{}\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "Cache",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "class Cache:\n    def __init__(self, initial_plugins: List[Plugin], cache_file_name: str) -> None:\n        self.cache_file = get_cache_path(cache_file_name)\n        downloads = {}\n        for plugin in initial_plugins:\n            downloads[plugin.commit] = plugin\n        downloads.update(self.load())\n        self.downloads = downloads\n    def load(self) -> Dict[str, Plugin]:\n        if self.cache_file is None or not self.cache_file.exists():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "retry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n    (BSD licensed)\n    :param ExceptionToCheck: the exception on which to retry\n    :param tries: number of times to try (not retry) before giving up\n    :param delay: initial delay between retries in seconds\n    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n        each retry",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "make_request",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def make_request(url: str, token=None) -> urllib.request.Request:\n    headers = {}\n    if token is not None:\n        headers[\"Authorization\"] = f\"token {token}\"\n    return urllib.request.Request(url, headers=headers)\n# a dictionary of plugins and their new repositories\nRedirects = Dict[\"PluginDesc\", \"Repo\"]\nclass Repo:\n    def __init__(self, uri: str, branch: str) -> None:\n        self.uri = uri",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "load_plugins_from_csv",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def load_plugins_from_csv(\n    config: FetchConfig,\n    input_file: Path,\n) -> List[PluginDesc]:\n    log.debug(\"Load plugins from csv %s\", input_file)\n    plugins = []\n    with open(input_file, newline=\"\") as csvfile:\n        log.debug(\"Writing into %s\", input_file)\n        reader = csv.DictReader(\n            csvfile,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "run_nix_expr",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def run_nix_expr(expr, nixpkgs: str):\n    '''\n    :param expr nix expression to fetch current plugins\n    :param nixpkgs Path towards a nixpkgs checkout\n    '''\n    with CleanEnvironment(nixpkgs) as nix_path:\n        cmd = [\n            \"nix\",\n            \"eval\",\n            \"--extra-experimental-features\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "prefetch_plugin",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def prefetch_plugin(\n    p: PluginDesc,\n    cache: \"Optional[Cache]\" = None,\n) -> Tuple[Plugin, Optional[Repo]]:\n    repo, branch, alias = p.repo, p.branch, p.alias\n    name = alias or p.repo.name\n    commit = None\n    log.info(f\"Fetching last commit for plugin {name} from {repo.uri}@{branch}\")\n    commit, date = repo.latest_commit()\n    cached_plugin = cache[commit] if cache else None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "print_download_error",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def print_download_error(plugin: PluginDesc, ex: Exception):\n    print(f\"{plugin}: {ex}\", file=sys.stderr)\n    ex_traceback = ex.__traceback__\n    tb_lines = [\n        line.rstrip(\"\\n\")\n        for line in traceback.format_exception(ex.__class__, ex, ex_traceback)\n    ]\n    print(\"\\n\".join(tb_lines))\ndef check_results(\n    results: List[Tuple[PluginDesc, Union[Exception, Plugin], Optional[Repo]]]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "check_results",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def check_results(\n    results: List[Tuple[PluginDesc, Union[Exception, Plugin], Optional[Repo]]]\n) -> Tuple[List[Tuple[PluginDesc, Plugin]], Redirects]:\n    \"\"\" \"\"\"\n    failures: List[Tuple[PluginDesc, Exception]] = []\n    plugins = []\n    redirects: Redirects = {}\n    for pdesc, result, redirect in results:\n        if isinstance(result, Exception):\n            failures.append((pdesc, result))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "make_repo",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def make_repo(uri: str, branch) -> Repo:\n    \"\"\"Instantiate a Repo with the correct specialization depending on server (gitub spec)\"\"\"\n    # dumb check to see if it's of the form owner/repo (=> github) or https://...\n    res = urlparse(uri)\n    if res.netloc in [\"github.com\", \"\"]:\n        res = res.path.strip(\"/\").split(\"/\")\n        repo = RepoGitHub(res[0], res[1], branch)\n    else:\n        repo = Repo(uri.strip(), branch)\n    return repo",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "get_cache_path",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def get_cache_path(cache_file_name: str) -> Optional[Path]:\n    xdg_cache = os.environ.get(\"XDG_CACHE_HOME\", None)\n    if xdg_cache is None:\n        home = os.environ.get(\"HOME\", None)\n        if home is None:\n            return None\n        xdg_cache = str(Path(home, \".cache\"))\n    return Path(xdg_cache, cache_file_name)\nclass Cache:\n    def __init__(self, initial_plugins: List[Plugin], cache_file_name: str) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "prefetch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def prefetch(\n    pluginDesc: PluginDesc, cache: Cache\n) -> Tuple[PluginDesc, Union[Exception, Plugin], Optional[Repo]]:\n    try:\n        plugin, redirect = prefetch_plugin(pluginDesc, cache)\n        cache[plugin.commit] = plugin\n        return (pluginDesc, plugin, redirect)\n    except Exception as e:\n        return (pluginDesc, e, None)\ndef rewrite_input(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "rewrite_input",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def rewrite_input(\n    config: FetchConfig,\n    input_file: Path,\n    deprecated: Path,\n    # old pluginDesc and the new\n    redirects: Redirects = {},\n    append: List[PluginDesc] = [],\n):\n    plugins = load_plugins_from_csv(\n        config,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "commit",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def commit(repo: git.Repo, message: str, files: List[Path]) -> None:\n    repo.index.add([str(f.resolve()) for f in files])\n    if repo.index.diff(\"HEAD\"):\n        print(f'committing to nixpkgs \"{message}\"')\n        repo.index.commit(message)\n    else:\n        print(\"no changes in working tree to commit\")\ndef update_plugins(editor: Editor, args):\n    \"\"\"The main entry function of this module.\n    All input arguments are grouped in the `Editor`.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "update_plugins",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "def update_plugins(editor: Editor, args):\n    \"\"\"The main entry function of this module.\n    All input arguments are grouped in the `Editor`.\"\"\"\n    log.info(\"Start updating plugins\")\n    fetch_config = FetchConfig(args.proc, args.github_token)\n    update = editor.get_update(args.input_file, args.outfile, fetch_config)\n    start_time = time.time()\n    redirects = update()\n    duration = time.time() - start_time\n    print(f\"The plugin update took {duration}s.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "ATOM_ENTRY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "ATOM_ENTRY = \"{http://www.w3.org/2005/Atom}entry\"  # \" vim gets confused here\nATOM_LINK = \"{http://www.w3.org/2005/Atom}link\"  # \"\nATOM_UPDATED = \"{http://www.w3.org/2005/Atom}updated\"  # \"\nLOG_LEVELS = {\n    logging.getLevelName(level): level\n    for level in [logging.DEBUG, logging.INFO, logging.WARN, logging.ERROR]\n}\nlog = logging.getLogger()\ndef retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "ATOM_LINK",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "ATOM_LINK = \"{http://www.w3.org/2005/Atom}link\"  # \"\nATOM_UPDATED = \"{http://www.w3.org/2005/Atom}updated\"  # \"\nLOG_LEVELS = {\n    logging.getLevelName(level): level\n    for level in [logging.DEBUG, logging.INFO, logging.WARN, logging.ERROR]\n}\nlog = logging.getLogger()\ndef retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "ATOM_UPDATED",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "ATOM_UPDATED = \"{http://www.w3.org/2005/Atom}updated\"  # \"\nLOG_LEVELS = {\n    logging.getLevelName(level): level\n    for level in [logging.DEBUG, logging.INFO, logging.WARN, logging.ERROR]\n}\nlog = logging.getLogger()\ndef retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "LOG_LEVELS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "LOG_LEVELS = {\n    logging.getLevelName(level): level\n    for level in [logging.DEBUG, logging.INFO, logging.WARN, logging.ERROR]\n}\nlog = logging.getLogger()\ndef retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n    (BSD licensed)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "log = logging.getLogger()\ndef retry(ExceptionToCheck: Any, tries: int = 4, delay: float = 3, backoff: float = 2):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n    (BSD licensed)\n    :param ExceptionToCheck: the exception on which to retry\n    :param tries: number of times to try (not retry) before giving up\n    :param delay: initial delay between retries in seconds\n    :param backoff: backoff multiplier e.g. value of 2 will double the delay",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "Redirects",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "peekOfCode": "Redirects = Dict[\"PluginDesc\", \"Repo\"]\nclass Repo:\n    def __init__(self, uri: str, branch: str) -> None:\n        self.uri = uri\n        \"\"\"Url to the repo\"\"\"\n        self._branch = branch\n        # Redirect is the new Repo to use\n        self.redirect: Optional[\"Repo\"] = None\n        self.token = \"dummy_token\"\n    @property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.pluginupdate",
        "documentation": {}
    },
    {
        "label": "process_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def process_args() -> argparse.Namespace:\n    \"\"\"process args\"\"\"\n    arg_parser = argparse.ArgumentParser()\n    arg_parser.add_argument(\n        \"--year\", required=True, type=int, help=\"operate on aliases older than $year\"\n    )\n    arg_parser.add_argument(\n        \"--month\",\n        type=int,\n        default=1,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "get_date_lists",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def get_date_lists(\n    txt: list[str], cutoffdate: datetimedate, only_throws: bool\n) -> tuple[list[str], list[str], list[str]]:\n    \"\"\"get a list of lines in which the date is older than $cutoffdate\"\"\"\n    date_older_list: list[str] = []\n    date_older_throw_list: list[str] = []\n    date_sep_line_list: list[str] = []\n    for lineno, line in enumerate(txt, start=1):\n        line = line.rstrip()\n        my_date = None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "convert_to_throw",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def convert_to_throw(date_older_list: list[str]) -> list[tuple[str, str]]:\n    \"\"\"convert a list of lines to throws\"\"\"\n    converted_list = []\n    for line in date_older_list.copy():\n        indent: str = \" \" * (len(line) - len(line.lstrip()))\n        before_equal = \"\"\n        after_equal = \"\"\n        try:\n            before_equal, after_equal = (x.strip() for x in line.split(\"=\", maxsplit=2))\n        except ValueError as err:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "generate_text_to_write",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def generate_text_to_write(\n    txt: list[str],\n    date_older_list: list[str],\n    converted_to_throw: list[tuple[str, str]],\n    date_older_throw_list: list[str],\n) -> list[str]:\n    \"\"\"generate a list of text to be written to the aliasfile\"\"\"\n    text_to_write: list[str] = []\n    for line in txt:\n        text_to_append: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "write_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def write_file(\n    aliasfile: Path,\n    text_to_write: list[str],\n) -> None:\n    \"\"\"write file\"\"\"\n    temp_aliasfile = Path(f\"{aliasfile}.raliases\")\n    with open(temp_aliasfile, \"w\", encoding=\"utf-8\") as far:\n        for line in text_to_write:\n            far.write(line)\n    print(\"\\nChecking the syntax of the new aliasfile\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "peekOfCode": "def main() -> None:\n    \"\"\"main\"\"\"\n    args = process_args()\n    only_throws = args.only_throws\n    aliasfile = Path(args.file).absolute()\n    cutoffdate = (datetime.strptime(f\"{args.year}-{args.month}-01\", \"%Y-%m-%d\")).date()\n    txt: list[str] = (aliasfile.read_text(encoding=\"utf-8\")).splitlines()\n    date_older_list: list[str] = []\n    date_sep_line_list: list[str] = []\n    date_older_throw_list: list[str] = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.remove-old-aliases",
        "documentation": {}
    },
    {
        "label": "Encoding",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "class Encoding(ABC):\n    alphabet: ClassVar[str]\n    @classmethod\n    @property\n    def name(cls) -> str:\n        return cls.__name__.lower()\n    def toSRI(self, s: str) -> str:\n        digest = self.decode(s)\n        assert len(digest) == self.n\n        from base64 import b64encode",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "Nix32",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "class Nix32(Encoding):\n    alphabet = \"0123456789abcdfghijklmnpqrsvwxyz\"\n    inverted  = { c: i for i, c in enumerate(alphabet) }\n    @property\n    def length(self):\n        return 1 + (8 * self.n) // 5\n    def decode(self, s: str):\n        assert len(s) == self.length\n        out = [ 0 for _ in range(self.n) ]\n        # TODO: Do better than a list of byte-sized ints",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "Hex",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "class Hex(Encoding):\n    alphabet = \"0-9A-Fa-f\"\n    @property\n    def length(self):\n        return 2 * self.n\n    def decode(self, s: str):\n        from binascii import unhexlify\n        return unhexlify(s)\nclass Base64(Encoding):\n    alphabet = \"A-Za-z0-9+/\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "Base64",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "class Base64(Encoding):\n    alphabet = \"A-Za-z0-9+/\"\n    @property\n    def format(self) -> Tuple[int, int]:\n        \"\"\"Number of characters in data and padding.\"\"\"\n        i, k = divmod(self.n, 3)\n        return 4 * i + (0 if k == 0 else k + 1), (3 - k) % 3\n    @property\n    def length(self):\n        return sum(self.format)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "defToSRI",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "def defToSRI(s: str) -> str:\n    def f(m: re.Match[str]) -> str:\n        try:\n            for h, encodings in ENCODINGS.items():\n                if m.group(h) is None:\n                    continue\n                for e in encodings:\n                    s = m.group(f\"{h}_{e.name}\")\n                    if s is not None:\n                        return f'hash = \"{e.toSRI(s)}\";'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "atomicFileUpdate",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "def atomicFileUpdate(target: Path):\n    '''Atomically replace the contents of a file.\n    Guarantees that no temporary files are left behind, and `target` is either\n    left untouched, or overwritten with new content if no exception was raised.\n    Yields a pair `(original, new)` of open files.\n    `original` is the pre-existing file at `target`, open for reading;\n    `new` is an empty, temporary file in the same filder, open for writing.\n    Upon exiting the context, the files are closed; if no exception was\n    raised, `new` (atomically) replaces the `target`, otherwise it is deleted.\n    '''",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "fileToSRI",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "def fileToSRI(p: Path):\n    with atomicFileUpdate(p) as (og, new):\n        for i, line in enumerate(og):\n            with log_context(line=i):\n                new.write(defToSRI(line))\n_SKIP_RE = re.compile(\n    \"(generated by)|(do not edit)\",\n    re.IGNORECASE\n)\nif __name__ == \"__main__\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "logger = structlog.getLogger(\"sha-to-SRI\")\nclass Encoding(ABC):\n    alphabet: ClassVar[str]\n    @classmethod\n    @property\n    def name(cls) -> str:\n        return cls.__name__.lower()\n    def toSRI(self, s: str) -> str:\n        digest = self.decode(s)\n        assert len(digest) == self.n",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "_HASHES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "_HASHES = (hashlib.new(n) for n in ('SHA-256', 'SHA-512'))\nENCODINGS = {\n    h.name: Encoding.all(h)\n    for h in _HASHES\n}\nRE = {\n    h: \"|\".join(\n        (f\"({h}-)?\" if e.name == 'base64' else '') +\n        f\"(?P<{h}_{e.name}>{e.regex})\"\n        for e in encodings",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "ENCODINGS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "ENCODINGS = {\n    h.name: Encoding.all(h)\n    for h in _HASHES\n}\nRE = {\n    h: \"|\".join(\n        (f\"({h}-)?\" if e.name == 'base64' else '') +\n        f\"(?P<{h}_{e.name}>{e.regex})\"\n        for e in encodings\n    ) for h, encodings in ENCODINGS.items()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "RE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "RE = {\n    h: \"|\".join(\n        (f\"({h}-)?\" if e.name == 'base64' else '') +\n        f\"(?P<{h}_{e.name}>{e.regex})\"\n        for e in encodings\n    ) for h, encodings in ENCODINGS.items()\n}\n_DEF_RE = re.compile(\"|\".join(\n    f\"(?P<{h}>{h} = (?P<{h}_quote>['\\\"])({re})(?P={h}_quote);)\"\n    for h, re in RE.items()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "_DEF_RE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "_DEF_RE = re.compile(\"|\".join(\n    f\"(?P<{h}>{h} = (?P<{h}_quote>['\\\"])({re})(?P={h}_quote);)\"\n    for h, re in RE.items()\n))\ndef defToSRI(s: str) -> str:\n    def f(m: re.Match[str]) -> str:\n        try:\n            for h, encodings in ENCODINGS.items():\n                if m.group(h) is None:\n                    continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "_SKIP_RE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "peekOfCode": "_SKIP_RE = re.compile(\n    \"(generated by)|(do not edit)\",\n    re.IGNORECASE\n)\nif __name__ == \"__main__\":\n    from sys import argv, stderr\n    logger.info(\"Starting!\")\n    for arg in argv[1:]:\n        p = Path(arg)\n        with log_context(path=str(p)):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.sha-to-sri",
        "documentation": {}
    },
    {
        "label": "CalledProcessError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "class CalledProcessError(Exception):\n    process: asyncio.subprocess.Process\nclass UpdateFailedException(Exception):\n    pass\ndef eprint(*args, **kwargs):\n    print(*args, file=sys.stderr, **kwargs)\nasync def check_subprocess(*args, **kwargs):\n    \"\"\"\n    Emulate check argument of subprocess.run function.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "UpdateFailedException",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "class UpdateFailedException(Exception):\n    pass\ndef eprint(*args, **kwargs):\n    print(*args, file=sys.stderr, **kwargs)\nasync def check_subprocess(*args, **kwargs):\n    \"\"\"\n    Emulate check argument of subprocess.run function.\n    \"\"\"\n    process = await asyncio.create_subprocess_exec(*args, **kwargs)\n    returncode = await process.wait()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "eprint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "def eprint(*args, **kwargs):\n    print(*args, file=sys.stderr, **kwargs)\nasync def check_subprocess(*args, **kwargs):\n    \"\"\"\n    Emulate check argument of subprocess.run function.\n    \"\"\"\n    process = await asyncio.create_subprocess_exec(*args, **kwargs)\n    returncode = await process.wait()\n    if returncode != 0:\n        error = CalledProcessError()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "make_worktree",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "def make_worktree() -> Generator[Tuple[str, str], None, None]:\n    with tempfile.TemporaryDirectory() as wt:\n        branch_name = f'update-{os.path.basename(wt)}'\n        target_directory = f'{wt}/nixpkgs'\n        subprocess.run(['git', 'worktree', 'add', '-b', branch_name, target_directory])\n        yield (target_directory, branch_name)\n        subprocess.run(['git', 'worktree', 'remove', '--force', target_directory])\n        subprocess.run(['git', 'branch', '-D', branch_name])\nasync def commit_changes(name: str, merge_lock: asyncio.Lock, worktree: str, branch: str, changes: List[Dict]) -> None:\n    for change in changes:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "def main(max_workers: int, keep_going: bool, commit: bool, packages_path: str) -> None:\n    with open(packages_path) as f:\n        packages = json.load(f)\n    eprint()\n    eprint('Going to be running update for following packages:')\n    for package in packages:\n        eprint(f\" - {package['name']}\")\n    eprint()\n    confirm = input('Press Enter key to continue...')\n    if confirm == '':",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "peekOfCode": "parser = argparse.ArgumentParser(description='Update packages')\nparser.add_argument('--max-workers', '-j', dest='max_workers', type=int, help='Number of updates to run concurrently', nargs='?', default=4)\nparser.add_argument('--keep-going', '-k', dest='keep_going', action='store_true', help='Do not stop after first failure')\nparser.add_argument('--commit', '-c', dest='commit', action='store_true', help='Commit the changes')\nparser.add_argument('packages', help='JSON file containing the list of package names and their update scripts')\nif __name__ == '__main__':\n    args = parser.parse_args()\n    try:\n        main(args.max_workers, args.keep_going, args.commit, args.packages)\n    except KeyboardInterrupt as e:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.maintainers.scripts.update",
        "documentation": {}
    },
    {
        "label": "Key",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "class Key:\n    def __init__(self, path: List[str]):\n        self.path = path\n    def __hash__(self):\n        result = 0\n        for id in self.path:\n            result ^= hash(id)\n        return result\n    def __eq__(self, other):\n        return type(self) is type(other) and self.path == other.path",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "pivot",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "def pivot(options: Dict[str, JSON]) -> Dict[Key, Option]:\n    result: Dict[Key, Option] = dict()\n    for (name, opt) in options.items():\n        result[Key(opt['loc'])] = Option(name, opt)\n    return result\n# pivot back to indexed-by-full-name\n# like the docbook build we'll just fail if multiple options with differing locs\n# render to the same option name.\ndef unpivot(options: Dict[Key, Option]) -> Dict[str, JSON]:\n    result: Dict[str, Dict] = dict()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "unpivot",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "def unpivot(options: Dict[Key, Option]) -> Dict[str, JSON]:\n    result: Dict[str, Dict] = dict()\n    for (key, opt) in options.items():\n        if opt.name in result:\n            raise RuntimeError(\n                'multiple options with colliding ids found',\n                opt.name,\n                result[opt.name]['loc'],\n                opt.value['loc'],\n            )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "JSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "JSON = Dict[str, Any]\nclass Key:\n    def __init__(self, path: List[str]):\n        self.path = path\n    def __hash__(self):\n        result = 0\n        for id in self.path:\n            result ^= hash(id)\n        return result\n    def __eq__(self, other):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "Option",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "Option = collections.namedtuple('Option', ['name', 'value'])\n# pivot a dict of options keyed by their display name to a dict keyed by their path\ndef pivot(options: Dict[str, JSON]) -> Dict[Key, Option]:\n    result: Dict[Key, Option] = dict()\n    for (name, opt) in options.items():\n        result[Key(opt['loc'])] = Option(name, opt)\n    return result\n# pivot back to indexed-by-full-name\n# like the docbook build we'll just fail if multiple options with differing locs\n# render to the same option name.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "warningsAreErrors",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "warningsAreErrors = False\noptOffset = 0\nfor arg in sys.argv[1:]:\n    if arg == \"--warnings-are-errors\":\n        optOffset += 1\n        warningsAreErrors = True\noptions = pivot(json.load(open(sys.argv[1 + optOffset], 'r')))\noverrides = pivot(json.load(open(sys.argv[2 + optOffset], 'r')))\n# fix up declaration paths in lazy options, since we don't eval them from a full nixpkgs dir\nfor (k, v) in options.items():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "optOffset",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "optOffset = 0\nfor arg in sys.argv[1:]:\n    if arg == \"--warnings-are-errors\":\n        optOffset += 1\n        warningsAreErrors = True\noptions = pivot(json.load(open(sys.argv[1 + optOffset], 'r')))\noverrides = pivot(json.load(open(sys.argv[2 + optOffset], 'r')))\n# fix up declaration paths in lazy options, since we don't eval them from a full nixpkgs dir\nfor (k, v) in options.items():\n    # The _module options are not declared in nixos/modules",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "options",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "options = pivot(json.load(open(sys.argv[1 + optOffset], 'r')))\noverrides = pivot(json.load(open(sys.argv[2 + optOffset], 'r')))\n# fix up declaration paths in lazy options, since we don't eval them from a full nixpkgs dir\nfor (k, v) in options.items():\n    # The _module options are not declared in nixos/modules\n    if v.value['loc'][0] != \"_module\":\n        v.value['declarations'] = list(map(lambda s: f'nixos/modules/{s}' if isinstance(s, str) else s, v.value['declarations']))\n# merge both descriptions\nfor (k, v) in overrides.items():\n    cur = options.setdefault(k, v).value",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "overrides",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "overrides = pivot(json.load(open(sys.argv[2 + optOffset], 'r')))\n# fix up declaration paths in lazy options, since we don't eval them from a full nixpkgs dir\nfor (k, v) in options.items():\n    # The _module options are not declared in nixos/modules\n    if v.value['loc'][0] != \"_module\":\n        v.value['declarations'] = list(map(lambda s: f'nixos/modules/{s}' if isinstance(s, str) else s, v.value['declarations']))\n# merge both descriptions\nfor (k, v) in overrides.items():\n    cur = options.setdefault(k, v).value\n    for (ok, ov) in v.value.items():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "severity",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "severity = \"error\" if warningsAreErrors else \"warning\"\n# check that every option has a description\nhasWarnings = False\nhasErrors = False\nfor (k, v) in options.items():\n    if v.value.get('description', None) is None:\n        hasWarnings = True\n        print(f\"\\x1b[1;31m{severity}: option {v.name} has no description\\x1b[0m\", file=sys.stderr)\n        v.value['description'] = \"This option has no description.\"\n    if v.value.get('type', \"unspecified\") == \"unspecified\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "hasWarnings",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "hasWarnings = False\nhasErrors = False\nfor (k, v) in options.items():\n    if v.value.get('description', None) is None:\n        hasWarnings = True\n        print(f\"\\x1b[1;31m{severity}: option {v.name} has no description\\x1b[0m\", file=sys.stderr)\n        v.value['description'] = \"This option has no description.\"\n    if v.value.get('type', \"unspecified\") == \"unspecified\":\n        hasWarnings = True\n        print(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "hasErrors",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "peekOfCode": "hasErrors = False\nfor (k, v) in options.items():\n    if v.value.get('description', None) is None:\n        hasWarnings = True\n        print(f\"\\x1b[1;31m{severity}: option {v.name} has no description\\x1b[0m\", file=sys.stderr)\n        v.value['description'] = \"This option has no description.\"\n    if v.value.get('type', \"unspecified\") == \"unspecified\":\n        hasWarnings = True\n        print(\n            f\"\\x1b[1;31m{severity}: option {v.name} has no type. Please specify a valid type, see \" +",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.make-options-doc.mergeJSON",
        "documentation": {}
    },
    {
        "label": "Driver",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "peekOfCode": "class Driver:\n    \"\"\"A handle to the driver that sets up the environment\n    and runs the tests\"\"\"\n    tests: str\n    vlans: List[VLan]\n    machines: List[Machine]\n    polling_conditions: List[PollingCondition]\n    global_timeout: int\n    race_timer: threading.Timer\n    logger: AbstractLogger",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "documentation": {}
    },
    {
        "label": "get_tmp_dir",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "peekOfCode": "def get_tmp_dir() -> Path:\n    \"\"\"Returns a temporary directory that is defined by TMPDIR, TEMP, TMP or CWD\n    Raises an exception in case the retrieved temporary directory is not writeable\n    See https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir\n    \"\"\"\n    tmp_dir = Path(tempfile.gettempdir())\n    tmp_dir.mkdir(mode=0o700, exist_ok=True)\n    if not tmp_dir.is_dir():\n        raise NotADirectoryError(\n            f\"The directory defined by TMPDIR, TEMP, TMP or CWD: {tmp_dir} is not a directory\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "documentation": {}
    },
    {
        "label": "pythonize_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "peekOfCode": "def pythonize_name(name: str) -> str:\n    return re.sub(r\"^[^A-z_]|[^A-z0-9_]\", \"_\", name)\nclass Driver:\n    \"\"\"A handle to the driver that sets up the environment\n    and runs the tests\"\"\"\n    tests: str\n    vlans: List[VLan]\n    machines: List[Machine]\n    polling_conditions: List[PollingCondition]\n    global_timeout: int",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "documentation": {}
    },
    {
        "label": "SENTINEL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "peekOfCode": "SENTINEL = object()\ndef get_tmp_dir() -> Path:\n    \"\"\"Returns a temporary directory that is defined by TMPDIR, TEMP, TMP or CWD\n    Raises an exception in case the retrieved temporary directory is not writeable\n    See https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir\n    \"\"\"\n    tmp_dir = Path(tempfile.gettempdir())\n    tmp_dir.mkdir(mode=0o700, exist_ok=True)\n    if not tmp_dir.is_dir():\n        raise NotADirectoryError(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.driver",
        "documentation": {}
    },
    {
        "label": "AbstractLogger",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "peekOfCode": "class AbstractLogger(ABC):\n    @abstractmethod\n    def log(self, message: str, attributes: Dict[str, str] = {}) -> None:\n        pass\n    @abstractmethod\n    @contextmanager\n    def subtest(self, name: str, attributes: Dict[str, str] = {}) -> Iterator[None]:\n        pass\n    @abstractmethod\n    @contextmanager",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "documentation": {}
    },
    {
        "label": "JunitXMLLogger",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "peekOfCode": "class JunitXMLLogger(AbstractLogger):\n    class TestCaseState:\n        def __init__(self) -> None:\n            self.stdout = \"\"\n            self.stderr = \"\"\n            self.failure = False\n    def __init__(self, outfile: Path) -> None:\n        self.tests: dict[str, JunitXMLLogger.TestCaseState] = {\n            \"main\": self.TestCaseState()\n        }",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "documentation": {}
    },
    {
        "label": "CompositeLogger",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "peekOfCode": "class CompositeLogger(AbstractLogger):\n    def __init__(self, logger_list: List[AbstractLogger]) -> None:\n        self.logger_list = logger_list\n    def add_logger(self, logger: AbstractLogger) -> None:\n        self.logger_list.append(logger)\n    def log(self, message: str, attributes: Dict[str, str] = {}) -> None:\n        for logger in self.logger_list:\n            logger.log(message, attributes)\n    @contextmanager\n    def subtest(self, name: str, attributes: Dict[str, str] = {}) -> Iterator[None]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "documentation": {}
    },
    {
        "label": "TerminalLogger",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "peekOfCode": "class TerminalLogger(AbstractLogger):\n    def __init__(self) -> None:\n        self._print_serial_logs = True\n    def maybe_prefix(self, message: str, attributes: Dict[str, str]) -> str:\n        if \"machine\" in attributes:\n            return f\"{attributes['machine']}: {message}\"\n        return message\n    @staticmethod\n    def _eprint(*args: object, **kwargs: Any) -> None:\n        print(*args, file=sys.stderr, **kwargs)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "documentation": {}
    },
    {
        "label": "XMLLogger",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "peekOfCode": "class XMLLogger(AbstractLogger):\n    def __init__(self, outfile: str) -> None:\n        self.logfile_handle = codecs.open(outfile, \"wb\")\n        self.xml = XMLGenerator(self.logfile_handle, encoding=\"utf-8\")\n        self.queue: Queue[dict[str, str]] = Queue()\n        self._print_serial_logs = True\n        self.xml.startDocument()\n        self.xml.startElement(\"logfile\", attrs=AttributesImpl({}))\n    def close(self) -> None:\n        self.xml.endElement(\"logfile\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.logger",
        "documentation": {}
    },
    {
        "label": "StartCommand",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "class StartCommand:\n    \"\"\"The Base Start Command knows how to append the necessary\n    runtime qemu options as determined by a particular test driver\n    run. Any such start command is expected to happily receive and\n    append additional qemu args.\n    \"\"\"\n    _cmd: str\n    def cmd(\n        self,\n        monitor_socket_path: Path,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "NixStartScript",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "class NixStartScript(StartCommand):\n    \"\"\"A start script from nixos/modules/virtualiation/qemu-vm.nix\n    that also satisfies the requirement of the BaseStartCommand.\n    These Nix commands have the particular characteristic that the\n    machine name can be extracted out of them via a regex match.\n    (Admittedly a _very_ implicit contract, evtl. TODO fix)\n    \"\"\"\n    def __init__(self, script: str):\n        self._cmd = script\n    @property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "Machine",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "class Machine:\n    \"\"\"A handle to the machine with this name, that also knows how to manage\n    the machine lifecycle with the help of a start script / command.\"\"\"\n    name: str\n    out_dir: Path\n    tmp_dir: Path\n    shared_dir: Path\n    state_dir: Path\n    monitor_path: Path\n    qmp_path: Path",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "make_command",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "def make_command(args: list) -> str:\n    return \" \".join(map(shlex.quote, (map(str, args))))\ndef _perform_ocr_on_screenshot(\n    screenshot_path: str, model_ids: Iterable[int]\n) -> List[str]:\n    if shutil.which(\"tesseract\") is None:\n        raise Exception(\"OCR requested but enableOCR is false\")\n    magick_args = (\n        \"-filter Catrom -density 72 -resample 300 \"\n        + \"-contrast -normalize -despeckle -type grayscale \"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "retry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "def retry(fn: Callable, timeout: int = 900) -> None:\n    \"\"\"Call the given function repeatedly, with 1 second intervals,\n    until it returns True or a timeout is reached.\n    \"\"\"\n    for _ in range(timeout):\n        if fn(False):\n            return\n        time.sleep(1)\n    if not fn(True):\n        raise Exception(f\"action timed out after {timeout} seconds\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "CHAR_TO_KEY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "peekOfCode": "CHAR_TO_KEY = {\n    \"A\": \"shift-a\",\n    \"N\": \"shift-n\",\n    \"-\": \"0x0C\",\n    \"_\": \"shift-0x0C\",\n    \"B\": \"shift-b\",\n    \"O\": \"shift-o\",\n    \"=\": \"0x0D\",\n    \"+\": \"shift-0x0D\",\n    \"C\": \"shift-c\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.machine",
        "documentation": {}
    },
    {
        "label": "PollingConditionError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "peekOfCode": "class PollingConditionError(Exception):\n    pass\nclass PollingCondition:\n    condition: Callable[[], bool]\n    seconds_interval: float\n    description: Optional[str]\n    logger: AbstractLogger\n    last_called: float\n    entry_count: int\n    def __init__(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "documentation": {}
    },
    {
        "label": "PollingCondition",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "peekOfCode": "class PollingCondition:\n    condition: Callable[[], bool]\n    seconds_interval: float\n    description: Optional[str]\n    logger: AbstractLogger\n    last_called: float\n    entry_count: int\n    def __init__(\n        self,\n        condition: Callable[[], Optional[bool]],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.polling_condition",
        "documentation": {}
    },
    {
        "label": "QMPAPIError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "peekOfCode": "class QMPAPIError(RuntimeError):\n    def __init__(self, message: dict[str, Any]):\n        assert \"error\" in message, \"Not an error message!\"\n        try:\n            self.class_name = message[\"class\"]\n            self.description = message[\"desc\"]\n            # NOTE: Some errors can occur before the Server is able to read the\n            # id member; in these cases the id member will not be part of the\n            # error response, even if provided by the client.\n            self.transaction_id = message.get(\"id\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "documentation": {}
    },
    {
        "label": "QMPSession",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "peekOfCode": "class QMPSession:\n    def __init__(self, sock: socket.socket) -> None:\n        self.sock = sock\n        self.results: Queue[dict[str, str]] = Queue()\n        self.pending_events: Queue[dict[str, Any]] = Queue()\n        self.reader = sock.makefile(\"r\")\n        self.writer = sock.makefile(\"w\")\n        # Make the reader non-blocking so we can kind of select on it.\n        os.set_blocking(self.reader.fileno(), False)\n        hello = self._wait_for_new_result()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass QMPAPIError(RuntimeError):\n    def __init__(self, message: dict[str, Any]):\n        assert \"error\" in message, \"Not an error message!\"\n        try:\n            self.class_name = message[\"class\"]\n            self.description = message[\"desc\"]\n            # NOTE: Some errors can occur before the Server is able to read the\n            # id member; in these cases the id member will not be part of the\n            # error response, even if provided by the client.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.qmp",
        "documentation": {}
    },
    {
        "label": "VLan",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.vlan",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.vlan",
        "peekOfCode": "class VLan:\n    \"\"\"This class handles a VLAN that the run-vm scripts identify via its\n    number handles. The network's lifetime equals the object's lifetime.\n    \"\"\"\n    nr: int\n    socket_dir: Path\n    process: subprocess.Popen\n    pid: int\n    fd: io.TextIOBase\n    logger: AbstractLogger",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.test_driver.vlan",
        "documentation": {}
    },
    {
        "label": "Machine",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "peekOfCode": "class Machine(...):\n    ...\n    def some_function(self, param1, param2):\n        \"\"\n        documentation string of some_function.\n        foo bar baz.\n        \"\"\n        ...\n```\nOutput will be:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "peekOfCode": "def main() -> None:\n    if len(sys.argv) != 2:\n        print(f\"Usage: {sys.argv[0]} <path-to-test-driver>\")\n        sys.exit(1)\n    module = ast.parse(Path(sys.argv[1]).read_text())\n    class_definitions = (node for node in module.body if isinstance(node, ast.ClassDef))\n    machine_class = next(filter(lambda x: x.name == \"Machine\", class_definitions))\n    assert machine_class is not None\n    function_definitions = [\n        node for node in machine_class.body if isinstance(node, ast.FunctionDef)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-driver.extract-docstrings",
        "documentation": {}
    },
    {
        "label": "RetryProtocol",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "peekOfCode": "class RetryProtocol(Protocol):\n    def __call__(self, fn: Callable, timeout: int = 900) -> None:\n        raise Exception(\"This is just type information for the Nix test driver\")\nclass PollingConditionProtocol(Protocol):\n    def __call__(\n        self,\n        fun_: Optional[Callable] = None,\n        *,\n        seconds_interval: float = 2.0,\n        description: Optional[str] = None,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "documentation": {}
    },
    {
        "label": "PollingConditionProtocol",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "peekOfCode": "class PollingConditionProtocol(Protocol):\n    def __call__(\n        self,\n        fun_: Optional[Callable] = None,\n        *,\n        seconds_interval: float = 2.0,\n        description: Optional[str] = None,\n    ) -> Union[Callable[[Callable], ContextManager], ContextManager]:\n        raise Exception(\"This is just type information for the Nix test driver\")\nclass CreateMachineProtocol(Protocol):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "documentation": {}
    },
    {
        "label": "CreateMachineProtocol",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "peekOfCode": "class CreateMachineProtocol(Protocol):\n    def __call__(\n        self,\n        start_command: str | dict,\n        *,\n        name: Optional[str] = None,\n        keep_vm_state: bool = False,\n    ) -> Machine:\n        raise Exception(\"This is just type information for the Nix test driver\")\nstart_all: Callable[[], None]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.lib.test-script-prepend",
        "documentation": {}
    },
    {
        "label": "add_contents_to_definition",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "peekOfCode": "def add_contents_to_definition(\n    definition: Path, contents: dict[str, dict[str, str]] | None\n) -> None:\n    \"\"\"Add CopyFiles= instructions to a definition for all files in contents.\"\"\"\n    if not contents:\n        return\n    copy_files_lines: list[str] = []\n    for target, options in contents.items():\n        source = options[\"source\"]\n        copy_files_lines.append(f\"CopyFiles={source}:{target}\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "documentation": {}
    },
    {
        "label": "add_closure_to_definition",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "peekOfCode": "def add_closure_to_definition(\n    definition: Path, closure: Path | None, strip_nix_store_prefix: bool | None\n) -> None:\n    \"\"\"Add CopyFiles= instructions to a definition for all paths in the closure.\n    If strip_nix_store_prefix is True, `/nix/store` is stripped from the target path.\n    \"\"\"\n    if not closure:\n        return\n    copy_files_lines: list[str] = []\n    with open(closure, \"r\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "peekOfCode": "def main() -> None:\n    \"\"\"Amend the provided repart definitions by adding CopyFiles= instructions.\n    For each file specified in the `contents` field of a partition in the\n    partiton config file, a `CopyFiles=` instruction is added to the\n    corresponding definition file.\n    The same is done for every store path of the `closure` field.\n    Print the path to a directory that contains the amended repart\n    definitions to stdout.\n    \"\"\"\n    partition_config_file = sys.argv[1]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.image.amend-repart-definitions",
        "documentation": {}
    },
    {
        "label": "TaskdError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class TaskdError(OSError):\n    pass\ndef run_as_taskd_user():\n    uid = pwd.getpwnam(TASKD_USER).pw_uid\n    gid = grp.getgrnam(TASKD_GROUP).gr_gid\n    os.setgid(gid)\n    os.setuid(uid)\ndef run_as_taskd_group():\n    gid = grp.getgrnam(TASKD_GROUP).gr_gid\n    os.setgid(gid)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "User",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class User(object):\n    def __init__(self, org, name, key):\n        self.__org = org\n        self.name = name\n        self.key = key\n    def export(self):\n        credentials = '/'.join([self.__org, self.name, self.key])\n        allow_unquoted = string.ascii_letters + string.digits + \"/-_.\"\n        if not all((c in allow_unquoted) for c in credentials):\n            credentials = \"'\" + credentials.replace(\"'\", r\"'\\''\") + \"'\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "Group",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class Group(object):\n    def __init__(self, org, name):\n        self.__org = org\n        self.name = name\nclass Organisation(object):\n    def __init__(self, name, ignore_imperative):\n        self.name = name\n        self.ignore_imperative = ignore_imperative\n    def add_user(self, name):\n        \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "Organisation",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class Organisation(object):\n    def __init__(self, name, ignore_imperative):\n        self.name = name\n        self.ignore_imperative = ignore_imperative\n    def add_user(self, name):\n        \"\"\"\n        Create a new user along with a certificate and key.\n        Returns a 'User' object or None if the user already exists.\n        \"\"\"\n        if self.ignore_imperative and is_imperative(self.name):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "Manager",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class Manager(object):\n    def __init__(self, ignore_imperative=False):\n        \"\"\"\n        Instantiates an organisations manager.\n        If ignore_imperative is True, all actions that modify data are checked\n        whether they're created imperatively and if so, they will result in no\n        operation.\n        \"\"\"\n        self.ignore_imperative = ignore_imperative\n    def add_org(self, name):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "OrganisationType",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "class OrganisationType(click.ParamType):\n    name = 'organisation'\n    def convert(self, value, param, ctx):\n        org = Manager().get_org(value)\n        if org is None:\n            self.fail(\"Organisation {} does not exist.\".format(value))\n        return org\nORGANISATION = OrganisationType()\n@click.group()\n@click.pass_context",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "lazyprop",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__\n    @property\n    def _lazy(self):\n        val = getattr(self, name, None)\n        if val is None:\n            val = fun(self)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "run_as_taskd_user",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def run_as_taskd_user():\n    uid = pwd.getpwnam(TASKD_USER).pw_uid\n    gid = grp.getgrnam(TASKD_GROUP).gr_gid\n    os.setgid(gid)\n    os.setuid(uid)\ndef run_as_taskd_group():\n    gid = grp.getgrnam(TASKD_GROUP).gr_gid\n    os.setgid(gid)\ndef taskd_cmd(cmd, *args, **kwargs):\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "run_as_taskd_group",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def run_as_taskd_group():\n    gid = grp.getgrnam(TASKD_GROUP).gr_gid\n    os.setgid(gid)\ndef taskd_cmd(cmd, *args, **kwargs):\n    \"\"\"\n    Invoke taskd with the specified command with the privileges of the 'taskd'\n    user and 'taskd' group.\n    If 'capture_stdout' is passed as a keyword argument with the value True,\n    the return value are the contents the command printed to stdout.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "taskd_cmd",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def taskd_cmd(cmd, *args, **kwargs):\n    \"\"\"\n    Invoke taskd with the specified command with the privileges of the 'taskd'\n    user and 'taskd' group.\n    If 'capture_stdout' is passed as a keyword argument with the value True,\n    the return value are the contents the command printed to stdout.\n    \"\"\"\n    capture_stdout = kwargs.pop(\"capture_stdout\", False)\n    fun = subprocess.check_output if capture_stdout else subprocess.check_call\n    return fun(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "certtool_cmd",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def certtool_cmd(*args, **kwargs):\n    \"\"\"\n    Invoke certtool from GNUTLS and return the output of the command.\n    The provided arguments are added to the certtool command and keyword\n    arguments are added to subprocess.check_output().\n    Note that this will suppress all output of certtool and it will only be\n    printed whenever there is an unsuccessful return code.\n    \"\"\"\n    return subprocess.check_output(\n        [CERTTOOL_COMMAND] + list(args),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "label",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def label(msg):\n    if sys.stdout.isatty() or sys.stderr.isatty():\n        sys.stderr.write(msg + \"\\n\")\ndef mkpath(*args):\n    return os.path.join(TASKD_DATA_DIR, \"orgs\", *args)\ndef mark_imperative(*path):\n    \"\"\"\n    Mark the specified path as being imperatively managed by creating an empty\n    file called \".imperative\", so that it doesn't interfere with the\n    declarative configuration.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "mkpath",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def mkpath(*args):\n    return os.path.join(TASKD_DATA_DIR, \"orgs\", *args)\ndef mark_imperative(*path):\n    \"\"\"\n    Mark the specified path as being imperatively managed by creating an empty\n    file called \".imperative\", so that it doesn't interfere with the\n    declarative configuration.\n    \"\"\"\n    open(os.path.join(mkpath(*path), \".imperative\"), 'a').close()\ndef is_imperative(*path):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "mark_imperative",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def mark_imperative(*path):\n    \"\"\"\n    Mark the specified path as being imperatively managed by creating an empty\n    file called \".imperative\", so that it doesn't interfere with the\n    declarative configuration.\n    \"\"\"\n    open(os.path.join(mkpath(*path), \".imperative\"), 'a').close()\ndef is_imperative(*path):\n    \"\"\"\n    Check whether the given path is marked as imperative, see mark_imperative()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "is_imperative",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def is_imperative(*path):\n    \"\"\"\n    Check whether the given path is marked as imperative, see mark_imperative()\n    for more information.\n    \"\"\"\n    full_path = []\n    for component in path:\n        full_path.append(component)\n        if os.path.exists(os.path.join(mkpath(*full_path), \".imperative\")):\n            return True",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "fetch_username",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def fetch_username(org, key):\n    for line in open(mkpath(org, \"users\", key, \"config\"), \"r\"):\n        match = RE_CONFIGUSER.match(line)\n        if match is None:\n            continue\n        return match.group(1).strip()\n    return None\n@contextmanager\ndef create_template(contents):\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "create_template",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def create_template(contents):\n    \"\"\"\n    Generate a temporary file with the specified contents as a list of strings\n    and yield its path as the context.\n    \"\"\"\n    template = NamedTemporaryFile(mode=\"w\", prefix=\"certtool-template\")\n    template.writelines(map(lambda l: l + \"\\n\", contents))\n    template.flush()\n    yield template.name\n    template.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "generate_key",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def generate_key(org, user):\n    if not IS_AUTO_CONFIG:\n        msg = \"Automatic PKI handling is disabled, you need to \" \\\n              \"manually issue a client certificate for user {}.\\n\"\n        sys.stderr.write(msg.format(user))\n        return\n    keysdir = os.path.join(TASKD_DATA_DIR, \"keys\" )\n    orgdir  = os.path.join(keysdir       , org    )\n    userdir = os.path.join(orgdir        , user   )\n    if os.path.exists(userdir):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "revoke_key",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def revoke_key(org, user):\n    basedir = os.path.join(TASKD_DATA_DIR, \"keys\", org, user)\n    if not os.path.exists(basedir):\n        raise OSError(\"Keyfile directory for {} doesn't exist.\".format(user))\n    pubcert = os.path.join(basedir, \"public.cert\")\n    expiration = \"expiration_days = {}\".format(CRL_EXPIRATION)\n    with create_template([expiration]) as template:\n        oldcrl = NamedTemporaryFile(mode=\"wb\", prefix=\"old-crl\")\n        oldcrl.write(open(CRL_FILE, \"rb\").read())\n        oldcrl.flush()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "is_key_line",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def is_key_line(line, match):\n    return line.startswith(\"---\") and line.lstrip(\"- \").startswith(match)\ndef getkey(*args):\n    path = os.path.join(TASKD_DATA_DIR, \"keys\", *args)\n    buf = []\n    for line in open(path, \"r\"):\n        if len(buf) == 0:\n            if is_key_line(line, \"BEGIN\"):\n                buf.append(line)\n            continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "getkey",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def getkey(*args):\n    path = os.path.join(TASKD_DATA_DIR, \"keys\", *args)\n    buf = []\n    for line in open(path, \"r\"):\n        if len(buf) == 0:\n            if is_key_line(line, \"BEGIN\"):\n                buf.append(line)\n            continue\n        buf.append(line)\n        if is_key_line(line, \"END\"):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "mktaskkey",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def mktaskkey(cfg, path, keydata):\n    heredoc = 'cat > \"{}\" <<EOF\\n{}EOF'.format(path, keydata)\n    cmd = 'task config taskd.{} -- \"{}\"'.format(cfg, path)\n    return heredoc + \"\\n\" + cmd\nclass User(object):\n    def __init__(self, org, name, key):\n        self.__org = org\n        self.name = name\n        self.key = key\n    def export(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def cli(ctx):\n    \"\"\"\n    Manage Taskserver users and certificates\n    \"\"\"\n    if not IS_AUTO_CONFIG:\n        return\n    for path in (CA_KEY, CA_CERT, CRL_FILE):\n        if not os.path.exists(path):\n            msg = \"CA setup not done or incomplete, missing file {}.\"\n            ctx.fail(msg.format(path))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "org_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def org_cli():\n    \"\"\"\n    Manage organisations\n    \"\"\"\n    pass\n@cli.group(\"user\")\ndef user_cli():\n    \"\"\"\n    Manage users\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "user_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def user_cli():\n    \"\"\"\n    Manage users\n    \"\"\"\n    pass\n@cli.group(\"group\")\ndef group_cli():\n    \"\"\"\n    Manage groups\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "group_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def group_cli():\n    \"\"\"\n    Manage groups\n    \"\"\"\n    pass\n@user_cli.command(\"list\")\n@click.argument(\"organisation\", type=ORGANISATION)\ndef list_users(organisation):\n    \"\"\"\n    List all users belonging to the specified organisation.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "list_users",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def list_users(organisation):\n    \"\"\"\n    List all users belonging to the specified organisation.\n    \"\"\"\n    label(\"The following users exists for {}:\".format(organisation.name))\n    for user in organisation.users.values():\n        sys.stdout.write(user.name + \"\\n\")\n@group_cli.command(\"list\")\n@click.argument(\"organisation\", type=ORGANISATION)\ndef list_groups(organisation):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "list_groups",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def list_groups(organisation):\n    \"\"\"\n    List all users belonging to the specified organisation.\n    \"\"\"\n    label(\"The following users exists for {}:\".format(organisation.name))\n    for group in organisation.groups.values():\n        sys.stdout.write(group.name + \"\\n\")\n@org_cli.command(\"list\")\ndef list_orgs():\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "list_orgs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def list_orgs():\n    \"\"\"\n    List available organisations\n    \"\"\"\n    label(\"The following organisations exist:\")\n    for org in Manager().orgs:\n        sys.stdout.write(org.name + \"\\n\")\n@user_cli.command(\"getkey\")\n@click.argument(\"organisation\", type=ORGANISATION)\n@click.argument(\"user\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "get_uuid",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def get_uuid(organisation, user):\n    \"\"\"\n    Get the UUID of the specified user belonging to the specified organisation.\n    \"\"\"\n    userobj = organisation.get_user(user)\n    if userobj is None:\n        msg = \"User {} doesn't exist in organisation {}.\"\n        sys.exit(msg.format(userobj.name, organisation.name))\n    label(\"User {} has the following UUID:\".format(userobj.name))\n    sys.stdout.write(user.key + \"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "export_user",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def export_user(organisation, user):\n    \"\"\"\n    Export user of the specified organisation as a series of shell commands\n    that can be used on the client side to easily import the certificates.\n    Note that the private key will be exported as well, so use this with care!\n    \"\"\"\n    userobj = organisation.get_user(user)\n    if userobj is None:\n        msg = \"User {} doesn't exist in organisation {}.\"\n        sys.exit(msg.format(user, organisation.name))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "add_org",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def add_org(name):\n    \"\"\"\n    Create an organisation with the specified name.\n    \"\"\"\n    if os.path.exists(mkpath(name)):\n        msg = \"Organisation with name {} already exists.\"\n        sys.exit(msg.format(name))\n    taskd_cmd(\"add\", \"org\", name)\n    mark_imperative(name)\n@org_cli.command(\"remove\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "del_org",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def del_org(name):\n    \"\"\"\n    Delete the organisation with the specified name.\n    All of the users and groups will be deleted as well and client certificates\n    will be revoked.\n    \"\"\"\n    Manager().del_org(name)\n    msg = (\"Organisation {} deleted. Be sure to restart the Taskserver\"\n           \" using 'systemctl restart taskserver.service' in order for\"\n           \" the certificate revocation to apply.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "add_user",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def add_user(organisation, user):\n    \"\"\"\n    Create a user for the given organisation along with a client certificate\n    and print the key of the new user.\n    The client certificate along with it's public key can be shown via the\n    'user export' subcommand.\n    \"\"\"\n    userobj = organisation.add_user(user)\n    if userobj is None:\n        msg = \"User {} already exists in organisation {}.\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "del_user",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def del_user(organisation, user):\n    \"\"\"\n    Delete a user from the given organisation.\n    This will also revoke the client certificate of the given user.\n    \"\"\"\n    organisation.del_user(user)\n    msg = (\"User {} deleted. Be sure to restart the Taskserver using\"\n           \" 'systemctl restart taskserver.service' in order for the\"\n           \" certificate revocation to apply.\")\n    click.echo(msg.format(user), err=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "add_group",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def add_group(organisation, group):\n    \"\"\"\n    Create a group for the given organisation.\n    \"\"\"\n    groupobj = organisation.add_group(group)\n    if groupobj is None:\n        msg = \"Group {} already exists in organisation {}.\"\n        sys.exit(msg.format(group, organisation))\n    else:\n        mark_imperative(organisation.name, \"groups\", groupobj.name)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "del_group",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def del_group(organisation, group):\n    \"\"\"\n    Delete a group from the given organisation.\n    \"\"\"\n    organisation.del_group(group)\n    click(\"Group {} deleted.\".format(group), err=True)\ndef add_or_delete(old, new, add_fun, del_fun):\n    \"\"\"\n    Given an 'old' and 'new' list, figure out the intersections and invoke\n    'add_fun' against every element that is not in the 'old' list and 'del_fun'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "add_or_delete",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def add_or_delete(old, new, add_fun, del_fun):\n    \"\"\"\n    Given an 'old' and 'new' list, figure out the intersections and invoke\n    'add_fun' against every element that is not in the 'old' list and 'del_fun'\n    against every element that is not in the 'new' list.\n    Returns a tuple where the first element is the list of elements that were\n    added and the second element consisting of elements that were deleted.\n    \"\"\"\n    old_set = set(old)\n    new_set = set(new)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "process_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "def process_json(json_file):\n    \"\"\"\n    Create and delete users, groups and organisations based on a JSON file.\n    The structure of this file is exactly the same as the\n    'services.taskserver.organisations' option of the NixOS module and is used\n    for declaratively adding and deleting users.\n    Hence this subcommand is not recommended outside of the scope of the NixOS\n    module.\n    \"\"\"\n    data = json.load(json_file)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "IS_AUTO_CONFIG",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "IS_AUTO_CONFIG = @isAutoConfig@ # NOQA\nCERTTOOL_COMMAND = \"@certtool@\"\nCERT_BITS = \"@certBits@\"\nCLIENT_EXPIRATION = \"@clientExpiration@\"\nCRL_EXPIRATION = \"@crlExpiration@\"\nTASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CERTTOOL_COMMAND",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CERTTOOL_COMMAND = \"@certtool@\"\nCERT_BITS = \"@certBits@\"\nCLIENT_EXPIRATION = \"@clientExpiration@\"\nCRL_EXPIRATION = \"@crlExpiration@\"\nTASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CERT_BITS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CERT_BITS = \"@certBits@\"\nCLIENT_EXPIRATION = \"@clientExpiration@\"\nCRL_EXPIRATION = \"@crlExpiration@\"\nTASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CLIENT_EXPIRATION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CLIENT_EXPIRATION = \"@clientExpiration@\"\nCRL_EXPIRATION = \"@crlExpiration@\"\nTASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CRL_EXPIRATION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CRL_EXPIRATION = \"@crlExpiration@\"\nTASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "TASKD_COMMAND",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "TASKD_COMMAND = \"@taskd@\"\nTASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "TASKD_DATA_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "TASKD_DATA_DIR = \"@dataDir@\"\nTASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "TASKD_USER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "TASKD_USER = \"@user@\"\nTASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "TASKD_GROUP",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "TASKD_GROUP = \"@group@\"\nFQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "FQDN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "FQDN = \"@fqdn@\"\nCA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CA_KEY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CA_KEY = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.key\")\nCA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CA_CERT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CA_CERT = os.path.join(TASKD_DATA_DIR, \"keys\", \"ca.cert\")\nCRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__\n    @property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "CRL_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "CRL_FILE = os.path.join(TASKD_DATA_DIR, \"keys\", \"server.crl\")\nRE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__\n    @property\n    def _lazy(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "RE_CONFIGUSER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "RE_CONFIGUSER = re.compile(r'^\\s*user\\s*=(.*)$')\nRE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__\n    @property\n    def _lazy(self):\n        val = getattr(self, name, None)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "RE_USERKEY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "RE_USERKEY = re.compile(r'New user key: (.+)$', re.MULTILINE)\ndef lazyprop(fun):\n    \"\"\"\n    Decorator which only evaluates the specified function when accessed.\n    \"\"\"\n    name = '_lazy_' + fun.__name__\n    @property\n    def _lazy(self):\n        val = getattr(self, name, None)\n        if val is None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "ORGANISATION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "peekOfCode": "ORGANISATION = OrganisationType()\n@click.group()\n@click.pass_context\ndef cli(ctx):\n    \"\"\"\n    Manage Taskserver users and certificates\n    \"\"\"\n    if not IS_AUTO_CONFIG:\n        return\n    for path in (CA_KEY, CA_CERT, CRL_FILE):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.misc.taskserver.helper-tool",
        "documentation": {}
    },
    {
        "label": "get_session_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "peekOfCode": "def get_session_file(session):\n    system_data_dirs = GLib.get_system_data_dirs()\n    session_dirs = OrderedSet(\n        os.path.join(data_dir, session)\n        for data_dir in system_data_dirs\n        for session in {\"wayland-sessions\", \"xsessions\"}\n    )\n    session_files = OrderedSet(\n        os.path.join(dir, session + \".desktop\")\n        for dir in session_dirs",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "documentation": {}
    },
    {
        "label": "is_session_xsession",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "peekOfCode": "def is_session_xsession(session_file):\n    return \"/xsessions/\" in session_file\ndef is_session_wayland(session_file):\n    return \"/wayland-sessions/\" in session_file\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Set session type for all normal users.\"\n    )\n    parser.add_argument(\"session\", help=\"Name of session to set.\")\n    args = parser.parse_args()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "documentation": {}
    },
    {
        "label": "is_session_wayland",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "peekOfCode": "def is_session_wayland(session_file):\n    return \"/wayland-sessions/\" in session_file\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Set session type for all normal users.\"\n    )\n    parser.add_argument(\"session\", help=\"Name of session to set.\")\n    args = parser.parse_args()\n    session = getattr(args, \"session\")\n    session_file = get_session_file(session)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(\n        description=\"Set session type for all normal users.\"\n    )\n    parser.add_argument(\"session\", help=\"Name of session to set.\")\n    args = parser.parse_args()\n    session = getattr(args, \"session\")\n    session_file = get_session_file(session)\n    user_manager = AccountsService.UserManager.get_default()\n    users = user_manager.list_users()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.services.x11.display-managers.set-session",
        "documentation": {}
    },
    {
        "label": "BootSpec",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "class BootSpec:\n    init: str\n    initrd: str\n    kernel: str\n    kernelParams: List[str]\n    label: str\n    system: str\n    toplevel: str\n    specialisations: Dict[str, \"BootSpec\"]\n    sortKey: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "SystemIdentifier",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "class SystemIdentifier(NamedTuple):\n    profile: str | None\n    generation: int\n    specialisation: str | None\ndef copy_if_not_exists(source: str, dest: str) -> None:\n    if not os.path.exists(dest):\n        shutil.copyfile(source, dest)\ndef generation_dir(profile: str | None, generation: int) -> str:\n    if profile:\n        return \"/nix/var/nix/profiles/system-profiles/%s-%d-link\" % (profile, generation)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "copy_if_not_exists",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def copy_if_not_exists(source: str, dest: str) -> None:\n    if not os.path.exists(dest):\n        shutil.copyfile(source, dest)\ndef generation_dir(profile: str | None, generation: int) -> str:\n    if profile:\n        return \"/nix/var/nix/profiles/system-profiles/%s-%d-link\" % (profile, generation)\n    else:\n        return \"/nix/var/nix/profiles/system-%d-link\" % (generation)\ndef system_dir(profile: str | None, generation: int, specialisation: str | None) -> str:\n    d = generation_dir(profile, generation)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "generation_dir",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def generation_dir(profile: str | None, generation: int) -> str:\n    if profile:\n        return \"/nix/var/nix/profiles/system-profiles/%s-%d-link\" % (profile, generation)\n    else:\n        return \"/nix/var/nix/profiles/system-%d-link\" % (generation)\ndef system_dir(profile: str | None, generation: int, specialisation: str | None) -> str:\n    d = generation_dir(profile, generation)\n    if specialisation:\n        return os.path.join(d, \"specialisation\", specialisation)\n    else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "system_dir",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def system_dir(profile: str | None, generation: int, specialisation: str | None) -> str:\n    d = generation_dir(profile, generation)\n    if specialisation:\n        return os.path.join(d, \"specialisation\", specialisation)\n    else:\n        return d\nBOOT_ENTRY = \"\"\"title {title}\nsort-key {sort_key}\nversion Generation {generation} {description}\nlinux {kernel}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "generation_conf_filename",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def generation_conf_filename(profile: str | None, generation: int, specialisation: str | None) -> str:\n    pieces = [\n        \"nixos\",\n        profile or None,\n        \"generation\",\n        str(generation),\n        f\"specialisation-{specialisation}\" if specialisation else None,\n    ]\n    return \"-\".join(p for p in pieces if p) + \".conf\"\ndef write_loader_conf(profile: str | None, generation: int, specialisation: str | None) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "write_loader_conf",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def write_loader_conf(profile: str | None, generation: int, specialisation: str | None) -> None:\n    with open(f\"{LOADER_CONF}.tmp\", 'w') as f:\n        if TIMEOUT != \"\":\n            f.write(f\"timeout {TIMEOUT}\\n\")\n        f.write(\"default %s\\n\" % generation_conf_filename(profile, generation, specialisation))\n        if not EDITOR:\n            f.write(\"editor 0\\n\")\n        f.write(f\"console-mode {CONSOLE_MODE}\\n\")\n        f.flush()\n        os.fsync(f.fileno())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "get_bootspec",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def get_bootspec(profile: str | None, generation: int) -> BootSpec:\n    system_directory = system_dir(profile, generation, None)\n    boot_json_path = os.path.realpath(\"%s/%s\" % (system_directory, \"boot.json\"))\n    if os.path.isfile(boot_json_path):\n        boot_json_f = open(boot_json_path, 'r')\n        bootspec_json = json.load(boot_json_f)\n    else:\n        boot_json_str = subprocess.check_output([\n        f\"{BOOTSPEC_TOOLS}/bin/synthesize\",\n        \"--version\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "bootspec_from_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def bootspec_from_json(bootspec_json: Dict) -> BootSpec:\n    specialisations = bootspec_json['org.nixos.specialisation.v1']\n    specialisations = {k: bootspec_from_json(v) for k, v in specialisations.items()}\n    systemdBootExtension = bootspec_json.get('org.nixos.systemd-boot', {})\n    sortKey = systemdBootExtension.get('sortKey', 'nixos')\n    return BootSpec(\n        **bootspec_json['org.nixos.bootspec.v1'],\n        specialisations=specialisations,\n        sortKey=sortKey\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "copy_from_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def copy_from_file(file: str, dry_run: bool = False) -> str:\n    store_file_path = os.path.realpath(file)\n    suffix = os.path.basename(store_file_path)\n    store_dir = os.path.basename(os.path.dirname(store_file_path))\n    efi_file_path = f\"{NIXOS_DIR}/{store_dir}-{suffix}.efi\"\n    if not dry_run:\n        copy_if_not_exists(store_file_path, f\"{BOOT_MOUNT_POINT}{efi_file_path}\")\n    return efi_file_path\ndef write_entry(profile: str | None, generation: int, specialisation: str | None,\n                machine_id: str, bootspec: BootSpec, current: bool) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "write_entry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def write_entry(profile: str | None, generation: int, specialisation: str | None,\n                machine_id: str, bootspec: BootSpec, current: bool) -> None:\n    if specialisation:\n        bootspec = bootspec.specialisations[specialisation]\n    kernel = copy_from_file(bootspec.kernel)\n    initrd = copy_from_file(bootspec.initrd)\n    title = \"{name}{profile}{specialisation}\".format(\n        name=DISTRO_NAME,\n        profile=\" [\" + profile + \"]\" if profile else \"\",\n        specialisation=\" (%s)\" % specialisation if specialisation else \"\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "get_generations",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def get_generations(profile: str | None = None) -> list[SystemIdentifier]:\n    gen_list = subprocess.check_output([\n        f\"{NIX}/bin/nix-env\",\n        \"--list-generations\",\n        \"-p\",\n        \"/nix/var/nix/profiles/%s\" % (\"system-profiles/\" + profile if profile else \"system\")],\n        universal_newlines=True)\n    gen_lines = gen_list.split('\\n')\n    gen_lines.pop()\n    configurationLimit = CONFIGURATION_LIMIT",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "remove_old_entries",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def remove_old_entries(gens: list[SystemIdentifier]) -> None:\n    rex_profile = re.compile(r\"^\" + re.escape(BOOT_MOUNT_POINT) + \"/loader/entries/nixos-(.*)-generation-.*\\.conf$\")\n    rex_generation = re.compile(r\"^\" + re.escape(BOOT_MOUNT_POINT) + \"/loader/entries/nixos.*-generation-([0-9]+)(-specialisation-.*)?\\.conf$\")\n    known_paths = []\n    for gen in gens:\n        bootspec = get_bootspec(gen.profile, gen.generation)\n        known_paths.append(copy_from_file(bootspec.kernel, True))\n        known_paths.append(copy_from_file(bootspec.initrd, True))\n    for path in glob.iglob(f\"{BOOT_MOUNT_POINT}/loader/entries/nixos*-generation-[1-9]*.conf\"):\n        if rex_profile.match(path):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "cleanup_esp",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def cleanup_esp() -> None:\n    for path in glob.iglob(f\"{EFI_SYS_MOUNT_POINT}/loader/entries/nixos*\"):\n        os.unlink(path)\n    if os.path.isdir(f\"{EFI_SYS_MOUNT_POINT}/{NIXOS_DIR}\"):\n        shutil.rmtree(f\"{EFI_SYS_MOUNT_POINT}/{NIXOS_DIR}\")\ndef get_profiles() -> list[str]:\n    if os.path.isdir(\"/nix/var/nix/profiles/system-profiles/\"):\n        return [x\n            for x in os.listdir(\"/nix/var/nix/profiles/system-profiles/\")\n            if not x.endswith(\"-link\")]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "get_profiles",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def get_profiles() -> list[str]:\n    if os.path.isdir(\"/nix/var/nix/profiles/system-profiles/\"):\n        return [x\n            for x in os.listdir(\"/nix/var/nix/profiles/system-profiles/\")\n            if not x.endswith(\"-link\")]\n    else:\n        return []\ndef install_bootloader(args: argparse.Namespace) -> None:\n    try:\n        with open(\"/etc/machine-id\") as machine_file:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "install_bootloader",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def install_bootloader(args: argparse.Namespace) -> None:\n    try:\n        with open(\"/etc/machine-id\") as machine_file:\n            machine_id = machine_file.readlines()[0]\n    except IOError as e:\n        if e.errno != errno.ENOENT:\n            raise\n        # Since systemd version 232 a machine ID is required and it might not\n        # be there on newly installed systems, so let's generate one so that\n        # bootctl can find it and we can also pass it to write_entry() later.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(description=f\"Update {DISTRO_NAME}-related systemd-boot files\")\n    parser.add_argument('default_config', metavar='DEFAULT-CONFIG', help=f\"The default {DISTRO_NAME} config to boot\")\n    args = parser.parse_args()\n    subprocess.check_call(CHECK_MOUNTPOINTS)\n    try:\n        install_bootloader(args)\n    finally:\n        # Since fat32 provides little recovery facilities after a crash,\n        # it can leave the system in an unbootable state, when a crash/outage",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "EFI_SYS_MOUNT_POINT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "EFI_SYS_MOUNT_POINT = \"@efiSysMountPoint@\"\nBOOT_MOUNT_POINT = \"@bootMountPoint@\"\nLOADER_CONF = f\"{EFI_SYS_MOUNT_POINT}/loader/loader.conf\"  # Always stored on the ESP\nNIXOS_DIR = \"@nixosDir@\"\nTIMEOUT = \"@timeout@\"\nEDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "BOOT_MOUNT_POINT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "BOOT_MOUNT_POINT = \"@bootMountPoint@\"\nLOADER_CONF = f\"{EFI_SYS_MOUNT_POINT}/loader/loader.conf\"  # Always stored on the ESP\nNIXOS_DIR = \"@nixosDir@\"\nTIMEOUT = \"@timeout@\"\nEDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "LOADER_CONF",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "LOADER_CONF = f\"{EFI_SYS_MOUNT_POINT}/loader/loader.conf\"  # Always stored on the ESP\nNIXOS_DIR = \"@nixosDir@\"\nTIMEOUT = \"@timeout@\"\nEDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "NIXOS_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "NIXOS_DIR = \"@nixosDir@\"\nTIMEOUT = \"@timeout@\"\nEDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "TIMEOUT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "TIMEOUT = \"@timeout@\"\nEDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "EDITOR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "EDITOR = \"@editor@\" == \"1\"\nCONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "CONSOLE_MODE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "CONSOLE_MODE = \"@consoleMode@\"\nBOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "BOOTSPEC_TOOLS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "BOOTSPEC_TOOLS = \"@bootspecTools@\"\nDISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "DISTRO_NAME",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "DISTRO_NAME = \"@distroName@\"\nNIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "NIX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "NIX = \"@nix@\"\nSYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "SYSTEMD",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "SYSTEMD = \"@systemd@\"\nCONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "CONFIGURATION_LIMIT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "CONFIGURATION_LIMIT = int(\"@configurationLimit@\")\nCAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str\n    kernel: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "CAN_TOUCH_EFI_VARIABLES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "CAN_TOUCH_EFI_VARIABLES = \"@canTouchEfiVariables@\"\nGRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str\n    kernel: str\n    kernelParams: List[str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "GRACEFUL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "GRACEFUL = \"@graceful@\"\nCOPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str\n    kernel: str\n    kernelParams: List[str]\n    label: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "COPY_EXTRA_FILES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "COPY_EXTRA_FILES = \"@copyExtraFiles@\"\nCHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str\n    kernel: str\n    kernelParams: List[str]\n    label: str\n    system: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "CHECK_MOUNTPOINTS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "CHECK_MOUNTPOINTS = \"@checkMountpoints@\"\n@dataclass\nclass BootSpec:\n    init: str\n    initrd: str\n    kernel: str\n    kernelParams: List[str]\n    label: str\n    system: str\n    toplevel: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "libc",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "libc = ctypes.CDLL(\"libc.so.6\")\nclass SystemIdentifier(NamedTuple):\n    profile: str | None\n    generation: int\n    specialisation: str | None\ndef copy_if_not_exists(source: str, dest: str) -> None:\n    if not os.path.exists(dest):\n        shutil.copyfile(source, dest)\ndef generation_dir(profile: str | None, generation: int) -> str:\n    if profile:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "BOOT_ENTRY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "peekOfCode": "BOOT_ENTRY = \"\"\"title {title}\nsort-key {sort_key}\nversion Generation {generation} {description}\nlinux {kernel}\ninitrd {initrd}\noptions {kernel_params}\n\"\"\"\ndef generation_conf_filename(profile: str | None, generation: int, specialisation: str | None) -> str:\n    pieces = [\n        \"nixos\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.boot.loader.systemd-boot.systemd-boot-builder",
        "documentation": {}
    },
    {
        "label": "FileType",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "class FileType(Enum):\n    \"\"\"The filetype as defined by the `st_mode` stat field in octal\n    You can check the st_mode stat field of a path in Python with\n    `oct(os.stat(\"/path/\").st_mode)`\n    \"\"\"\n    directory = \"4\"\n    file = \"10\"\n    symlink = \"12\"\nclass ComposefsPath:\n    path: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "ComposefsPath",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "class ComposefsPath:\n    path: str\n    size: int\n    filetype: FileType\n    mode: str\n    uid: str\n    gid: str\n    payload: str\n    rdev: str = \"0\"\n    nlink: int = 1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "eprint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "def eprint(*args: Any, **kwargs: Any) -> None:\n    print(*args, **kwargs, file=sys.stderr)\ndef normalize_path(path: str) -> str:\n    return str(\"/\" + os.path.normpath(path).lstrip(\"/\"))\ndef leading_directories(path: str) -> list[str]:\n    \"\"\"Return the leading directories of path\n    Given the path \"alsa/conf.d/50-pipewire.conf\", for example, this function\n    returns `[ \"alsa\", \"alsa/conf.d\" ]`.\n    \"\"\"\n    parents = list(Path(path).parents)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "normalize_path",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "def normalize_path(path: str) -> str:\n    return str(\"/\" + os.path.normpath(path).lstrip(\"/\"))\ndef leading_directories(path: str) -> list[str]:\n    \"\"\"Return the leading directories of path\n    Given the path \"alsa/conf.d/50-pipewire.conf\", for example, this function\n    returns `[ \"alsa\", \"alsa/conf.d\" ]`.\n    \"\"\"\n    parents = list(Path(path).parents)\n    parents.reverse()\n    # remove the implicit `.` from the start of a relative path or `/` from an",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "leading_directories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "def leading_directories(path: str) -> list[str]:\n    \"\"\"Return the leading directories of path\n    Given the path \"alsa/conf.d/50-pipewire.conf\", for example, this function\n    returns `[ \"alsa\", \"alsa/conf.d\" ]`.\n    \"\"\"\n    parents = list(Path(path).parents)\n    parents.reverse()\n    # remove the implicit `.` from the start of a relative path or `/` from an\n    # absolute path\n    del parents[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "add_leading_directories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "def add_leading_directories(\n    target: str, attrs: Attrs, paths: dict[str, ComposefsPath]\n) -> None:\n    \"\"\"Add the leading directories of a target path to the composefs paths\n    mkcomposefs expects that all leading directories are explicitly listed in\n    the dump file. Given the path \"alsa/conf.d/50-pipewire.conf\", for example,\n    this function adds \"alsa\" and \"alsa/conf.d\" to the composefs paths.\n    \"\"\"\n    path_components = leading_directories(target)\n    for component in path_components:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "def main() -> None:\n    \"\"\"Build a composefs dump from a Json config\n    This config describes the files that the final composefs image is supposed\n    to contain.\n    \"\"\"\n    config_file = sys.argv[1]\n    if not config_file:\n        eprint(\"No config file was supplied.\")\n        sys.exit(1)\n    with open(config_file, \"rb\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "Attrs",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "peekOfCode": "Attrs = dict[str, Any]\nclass FileType(Enum):\n    \"\"\"The filetype as defined by the `st_mode` stat field in octal\n    You can check the st_mode stat field of a path in Python with\n    `oct(os.stat(\"/path/\").st_mode)`\n    \"\"\"\n    directory = \"4\"\n    file = \"10\"\n    symlink = \"12\"\nclass ComposefsPath:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.system.etc.build-composefs-dump",
        "documentation": {}
    },
    {
        "label": "chars_to_inverted_class",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "def chars_to_inverted_class(letters):\n    assert len(letters) > 0\n    letters = list(letters)\n    s = \"[^\"\n    if \"]\" in letters:\n        s += \"]\"\n        letters.remove(\"]\")\n    final = \"\"\n    if \"-\" in letters:\n        final = \"-\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "strings_to_inverted_regex",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "def strings_to_inverted_regex(strings):\n    s = \"(\"\n    # Match anything that starts with the wrong character\n    chars = defaultdict(list)\n    for item in strings:\n        if item != \"\":\n            chars[item[0]].append(item[1:])\n    if len(chars) == 0:\n        s += match_end\n    else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "MATCH_EXACTLY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "MATCH_EXACTLY = \".+\"\n# Produce the negation of ^a\nMATCH_STRING_PREFIX = \"//X\" # //X should be epsilon regex instead. Not supported??\n# Produce the negation of ^a/?\nMATCH_SUBPATHS = \"[^/].*$\"\n# match_end = MATCH_SUBPATHS\nmatch_end = MATCH_STRING_PREFIX\n# match_end = MATCH_EXACTLY\ndef chars_to_inverted_class(letters):\n    assert len(letters) > 0",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "MATCH_STRING_PREFIX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "MATCH_STRING_PREFIX = \"//X\" # //X should be epsilon regex instead. Not supported??\n# Produce the negation of ^a/?\nMATCH_SUBPATHS = \"[^/].*$\"\n# match_end = MATCH_SUBPATHS\nmatch_end = MATCH_STRING_PREFIX\n# match_end = MATCH_EXACTLY\ndef chars_to_inverted_class(letters):\n    assert len(letters) > 0\n    letters = list(letters)\n    s = \"[^\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "MATCH_SUBPATHS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "MATCH_SUBPATHS = \"[^/].*$\"\n# match_end = MATCH_SUBPATHS\nmatch_end = MATCH_STRING_PREFIX\n# match_end = MATCH_EXACTLY\ndef chars_to_inverted_class(letters):\n    assert len(letters) > 0\n    letters = list(letters)\n    s = \"[^\"\n    if \"]\" in letters:\n        s += \"]\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "match_end",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "peekOfCode": "match_end = MATCH_STRING_PREFIX\n# match_end = MATCH_EXACTLY\ndef chars_to_inverted_class(letters):\n    assert len(letters) > 0\n    letters = list(letters)\n    s = \"[^\"\n    if \"]\" in letters:\n        s += \"]\"\n        letters.remove(\"]\")\n    final = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.modules.virtualisation.includes-to-excludes",
        "documentation": {}
    },
    {
        "label": "ReqHandler",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "class ReqHandler(BaseHTTPRequestHandler):\n    def _send_json_ok(self, data: dict):\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        out = json.dumps(data).encode()\n        w(out)\n        self.wfile.write(out)\n    def _send_json_success(self, success=True):\n        self.send_response(200)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "w",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "def w(msg: bytes):\n    sys.stderr.write(f\"{msg}\\n\")\n    sys.stderr.flush()\ndef gen_fingerprint(pubkey: str):\n    decoded_key = base64.b64decode(pubkey.encode(\"ascii\").split()[1])\n    return hashlib.sha256(decoded_key).hexdigest()\ndef gen_email(username: str):\n    \"\"\"username seems to be a 21 characters long number string, so mimic that in a reproducible way\"\"\"\n    return str(int(hashlib.sha256(username.encode()).hexdigest(), 16))[0:21]\ndef gen_mockuser(username: str, uid: str, gid: str, home_directory: str, snakeoil_pubkey: str) -> Dict:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "gen_fingerprint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "def gen_fingerprint(pubkey: str):\n    decoded_key = base64.b64decode(pubkey.encode(\"ascii\").split()[1])\n    return hashlib.sha256(decoded_key).hexdigest()\ndef gen_email(username: str):\n    \"\"\"username seems to be a 21 characters long number string, so mimic that in a reproducible way\"\"\"\n    return str(int(hashlib.sha256(username.encode()).hexdigest(), 16))[0:21]\ndef gen_mockuser(username: str, uid: str, gid: str, home_directory: str, snakeoil_pubkey: str) -> Dict:\n    snakeoil_pubkey_fingerprint = gen_fingerprint(snakeoil_pubkey)\n    # seems to be a 21 characters long numberstring, so mimic that in a reproducible way\n    email = gen_email(username)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "gen_email",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "def gen_email(username: str):\n    \"\"\"username seems to be a 21 characters long number string, so mimic that in a reproducible way\"\"\"\n    return str(int(hashlib.sha256(username.encode()).hexdigest(), 16))[0:21]\ndef gen_mockuser(username: str, uid: str, gid: str, home_directory: str, snakeoil_pubkey: str) -> Dict:\n    snakeoil_pubkey_fingerprint = gen_fingerprint(snakeoil_pubkey)\n    # seems to be a 21 characters long numberstring, so mimic that in a reproducible way\n    email = gen_email(username)\n    return {\n        \"loginProfiles\": [\n            {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "gen_mockuser",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "def gen_mockuser(username: str, uid: str, gid: str, home_directory: str, snakeoil_pubkey: str) -> Dict:\n    snakeoil_pubkey_fingerprint = gen_fingerprint(snakeoil_pubkey)\n    # seems to be a 21 characters long numberstring, so mimic that in a reproducible way\n    email = gen_email(username)\n    return {\n        \"loginProfiles\": [\n            {\n                \"name\": email,\n                \"posixAccounts\": [\n                    {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "SNAKEOIL_PUBLIC_KEY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "peekOfCode": "SNAKEOIL_PUBLIC_KEY = os.environ['SNAKEOIL_PUBLIC_KEY']\nMOCKUSER=\"mockuser_nixos_org\"\nMOCKADMIN=\"mockadmin_nixos_org\"\ndef w(msg: bytes):\n    sys.stderr.write(f\"{msg}\\n\")\n    sys.stderr.flush()\ndef gen_fingerprint(pubkey: str):\n    decoded_key = base64.b64decode(pubkey.encode(\"ascii\").split()[1])\n    return hashlib.sha256(decoded_key).hexdigest()\ndef gen_email(username: str):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.google-oslogin.server",
        "documentation": {}
    },
    {
        "label": "expected_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "expected_lines = {\n    \"account required pam_unix.so\",\n    \"account sufficient @@pam_krb5@@/lib/security/pam_krb5.so\",\n    \"auth [default=die success=done] @@pam_ccreds@@/lib/security/pam_ccreds.so action=validate use_first_pass\",\n    \"auth [default=ignore success=1 service_err=reset] @@pam_krb5@@/lib/security/pam_krb5.so use_first_pass\",\n    \"auth required pam_deny.so\",\n    \"auth sufficient @@pam_ccreds@@/lib/security/pam_ccreds.so action=store use_first_pass\",\n    \"auth sufficient pam_rootok.so\",\n    \"auth sufficient pam_unix.so likeauth try_first_pass\",\n    \"password sufficient @@pam_krb5@@/lib/security/pam_krb5.so use_first_pass\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "actual_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "actual_lines = set(machine.succeed(\"cat /etc/pam.d/chfn\").splitlines())\nstripped_lines = set([line.split(\"#\")[0].rstrip() for line in actual_lines])\nmissing_lines = expected_lines - stripped_lines\nextra_lines = stripped_lines - expected_lines\nnon_functional_lines = set([line for line in extra_lines if line == \"\"])\nunexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "stripped_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "stripped_lines = set([line.split(\"#\")[0].rstrip() for line in actual_lines])\nmissing_lines = expected_lines - stripped_lines\nextra_lines = stripped_lines - expected_lines\nnon_functional_lines = set([line for line in extra_lines if line == \"\"])\nunexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "missing_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "missing_lines = expected_lines - stripped_lines\nextra_lines = stripped_lines - expected_lines\nnon_functional_lines = set([line for line in extra_lines if line == \"\"])\nunexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "extra_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "extra_lines = stripped_lines - expected_lines\nnon_functional_lines = set([line for line in extra_lines if line == \"\"])\nunexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "non_functional_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "non_functional_lines = set([line for line in extra_lines if line == \"\"])\nunexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "unexpected_functional_lines",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "peekOfCode": "unexpected_functional_lines = extra_lines - non_functional_lines\nwith subtest(\"All expected lines are in the file\"):\n    assert not missing_lines, f\"Missing lines: {missing_lines}\"\nwith subtest(\"All remaining lines are empty or comments\"):\n    assert not unexpected_functional_lines, f\"Unexpected lines: {unexpected_functional_lines}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.pam.test_chfn",
        "documentation": {}
    },
    {
        "label": "explode_col",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "def explode_col(weight):\n    return int(weight//10) * [10.0] + ([] if weight%10==0 else [weight%10])\nspark = SparkSession.builder.getOrCreate()\ndataSchema = [\n    StructField(\"feature_1\", FloatType()),\n    StructField(\"feature_2\", FloatType()),\n    StructField(\"bias_weight\", FloatType())\n]\ndata = [\n    Row(0.1, 0.2, 10.32),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "spark",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "spark = SparkSession.builder.getOrCreate()\ndataSchema = [\n    StructField(\"feature_1\", FloatType()),\n    StructField(\"feature_2\", FloatType()),\n    StructField(\"bias_weight\", FloatType())\n]\ndata = [\n    Row(0.1, 0.2, 10.32),\n    Row(0.32, 1.43, 12.8),\n    Row(1.28, 1.12, 0.23)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "dataSchema",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "dataSchema = [\n    StructField(\"feature_1\", FloatType()),\n    StructField(\"feature_2\", FloatType()),\n    StructField(\"bias_weight\", FloatType())\n]\ndata = [\n    Row(0.1, 0.2, 10.32),\n    Row(0.32, 1.43, 12.8),\n    Row(1.28, 1.12, 0.23)\n]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "data = [\n    Row(0.1, 0.2, 10.32),\n    Row(0.32, 1.43, 12.8),\n    Row(1.28, 1.12, 0.23)\n]\ndf = spark.createDataFrame(spark.sparkContext.parallelize(data), StructType(dataSchema))\nnormalizing_constant = 100\nsum_bias_weight = df.select(F.sum('bias_weight')).collect()[0][0]\nnormalizing_factor = normalizing_constant / sum_bias_weight\ndf = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df = spark.createDataFrame(spark.sparkContext.parallelize(data), StructType(dataSchema))\nnormalizing_constant = 100\nsum_bias_weight = df.select(F.sum('bias_weight')).collect()[0][0]\nnormalizing_factor = normalizing_constant / sum_bias_weight\ndf = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)\ndf = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "normalizing_constant",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "normalizing_constant = 100\nsum_bias_weight = df.select(F.sum('bias_weight')).collect()[0][0]\nnormalizing_factor = normalizing_constant / sum_bias_weight\ndf = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)\ndf = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "sum_bias_weight",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "sum_bias_weight = df.select(F.sum('bias_weight')).collect()[0][0]\nnormalizing_factor = normalizing_constant / sum_bias_weight\ndf = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)\ndf = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "normalizing_factor",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "normalizing_factor = normalizing_constant / sum_bias_weight\ndf = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)\ndf = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df = df.withColumn('normalized_bias_weight', df.bias_weight * normalizing_factor)\ndf = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df = df.drop('bias_weight')\ndf = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df = df.withColumnRenamed('normalized_bias_weight', 'bias_weight')\nmy_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "my_udf",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "my_udf = udf(lambda x: explode_col(x), ArrayType(FloatType()))\ndf1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df1",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df1 = df.withColumn('explode_val', my_udf(df.bias_weight))\ndf1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df1",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df1 = df1.withColumn(\"explode_val_1\", explode(df1.explode_val)).drop(\"explode_val\")\ndf1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "df1",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "peekOfCode": "df1 = df1.drop('bias_weight').withColumnRenamed('explode_val_1', 'bias_weight')\ndf1.show()\nassert(df1.count() == 12)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.spark.spark_sample",
        "documentation": {}
    },
    {
        "label": "Accessibility",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "peekOfCode": "class Accessibility(IntEnum):\n    \"\"\"\n    The level of accessibility we have on a file or directory.\n    This is needed to assess the attack surface on the file system namespace we\n    have within a confined service. Higher levels mean more permissions for the\n    user and thus a bigger attack surface.\n    \"\"\"\n    NONE = 0\n    # Directories can be listed or files can be read.\n    READABLE = 1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "documentation": {}
    },
    {
        "label": "is_special_fs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "peekOfCode": "def is_special_fs(path: Path) -> bool:\n    \"\"\"\n    Check whether the given path truly is a special file system such as procfs\n    or sysfs.\n    \"\"\"\n    try:\n        if path == Path('/proc'):\n            return (path / 'version').read_text().startswith('Linux')\n        elif path == Path('/sys'):\n            return b'Linux' in (path / 'kernel' / 'notes').read_bytes()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "documentation": {}
    },
    {
        "label": "is_empty_dir",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "peekOfCode": "def is_empty_dir(path: Path) -> bool:\n    try:\n        next(path.iterdir())\n        return False\n    except (StopIteration, PermissionError):\n        return True\ndef _assert_permissions_in_directory(\n    directory: Path,\n    accessibility: Accessibility,\n    subdirs: dict[Path, Accessibility],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "documentation": {}
    },
    {
        "label": "assert_permissions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "peekOfCode": "def assert_permissions(subdirs: dict[str, Accessibility]) -> None:\n    \"\"\"\n    Recursively check whether the file system conforms to the accessibility\n    specification we specified via 'subdirs'.\n    \"\"\"\n    root = Path('/')\n    absolute_subdirs = {root / p: a for p, a in subdirs.items()}\n    _assert_permissions_in_directory(\n        root,\n        Accessibility.WRITABLE if os.getuid() == 0 else Accessibility.READABLE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.nixos.tests.systemd-confinement.checkperms",
        "documentation": {}
    },
    {
        "label": "fmt_grammar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "peekOfCode": "def fmt_grammar(grammar: str) -> str:\n    return \"tree-sitter-\" + grammar\ndef eval_expr(nixpkgs: str, expr: str) -> Any:\n    p = subprocess.run(\n        [\n            \"nix-instantiate\",\n            \"--json\",\n            \"--eval\",\n            \"--expr\",\n            (\"with import %s {}; %s\" % (nixpkgs, expr)),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "documentation": {}
    },
    {
        "label": "eval_expr",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "peekOfCode": "def eval_expr(nixpkgs: str, expr: str) -> Any:\n    p = subprocess.run(\n        [\n            \"nix-instantiate\",\n            \"--json\",\n            \"--eval\",\n            \"--expr\",\n            (\"with import %s {}; %s\" % (nixpkgs, expr)),\n        ],\n        check=True,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "documentation": {}
    },
    {
        "label": "check_grammar_exists",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "peekOfCode": "def check_grammar_exists(nixpkgs: str, grammar: str) -> bool:\n    return eval_expr(\n        nixpkgs, f'lib.hasAttr \"{fmt_grammar(grammar)}\" tree-sitter-grammars'\n    )\ndef build_attr(nixpkgs, attr: str) -> str:\n    return (\n        subprocess.run(\n            [\"nix-build\", \"--no-out-link\", nixpkgs, \"-A\", attr],\n            check=True,\n            stdout=subprocess.PIPE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "documentation": {}
    },
    {
        "label": "build_attr",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "peekOfCode": "def build_attr(nixpkgs, attr: str) -> str:\n    return (\n        subprocess.run(\n            [\"nix-build\", \"--no-out-link\", nixpkgs, \"-A\", attr],\n            check=True,\n            stdout=subprocess.PIPE,\n        )\n        .stdout.decode()\n        .strip()\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tree-sitter-langs.update-defaults",
        "documentation": {}
    },
    {
        "label": "eval_drv",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "peekOfCode": "def eval_drv(nixpkgs: str, expr: str) -> Any:\n    expr = \"\\n\".join(\n        (\n            \"with (import %s {});\" % nixpkgs,\n            expr,\n        )\n    )\n    with tempfile.NamedTemporaryFile(mode=\"w\") as f:\n        f.write(dedent(expr))\n        f.flush()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "documentation": {}
    },
    {
        "label": "get_src",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "peekOfCode": "def get_src(tag_name: str) -> Dict[str, str]:\n    p = subprocess.run(\n        [\n            \"nix-prefetch-github\",\n            \"--rev\",\n            tag_name,\n            \"--json\",\n            \"emacs-tree-sitter\",\n            \"elisp-tree-sitter\",\n        ],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "documentation": {}
    },
    {
        "label": "get_cargo_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "peekOfCode": "def get_cargo_hash(drv_path: str):\n    # Note: No check=True since we expect this command to fail\n    p = subprocess.run([\"nix-store\", \"-r\", drv_path], stderr=subprocess.PIPE)\n    stderr = p.stderr.decode()\n    lines = iter(stderr.split(\"\\n\"))\n    for l in lines:\n        if l.startswith(\"error: hash mismatch in fixed-output derivation\"):\n            break\n    else:\n        raise ValueError(\"Did not find expected hash mismatch message\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.emacs.elisp-packages.manual-packages.tsc.update",
        "documentation": {}
    },
    {
        "label": "one_or_more",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)\n    updates_response.raise_for_status()\n    root = xmltodict.parse(updates_response.text)\n    products = root[\"products\"][\"product\"]\n    return {\n        channel[\"@name\"]: channel",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "download_channels",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)\n    updates_response.raise_for_status()\n    root = xmltodict.parse(updates_response.text)\n    products = root[\"products\"][\"product\"]\n    return {\n        channel[\"@name\"]: channel\n        for product in products\n        if \"channel\" in product",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "build_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def build_version(build):\n    build_number = build[\"@fullNumber\"] if \"@fullNumber\" in build else build[\"@number\"]\n    return version.parse(build_number)\ndef latest_build(channel):\n    builds = one_or_more(channel[\"build\"])\n    latest = max(builds, key=build_version)\n    return latest\ndef download_sha256(url):\n    url = f\"{url}.sha256\"\n    download_response = requests.get(url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "latest_build",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def latest_build(channel):\n    builds = one_or_more(channel[\"build\"])\n    latest = max(builds, key=build_version)\n    return latest\ndef download_sha256(url):\n    url = f\"{url}.sha256\"\n    download_response = requests.get(url)\n    download_response.raise_for_status()\n    return download_response.content.decode('UTF-8').split(' ')[0]\nchannels = download_channels()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "download_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def download_sha256(url):\n    url = f\"{url}.sha256\"\n    download_response = requests.get(url)\n    download_response.raise_for_status()\n    return download_response.content.decode('UTF-8').split(' ')[0]\nchannels = download_channels()\ndef update_product(name, product):\n    update_channel = product[\"update-channel\"]\n    logging.info(\"Updating %s\", name)\n    channel = channels.get(update_channel)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "update_product",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def update_product(name, product):\n    update_channel = product[\"update-channel\"]\n    logging.info(\"Updating %s\", name)\n    channel = channels.get(update_channel)\n    if channel is None:\n        logging.error(\"Failed to find channel %s.\", update_channel)\n        logging.error(\"Check that the update-channel in %s matches the name in %s\", versions_file_path, updates_url)\n    else:\n        try:\n            build = latest_build(channel)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "update_products",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "def update_products(products):\n    for name, product in products.items():\n        update_product(name, product)\nwith open(versions_file_path, \"r\") as versions_file:\n    versions = json.load(versions_file)\nfor products in versions.values():\n    update_products(products)\nwith open(versions_file_path, \"w\") as versions_file:\n    json.dump(versions, versions_file, indent=2)\n    versions_file.write(\"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "updates_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "updates_url = \"https://www.jetbrains.com/updates/updates.xml\"\ncurrent_path = pathlib.Path(__file__).parent\nversions_file_path = current_path.joinpath(\"versions.json\").resolve()\nfromVersions = {}\ntoVersions = {}\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\ndef one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "current_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "current_path = pathlib.Path(__file__).parent\nversions_file_path = current_path.joinpath(\"versions.json\").resolve()\nfromVersions = {}\ntoVersions = {}\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\ndef one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "versions_file_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "versions_file_path = current_path.joinpath(\"versions.json\").resolve()\nfromVersions = {}\ntoVersions = {}\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\ndef one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)\n    updates_response.raise_for_status()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "fromVersions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "fromVersions = {}\ntoVersions = {}\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\ndef one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)\n    updates_response.raise_for_status()\n    root = xmltodict.parse(updates_response.text)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "toVersions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "toVersions = {}\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\ndef one_or_more(x):\n    return x if isinstance(x, list) else [x]\ndef download_channels():\n    logging.info(\"Checking for updates from %s\", updates_url)\n    updates_response = requests.get(updates_url)\n    updates_response.raise_for_status()\n    root = xmltodict.parse(updates_response.text)\n    products = root[\"products\"][\"product\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "channels",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "channels = download_channels()\ndef update_product(name, product):\n    update_channel = product[\"update-channel\"]\n    logging.info(\"Updating %s\", name)\n    channel = channels.get(update_channel)\n    if channel is None:\n        logging.error(\"Failed to find channel %s.\", update_channel)\n        logging.error(\"Check that the update-channel in %s matches the name in %s\", versions_file_path, updates_url)\n    else:\n        try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "plugin_script",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "peekOfCode": "plugin_script = current_path.joinpath(\"../plugins/update_plugins.py\").resolve()\nsubprocess.call(plugin_script)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.bin.update_bin",
        "documentation": {}
    },
    {
        "label": "tokenize_stream",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def tokenize_stream(stream):\n    for item in stream:\n        if item in TOKENS:\n            yield TOKENS[item], 0\n        elif item.isalpha():\n            for char in item:\n                yield 90, ord(char) - 96\n        elif item.isdigit():\n            yield 100, int(item)\ndef split(version_string: str):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "split",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def split(version_string: str):\n    prev_type = None\n    block = \"\"\n    for char in version_string:\n        if char.isdigit():\n            cur_type = \"number\"\n        elif char.isalpha():\n            cur_type = \"letter\"\n        else:\n            cur_type = \"other\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "tokenize_string",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def tokenize_string(version_string: str):\n    return list(tokenize_stream(split(version_string)))\ndef pick_newest(ver1: str, ver2: str) -> str:\n    if ver1 is None or ver1 == ver2:\n        return ver2\n    if ver2 is None:\n        return ver1\n    presort = [tokenize_string(ver1), tokenize_string(ver2)]\n    postsort = sorted(presort)\n    if presort == postsort:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "pick_newest",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def pick_newest(ver1: str, ver2: str) -> str:\n    if ver1 is None or ver1 == ver2:\n        return ver2\n    if ver2 is None:\n        return ver1\n    presort = [tokenize_string(ver1), tokenize_string(ver2)]\n    postsort = sorted(presort)\n    if presort == postsort:\n        return ver2\n    else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "is_build_older",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def is_build_older(ver1: str, ver2: str) -> int:\n    ver1 = [int(i) for i in ver1.replace(\"*\", str(SNAPSHOT_VALUE)).split(\".\")]\n    ver2 = [int(i) for i in ver2.replace(\"*\", str(SNAPSHOT_VALUE)).split(\".\")]\n    for i in range(min(len(ver1), len(ver2))):\n        if ver1[i] == ver2[i] and ver1[i] == SNAPSHOT_VALUE:\n            return 0\n        if ver1[i] == SNAPSHOT_VALUE:\n            return 1\n        if ver2[i] == SNAPSHOT_VALUE:\n            return -1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "is_compatible",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def is_compatible(build, since, until) -> bool:\n    return (not since or is_build_older(since, build) < 0) and (not until or 0 < is_build_older(until, build))\ndef get_newest_compatible(pid: str, build: str, plugin_infos: dict, quiet: bool) -> [None, str]:\n    newest_ver = None\n    newest_index = None\n    for index, info in enumerate(plugin_infos):\n        if pick_newest(newest_ver, info[\"version\"]) != newest_ver and \\\n                is_compatible(build, info[\"since\"], info[\"until\"]):\n            newest_ver = info[\"version\"]\n            newest_index = index",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_newest_compatible",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_newest_compatible(pid: str, build: str, plugin_infos: dict, quiet: bool) -> [None, str]:\n    newest_ver = None\n    newest_index = None\n    for index, info in enumerate(plugin_infos):\n        if pick_newest(newest_ver, info[\"version\"]) != newest_ver and \\\n                is_compatible(build, info[\"since\"], info[\"until\"]):\n            newest_ver = info[\"version\"]\n            newest_index = index\n    if newest_ver is not None:\n        return \"https://plugins.jetbrains.com/files/\" + plugin_infos[newest_index][\"file\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "flatten",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def flatten(main_list: list[list]) -> list:\n    return [item for sublist in main_list for item in sublist]\ndef get_compatible_ides(pid: str) -> list[str]:\n    int_id = pid.split(\"-\", 1)[0]\n    url = f\"https://plugins.jetbrains.com/api/plugins/{int_id}/compatible-products\"\n    result = get(url).json()\n    return sorted([PLUGIN_TO_FRIENDLY[i] for i in result if i in PLUGIN_TO_FRIENDLY])\ndef id_to_name(pid: str, channel=\"\") -> str:\n    channel_ext = \"-\" + channel if channel else \"\"\n    resp = get(\"https://plugins.jetbrains.com/api/plugins/\" + pid).json()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_compatible_ides",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_compatible_ides(pid: str) -> list[str]:\n    int_id = pid.split(\"-\", 1)[0]\n    url = f\"https://plugins.jetbrains.com/api/plugins/{int_id}/compatible-products\"\n    result = get(url).json()\n    return sorted([PLUGIN_TO_FRIENDLY[i] for i in result if i in PLUGIN_TO_FRIENDLY])\ndef id_to_name(pid: str, channel=\"\") -> str:\n    channel_ext = \"-\" + channel if channel else \"\"\n    resp = get(\"https://plugins.jetbrains.com/api/plugins/\" + pid).json()\n    return resp[\"link\"].split(\"-\", 1)[1] + channel_ext\ndef sort_dict(to_sort: dict) -> dict:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "id_to_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def id_to_name(pid: str, channel=\"\") -> str:\n    channel_ext = \"-\" + channel if channel else \"\"\n    resp = get(\"https://plugins.jetbrains.com/api/plugins/\" + pid).json()\n    return resp[\"link\"].split(\"-\", 1)[1] + channel_ext\ndef sort_dict(to_sort: dict) -> dict:\n    return {i: to_sort[i] for i in sorted(to_sort.keys())}\ndef make_name_mapping(infos: dict) -> dict[str, str]:\n    return sort_dict({i: id_to_name(*i.split(\"-\", 1)) for i in infos.keys()})\ndef make_plugin_files(plugin_infos: dict, ide_versions: dict, quiet: bool, extra_builds: list[str]) -> dict:\n    result = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "sort_dict",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def sort_dict(to_sort: dict) -> dict:\n    return {i: to_sort[i] for i in sorted(to_sort.keys())}\ndef make_name_mapping(infos: dict) -> dict[str, str]:\n    return sort_dict({i: id_to_name(*i.split(\"-\", 1)) for i in infos.keys()})\ndef make_plugin_files(plugin_infos: dict, ide_versions: dict, quiet: bool, extra_builds: list[str]) -> dict:\n    result = {}\n    names = make_name_mapping(plugin_infos)\n    for pid in plugin_infos:\n        plugin_versions = {\n            \"compatible\": get_compatible_ides(pid),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "make_name_mapping",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def make_name_mapping(infos: dict) -> dict[str, str]:\n    return sort_dict({i: id_to_name(*i.split(\"-\", 1)) for i in infos.keys()})\ndef make_plugin_files(plugin_infos: dict, ide_versions: dict, quiet: bool, extra_builds: list[str]) -> dict:\n    result = {}\n    names = make_name_mapping(plugin_infos)\n    for pid in plugin_infos:\n        plugin_versions = {\n            \"compatible\": get_compatible_ides(pid),\n            \"builds\": {},\n            \"name\": names[pid]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "make_plugin_files",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def make_plugin_files(plugin_infos: dict, ide_versions: dict, quiet: bool, extra_builds: list[str]) -> dict:\n    result = {}\n    names = make_name_mapping(plugin_infos)\n    for pid in plugin_infos:\n        plugin_versions = {\n            \"compatible\": get_compatible_ides(pid),\n            \"builds\": {},\n            \"name\": names[pid]\n        }\n        relevant_builds = [builds for ide, builds in ide_versions.items() if ide in plugin_versions[\"compatible\"]] + [extra_builds]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_old_file_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_old_file_hashes() -> dict[str, str]:\n    return load(open(PLUGINS_FILE))[\"files\"]\ndef get_hash(url):\n    print(f\"Downloading {url}\")\n    args = [\"nix-prefetch-url\", url, \"--print-path\"]\n    if url.endswith(\".zip\"):\n        args.append(\"--unpack\")\n    else:\n        args.append(\"--executable\")\n    path_process = run(args, capture_output=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_hash(url):\n    print(f\"Downloading {url}\")\n    args = [\"nix-prefetch-url\", url, \"--print-path\"]\n    if url.endswith(\".zip\"):\n        args.append(\"--unpack\")\n    else:\n        args.append(\"--executable\")\n    path_process = run(args, capture_output=True)\n    path = path_process.stdout.decode().split(\"\\n\")[1]\n    result = run([\"nix\", \"--extra-experimental-features\", \"nix-command\", \"hash\", \"path\", path], capture_output=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "print_file_diff",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def print_file_diff(old, new):\n    added = new.copy()\n    removed = old.copy()\n    to_delete = []\n    for file in added:\n        if file in removed:\n            to_delete.append(file)\n    for file in to_delete:\n        added.remove(file)\n        removed.remove(file)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_file_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_file_hashes(file_list: list[str], refetch_all: bool) -> dict[str, str]:\n    old = {} if refetch_all else get_old_file_hashes()\n    print_file_diff(list(old.keys()), file_list)\n    file_hashes = {}\n    for file in sorted(file_list):\n        if file in old:\n            file_hashes[file] = old[file]\n        else:\n            file_hashes[file] = get_hash(file)\n    return file_hashes",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_args() -> tuple[list[str], list[str], bool, bool, bool, list[str]]:\n    parser = ArgumentParser(\n        description=\"Add/remove/update entries in plugins.json\",\n        epilog=\"To update all plugins, run with no args.\\n\"\n               \"To add a version of a plugin from a different channel, append -[channel] to the id.\\n\"\n               \"The id of a plugin is the number before the name in the address of its page on https://plugins.jetbrains.com/\"\n    )\n    parser.add_argument(\"-r\", \"--refetch-all\", action=\"store_true\",\n                        help=\"don't use previously collected hashes, redownload all\")\n    parser.add_argument(\"-l\", \"--list\", action=\"store_true\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "sort_ids",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def sort_ids(ids: list[str]) -> list[str]:\n    sortable_ids = []\n    for pid in ids:\n        if \"-\" in pid:\n            split_pid = pid.split(\"-\", 1)\n            sortable_ids.append((int(split_pid[0]), split_pid[1]))\n        else:\n            sortable_ids.append((int(pid), \"\"))\n    sorted_ids = sorted(sortable_ids)\n    return [(f\"{i}-{j}\" if j else str(i)) for i, j in sorted_ids]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_plugin_ids",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_plugin_ids(add: list[str], remove: list[str]) -> list[str]:\n    ids = list(load(open(PLUGINS_FILE))[\"plugins\"].keys())\n    for pid in add:\n        if pid in ids:\n            raise ValueError(f\"ID {pid} already in JSON file\")\n        ids.append(pid)\n    for pid in remove:\n        try:\n            ids.remove(pid)\n        except ValueError:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_plugin_info",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_plugin_info(pid: str, channel: str) -> dict:\n    url = f\"https://plugins.jetbrains.com/api/plugins/{pid}/updates?channel={channel}\"\n    resp = get(url)\n    decoded = resp.json()\n    if resp.status_code != 200:\n        print(f\"Server gave non-200 code {resp.status_code} with message \" + decoded[\"message\"])\n        exit(1)\n    return decoded\ndef ids_to_infos(ids: list[str]) -> dict:\n    result = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "ids_to_infos",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def ids_to_infos(ids: list[str]) -> dict:\n    result = {}\n    for pid in ids:\n        if \"-\" in pid:\n            int_id, channel = pid.split(\"-\", 1)\n        else:\n            channel = \"\"\n            int_id = pid\n        result[pid] = get_plugin_info(int_id, channel)\n    return result",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_ide_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_ide_versions() -> dict:\n    ide_data = load(open(IDES_FILE))\n    result = {}\n    for platform in ide_data:\n        for product in ide_data[platform]:\n            version = ide_data[platform][product][\"build_number\"]\n            if product not in result:\n                result[product] = [version]\n            elif version not in result[product]:\n                result[product].append(version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_file_names",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def get_file_names(plugins: dict[str, dict]) -> list[str]:\n    result = []\n    for plugin_info in plugins.values():\n        for url in plugin_info[\"builds\"].values():\n            if url is not None:\n                result.append(url)\n    return list(set(result))\ndef dump(obj, file):\n    file.write(dumps(obj, indent=2))\n    file.write(\"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "dump",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def dump(obj, file):\n    file.write(dumps(obj, indent=2))\n    file.write(\"\\n\")\ndef write_result(to_write):\n    dump(to_write, open(PLUGINS_FILE, \"w\"))\ndef main():\n    add, remove, refetch_all, list_ids, quiet, extra_builds = get_args()\n    result = {}\n    print(\"Fetching plugin info\")\n    ids = get_plugin_ids(add, remove)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "write_result",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def write_result(to_write):\n    dump(to_write, open(PLUGINS_FILE, \"w\"))\ndef main():\n    add, remove, refetch_all, list_ids, quiet, extra_builds = get_args()\n    result = {}\n    print(\"Fetching plugin info\")\n    ids = get_plugin_ids(add, remove)\n    if list_ids:\n        print(*ids)\n    plugin_infos = ids_to_infos(ids)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "def main():\n    add, remove, refetch_all, list_ids, quiet, extra_builds = get_args()\n    result = {}\n    print(\"Fetching plugin info\")\n    ids = get_plugin_ids(add, remove)\n    if list_ids:\n        print(*ids)\n    plugin_infos = ids_to_infos(ids)\n    print(\"Working out which plugins need which files\")\n    ide_versions = get_ide_versions()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "TOKENS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "TOKENS = {\n    \"snap\": 10, \"snapshot\": 10,\n    \"m\": 20,\n    \"eap\": 25, \"pre\": 25, \"preview\": 25,\n    \"alpha\": 30, \"a\": 30,\n    \"beta\": 40, \"betta\": 40, \"b\": 40,\n    \"rc\": 50,\n    \"sp\": 70,\n    \"rel\": 80, \"release\": 80, \"r\": 80, \"final\": 80\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "SNAPSHOT_VALUE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "SNAPSHOT_VALUE = 99999\nPLUGINS_FILE = Path(__file__).parent.joinpath(\"plugins.json\").resolve()\nIDES_FILE = Path(__file__).parent.joinpath(\"../bin/versions.json\").resolve()\n# The plugin compatibility system uses a different naming scheme to the ide update system.\n# These dicts convert between them\nFRIENDLY_TO_PLUGIN = {\n    \"clion\": \"CLION\",\n    \"datagrip\": \"DBE\",\n    \"goland\": \"GOLAND\",\n    \"idea-community\": \"IDEA_COMMUNITY\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "PLUGINS_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "PLUGINS_FILE = Path(__file__).parent.joinpath(\"plugins.json\").resolve()\nIDES_FILE = Path(__file__).parent.joinpath(\"../bin/versions.json\").resolve()\n# The plugin compatibility system uses a different naming scheme to the ide update system.\n# These dicts convert between them\nFRIENDLY_TO_PLUGIN = {\n    \"clion\": \"CLION\",\n    \"datagrip\": \"DBE\",\n    \"goland\": \"GOLAND\",\n    \"idea-community\": \"IDEA_COMMUNITY\",\n    \"idea-ultimate\": \"IDEA\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "IDES_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "IDES_FILE = Path(__file__).parent.joinpath(\"../bin/versions.json\").resolve()\n# The plugin compatibility system uses a different naming scheme to the ide update system.\n# These dicts convert between them\nFRIENDLY_TO_PLUGIN = {\n    \"clion\": \"CLION\",\n    \"datagrip\": \"DBE\",\n    \"goland\": \"GOLAND\",\n    \"idea-community\": \"IDEA_COMMUNITY\",\n    \"idea-ultimate\": \"IDEA\",\n    \"mps\": \"MPS\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "FRIENDLY_TO_PLUGIN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "FRIENDLY_TO_PLUGIN = {\n    \"clion\": \"CLION\",\n    \"datagrip\": \"DBE\",\n    \"goland\": \"GOLAND\",\n    \"idea-community\": \"IDEA_COMMUNITY\",\n    \"idea-ultimate\": \"IDEA\",\n    \"mps\": \"MPS\",\n    \"phpstorm\": \"PHPSTORM\",\n    \"pycharm-community\": \"PYCHARM_COMMUNITY\",\n    \"pycharm-professional\": \"PYCHARM\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "PLUGIN_TO_FRIENDLY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "peekOfCode": "PLUGIN_TO_FRIENDLY = {j: i for i, j in FRIENDLY_TO_PLUGIN.items()}\ndef tokenize_stream(stream):\n    for item in stream:\n        if item in TOKENS:\n            yield TOKENS[item], 0\n        elif item.isalpha():\n            for char in item:\n                yield 90, ord(char) - 96\n        elif item.isdigit():\n            yield 100, int(item)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.plugins.update_plugins",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def get_args() -> (str, list[str]):\n    parser = ArgumentParser(\n        description=\"Given the path of a intellij source tree, make a list of urls and hashes of maven artefacts required to build\"\n    )\n    parser.add_argument(\"out\", help=\"File to output json to\")\n    parser.add_argument(\"path\", help=\"Path to the intellij-community source dir\")\n    args = parser.parse_args()\n    return args.path, args.out\ndef ensure_is_list(x):\n    if type(x) != list:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "ensure_is_list",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def ensure_is_list(x):\n    if type(x) != list:\n        return [x]\n    return x\ndef add_entries(sources, targets, hashes):\n    for num, artefact in enumerate(sources):\n        hashes.append({\n            \"url\": artefact[\"@url\"][26:],\n            \"hash\": artefact[\"sha256sum\"],\n            \"path\": targets[num][\"@url\"][25:-2]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "add_entries",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def add_entries(sources, targets, hashes):\n    for num, artefact in enumerate(sources):\n        hashes.append({\n            \"url\": artefact[\"@url\"][26:],\n            \"hash\": artefact[\"sha256sum\"],\n            \"path\": targets[num][\"@url\"][25:-2]\n        })\ndef add_libraries(root_path: str, hashes: list[dict[str, str]], projects_to_process: list[str]):\n    library_paths = os.listdir(root_path + \"/libraries/\")\n    for path in library_paths:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "add_libraries",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def add_libraries(root_path: str, hashes: list[dict[str, str]], projects_to_process: list[str]):\n    library_paths = os.listdir(root_path + \"/libraries/\")\n    for path in library_paths:\n        file_contents = parse(open(root_path + \"/libraries/\" + path).read())\n        if \"properties\" not in file_contents[\"component\"][\"library\"]:\n            continue\n        sources = ensure_is_list(file_contents[\"component\"][\"library\"][\"properties\"][\"verification\"][\"artifact\"])\n        targets = ensure_is_list(file_contents[\"component\"][\"library\"][\"CLASSES\"][\"root\"])\n        add_entries(sources, targets, hashes)\n    modules_xml = parse(open(root_path+\"/modules.xml\").read())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "add_iml",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def add_iml(path: str, hashes: list[dict[str, str]], projects_to_process: list[str]):\n    try:\n        contents = parse(open(path).read())\n    except FileNotFoundError:\n        print(f\"Warning: path {path} does not exist (did you forget the android directory?)\")\n        return\n    for manager in ensure_is_list(contents[\"module\"][\"component\"]):\n        if manager[\"@name\"] != \"NewModuleRootManager\":\n            continue\n        for entry in manager[\"orderEntry\"]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "peekOfCode": "def main():\n    root_path, out = get_args()\n    file_hashes = []\n    projects_to_process: list[str] = [root_path+\"/.idea\"]\n    while projects_to_process:\n        elem = projects_to_process.pop()\n        elem = elem.replace(\"$PROJECT_DIR$\", root_path)\n        if elem.endswith(\".iml\"):\n            add_iml(elem, file_hashes, projects_to_process)\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.jetbrains.source.build_maven",
        "documentation": {}
    },
    {
        "label": "KakouneEditor",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "class KakouneEditor(pluginupdate.Editor):\n    def generate_nix(self, plugins: List[Tuple[pluginupdate.PluginDesc, pluginupdate.Plugin]], outfile: str):\n        sorted_plugins = sorted(plugins, key=lambda v: v[1].name.lower())\n        with open(outfile, \"w+\") as f:\n            f.write(HEADER)\n            f.write(\n                \"\"\"\n{ lib, buildKakounePluginFrom2Nix, fetchFromGitHub, overrides ? (self: super: {}) }:\nlet\npackages = ( self:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "def main():\n    editor = KakouneEditor(\"kakoune\", ROOT, GET_PLUGINS)\n    editor.run()\nif __name__ == \"__main__\":\n    main()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "ROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))) # type: ignore\nsys.path.insert(\n    0, os.path.join(ROOT.parent.parent.parent.parent.parent, \"maintainers\", \"scripts\")\n)\nimport pluginupdate\nGET_PLUGINS = f\"\"\"(with import <localpkgs> {{}};\nlet\n  inherit (kakouneUtils.override {{}}) buildKakounePluginFrom2Nix;\n  generated = callPackage {ROOT}/generated.nix {{\n    inherit buildKakounePluginFrom2Nix;",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "GET_PLUGINS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "GET_PLUGINS = f\"\"\"(with import <localpkgs> {{}};\nlet\n  inherit (kakouneUtils.override {{}}) buildKakounePluginFrom2Nix;\n  generated = callPackage {ROOT}/generated.nix {{\n    inherit buildKakounePluginFrom2Nix;\n  }};\n  hasChecksum = value: lib.isAttrs value && lib.hasAttrByPath [\"src\" \"outputHash\"] value;\n  getChecksum = name: value:\n    if hasChecksum value then {{\n      submodules = value.src.fetchSubmodules or false;",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "HEADER = \"# This file has been generated by ./pkgs/applications/editors/kakoune/plugins/update.py. Do not edit!\"\nclass KakouneEditor(pluginupdate.Editor):\n    def generate_nix(self, plugins: List[Tuple[pluginupdate.PluginDesc, pluginupdate.Plugin]], outfile: str):\n        sorted_plugins = sorted(plugins, key=lambda v: v[1].name.lower())\n        with open(outfile, \"w+\") as f:\n            f.write(HEADER)\n            f.write(\n                \"\"\"\n{ lib, buildKakounePluginFrom2Nix, fetchFromGitHub, overrides ? (self: super: {}) }:\nlet",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "packages",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "peekOfCode": "packages = ( self:\n{\"\"\"\n            )\n            for pluginDesc, plugin in sorted_plugins:\n                f.write(\n                    f\"\"\"\n  {plugin.normalized_name} = buildKakounePluginFrom2Nix {{\n    pname = \"{plugin.normalized_name}\";\n    version = \"{plugin.version}\";\n    src = {pluginDesc.repo.as_nix(plugin)};",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.kakoune.plugins.update",
        "documentation": {}
    },
    {
        "label": "generate_grammar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "peekOfCode": "def generate_grammar(lang, rev, cfg):\n    \"\"\"Generate grammar for a language\"\"\"\n    info = cfg[\"install_info\"]\n    url = info[\"url\"]\n    generated = f\"\"\"  {lang} = buildGrammar {{\n    language = \"{lang}\";\n    version = \"0.0.0+rev={rev[:7]}\";\n    src = \"\"\"\n    generated += subprocess.check_output([\"nurl\", url, rev, \"--indent=4\"], text=True)\n    generated += \";\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "documentation": {}
    },
    {
        "label": "update_grammars",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "peekOfCode": "def update_grammars(nvim_treesitter_dir: str):\n    \"\"\"\n    The lockfile contains just revisions so we start neovim to dump the\n    grammar information in a better format\n    \"\"\"\n    # the lockfile\n    cmd = [\n        \"nvim\",\n        \"--headless\",\n        \"-u\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "peekOfCode": "log = logging.getLogger(\"vim-updater\")\ndef generate_grammar(lang, rev, cfg):\n    \"\"\"Generate grammar for a language\"\"\"\n    info = cfg[\"install_info\"]\n    url = info[\"url\"]\n    generated = f\"\"\"  {lang} = buildGrammar {{\n    language = \"{lang}\";\n    version = \"0.0.0+rev={rev[:7]}\";\n    src = \"\"\"\n    generated += subprocess.check_output([\"nurl\", url, rev, \"--indent=4\"], text=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.nvim-treesitter.update",
        "documentation": {}
    },
    {
        "label": "VimEditor",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "class VimEditor(pluginupdate.Editor):\n    nvim_treesitter_updated = False\n    def generate_nix(\n        self, plugins: List[Tuple[PluginDesc, pluginupdate.Plugin]], outfile: str\n    ):\n        sorted_plugins = sorted(plugins, key=lambda v: v[0].name.lower())\n        nvim_treesitter_rev = pluginupdate.run_nix_expr(\n            \"(import <localpkgs> { }).vimPlugins.nvim-treesitter.src.rev\", self.nixpkgs\n        )\n        with open(outfile, \"w+\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "def main():\n    global luaPlugins\n    log.debug(f\"Loading from {ROOT}/../get-plugins.nix\")\n    with open(f\"{ROOT}/../get-plugins.nix\") as f:\n        GET_PLUGINS = f.read()\n    editor = VimEditor(\n        \"vim\", Path(\"pkgs/applications/editors/vim/plugins\"), GET_PLUGINS\n    )\n    editor.run()\nif __name__ == \"__main__\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "log = logging.getLogger(\"vim-updater\")\nsh = logging.StreamHandler()\nformatter = logging.Formatter(\"%(name)s:%(levelname)s: %(message)s\")\nsh.setFormatter(formatter)\nlog.addHandler(sh)\n# Import plugin update library from maintainers/scripts/pluginupdate.py\nROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))\nimport pluginupdate\nimport importlib\nfrom pluginupdate import run_nix_expr, PluginDesc",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "sh",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "sh = logging.StreamHandler()\nformatter = logging.Formatter(\"%(name)s:%(levelname)s: %(message)s\")\nsh.setFormatter(formatter)\nlog.addHandler(sh)\n# Import plugin update library from maintainers/scripts/pluginupdate.py\nROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))\nimport pluginupdate\nimport importlib\nfrom pluginupdate import run_nix_expr, PluginDesc\nimport treesitter",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "formatter = logging.Formatter(\"%(name)s:%(levelname)s: %(message)s\")\nsh.setFormatter(formatter)\nlog.addHandler(sh)\n# Import plugin update library from maintainers/scripts/pluginupdate.py\nROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))\nimport pluginupdate\nimport importlib\nfrom pluginupdate import run_nix_expr, PluginDesc\nimport treesitter\nHEADER = (",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "ROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))\nimport pluginupdate\nimport importlib\nfrom pluginupdate import run_nix_expr, PluginDesc\nimport treesitter\nHEADER = (\n    \"# GENERATED by ./pkgs/applications/editors/vim/plugins/update.py. Do not edit!\"\n)\nNIXPKGS_NVIMTREESITTER_FOLDER = \"pkgs/applications/editors/vim/plugins/nvim-treesitter\"\nclass VimEditor(pluginupdate.Editor):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "HEADER = (\n    \"# GENERATED by ./pkgs/applications/editors/vim/plugins/update.py. Do not edit!\"\n)\nNIXPKGS_NVIMTREESITTER_FOLDER = \"pkgs/applications/editors/vim/plugins/nvim-treesitter\"\nclass VimEditor(pluginupdate.Editor):\n    nvim_treesitter_updated = False\n    def generate_nix(\n        self, plugins: List[Tuple[PluginDesc, pluginupdate.Plugin]], outfile: str\n    ):\n        sorted_plugins = sorted(plugins, key=lambda v: v[0].name.lower())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_NVIMTREESITTER_FOLDER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "peekOfCode": "NIXPKGS_NVIMTREESITTER_FOLDER = \"pkgs/applications/editors/vim/plugins/nvim-treesitter\"\nclass VimEditor(pluginupdate.Editor):\n    nvim_treesitter_updated = False\n    def generate_nix(\n        self, plugins: List[Tuple[PluginDesc, pluginupdate.Plugin]], outfile: str\n    ):\n        sorted_plugins = sorted(plugins, key=lambda v: v[0].name.lower())\n        nvim_treesitter_rev = pluginupdate.run_nix_expr(\n            \"(import <localpkgs> { }).vimPlugins.nvim-treesitter.src.rev\", self.nixpkgs\n        )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.editors.vim.plugins.update",
        "documentation": {}
    },
    {
        "label": "info",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "def info(*msg):\n    print(*msg, file=sys.stderr)\ndef get_repo_hash_fetchFromGitHub(\n    repo,\n    owner=\"libretro\",\n    deep_clone=False,\n    fetch_submodules=False,\n    leave_dot_git=False,\n    rev=None,\n):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "get_repo_hash_fetchFromGitHub",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "def get_repo_hash_fetchFromGitHub(\n    repo,\n    owner=\"libretro\",\n    deep_clone=False,\n    fetch_submodules=False,\n    leave_dot_git=False,\n    rev=None,\n):\n    extra_args = []\n    if deep_clone:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "get_repo_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "def get_repo_hash(fetcher=\"fetchFromGitHub\", **kwargs):\n    if fetcher == \"fetchFromGitHub\":\n        return get_repo_hash_fetchFromGitHub(**kwargs)\n    else:\n        raise ValueError(f\"Unsupported fetcher: {fetcher}\")\ndef get_repo_hashes(cores={}):\n    def get_repo_hash_from_core_def(core_def):\n        core, repo = core_def\n        info(f\"Getting repo hash for '{core}'...\")\n        result = core, get_repo_hash(**repo)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "get_repo_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "def get_repo_hashes(cores={}):\n    def get_repo_hash_from_core_def(core_def):\n        core, repo = core_def\n        info(f\"Getting repo hash for '{core}'...\")\n        result = core, get_repo_hash(**repo)\n        info(f\"Got repo hash for '{core}'!\")\n        return result\n    with open(HASHES_PATH) as f:\n        repo_hashes = json.loads(f.read())\n    info(f\"Running with {GET_REPO_THREADS} threads!\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "def main():\n    # If you don't want to update all cores, pass the name of the cores you\n    # want to update on the command line. E.g.:\n    # $ ./update.py citra snes9x\n    if len(sys.argv) > 1:\n        cores_to_update = sys.argv[1:]\n    else:\n        cores_to_update = CORES.keys()\n    cores = {core: repo for core, repo in CORES.items() if core in cores_to_update}\n    repo_hashes = get_repo_hashes(cores)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "SCRIPT_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "SCRIPT_PATH = Path(__file__).absolute().parent\nHASHES_PATH = SCRIPT_PATH / \"hashes.json\"\nGET_REPO_THREADS = int(os.environ.get(\"GET_REPO_THREADS\", 8))\n# To add a new core, add it to the dictionary below. You need to set at least\n# `repo`, that is the repository name if the owner of the repository is\n# `libretro` itself, otherwise also set `owner`.\n# You may set `deep_clone`, `fetch_submodules` or `leave_dot_git` options to\n# `True` and they're similar to `fetchgit` options. Also if for some reason you\n# need to pin a specific revision, set `rev` to a commit.\n# There is also a `fetcher` option that for now only supports `fetchFromGitHub`",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "HASHES_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "HASHES_PATH = SCRIPT_PATH / \"hashes.json\"\nGET_REPO_THREADS = int(os.environ.get(\"GET_REPO_THREADS\", 8))\n# To add a new core, add it to the dictionary below. You need to set at least\n# `repo`, that is the repository name if the owner of the repository is\n# `libretro` itself, otherwise also set `owner`.\n# You may set `deep_clone`, `fetch_submodules` or `leave_dot_git` options to\n# `True` and they're similar to `fetchgit` options. Also if for some reason you\n# need to pin a specific revision, set `rev` to a commit.\n# There is also a `fetcher` option that for now only supports `fetchFromGitHub`\n# (see `get_repo_hash()`), but it may be extended in the future if there is a",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "GET_REPO_THREADS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "GET_REPO_THREADS = int(os.environ.get(\"GET_REPO_THREADS\", 8))\n# To add a new core, add it to the dictionary below. You need to set at least\n# `repo`, that is the repository name if the owner of the repository is\n# `libretro` itself, otherwise also set `owner`.\n# You may set `deep_clone`, `fetch_submodules` or `leave_dot_git` options to\n# `True` and they're similar to `fetchgit` options. Also if for some reason you\n# need to pin a specific revision, set `rev` to a commit.\n# There is also a `fetcher` option that for now only supports `fetchFromGitHub`\n# (see `get_repo_hash()`), but it may be extended in the future if there is a\n# need to support fetchers from other source hubs.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "CORES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "peekOfCode": "CORES = {\n    \"2048\": {\"repo\": \"libretro-2048\"},\n    \"atari800\": {\"repo\": \"libretro-atari800\"},\n    \"beetle-gba\": {\"repo\": \"beetle-gba-libretro\"},\n    \"beetle-lynx\": {\"repo\": \"beetle-lynx-libretro\"},\n    \"beetle-ngp\": {\"repo\": \"beetle-ngp-libretro\"},\n    \"beetle-pce\": {\"repo\": \"beetle-pce-libretro\"},\n    \"beetle-pce-fast\": {\"repo\": \"beetle-pce-fast-libretro\"},\n    \"beetle-pcfx\": {\"repo\": \"beetle-pcfx-libretro\"},\n    \"beetle-psx\": {\"repo\": \"beetle-psx-libretro\"},",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.emulators.retroarch.update_cores",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "peekOfCode": "def test(test_interactive=False):\n    import osgeo  # just to check if geo python modules are available\n    from qgis.core import QgsVectorLayer, QgsFeature, QgsGeometry, QgsProject\n    # Nix snowflake as WKT\n    WKT = \"\"\"\n     MULTIPOLYGON (\n         ((37.10819200000000251 45.01934500000000128, 41.42360200000000248 45.0228350000000006, 43.98593199999999825 46.39836900000000242, 51.11554000000000286 46.39135900000000134, 52.20562400000000025 46.98079299999999847, 51.13812500000000227 47.55708200000000119, 46.12925599999999804 47.56117799999999818, 48.65136199999999889 48.91279899999999969, 46.46644299999999816 50.06610299999999825, 37.10819200000000251 45.01934500000000128)),\n         ((36.37806400000000195 49.06532800000000094, 34.21064499999999953 50.22733199999999698, 29.10392099999999971 50.23055699999999746, 25.55861099999999908 52.15672200000000203, 23.37426999999999921 52.15597100000000097, 22.30527299999999968 51.57995100000000122, 24.79831000000000074 50.22714599999999763, 19.77820099999999925 50.23147999999999769, 17.66315000000000168 49.06561399999999651, 36.37806400000000195 49.06532800000000094)),\n         ((25.51021400000000128 46.84120599999999968, 23.36222199999999916 45.67570500000000067, 25.90661599999999964 44.29694800000000043, 22.32231799999999922 42.37779100000000199, 23.41657500000000169 41.78910799999999881, 25.55307200000000023 41.78884599999999949, 28.06890399999999985 43.13755299999999693, 30.56690599999999947 41.78159999999999741, 34.86687599999999776 41.79416100000000256, 25.51021400000000128 46.84120599999999968)),\n         ((29.60533099999999962 44.88583400000000267, 31.77274900000000102 43.72382000000000346, 36.87947299999999728 43.7205939999999984, 40.42478299999999791 41.79442999999999842, 42.60912400000000133 41.7951929999999976, 43.67812200000000189 42.37121299999999735, 41.18508400000000336 43.72401599999999888, 46.20519399999999877 43.71968400000000088, 48.32024400000000242 44.885548, 29.60533099999999962 44.88583400000000267)),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "documentation": {}
    },
    {
        "label": "test_interactive",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "peekOfCode": "test_interactive = eval(os.getenv(\"QGIS_TEST_INTERACTIVE\", \"False\"))\ndef test(test_interactive=False):\n    import osgeo  # just to check if geo python modules are available\n    from qgis.core import QgsVectorLayer, QgsFeature, QgsGeometry, QgsProject\n    # Nix snowflake as WKT\n    WKT = \"\"\"\n     MULTIPOLYGON (\n         ((37.10819200000000251 45.01934500000000128, 41.42360200000000248 45.0228350000000006, 43.98593199999999825 46.39836900000000242, 51.11554000000000286 46.39135900000000134, 52.20562400000000025 46.98079299999999847, 51.13812500000000227 47.55708200000000119, 46.12925599999999804 47.56117799999999818, 48.65136199999999889 48.91279899999999969, 46.46644299999999816 50.06610299999999825, 37.10819200000000251 45.01934500000000128)),\n         ((36.37806400000000195 49.06532800000000094, 34.21064499999999953 50.22733199999999698, 29.10392099999999971 50.23055699999999746, 25.55861099999999908 52.15672200000000203, 23.37426999999999921 52.15597100000000097, 22.30527299999999968 51.57995100000000122, 24.79831000000000074 50.22714599999999763, 19.77820099999999925 50.23147999999999769, 17.66315000000000168 49.06561399999999651, 36.37806400000000195 49.06532800000000094)),\n         ((25.51021400000000128 46.84120599999999968, 23.36222199999999916 45.67570500000000067, 25.90661599999999964 44.29694800000000043, 22.32231799999999922 42.37779100000000199, 23.41657500000000169 41.78910799999999881, 25.55307200000000023 41.78884599999999949, 28.06890399999999985 43.13755299999999693, 30.56690599999999947 41.78159999999999741, 34.86687599999999776 41.79416100000000256, 25.51021400000000128 46.84120599999999968)),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.gis.qgis.test",
        "documentation": {}
    },
    {
        "label": "preferences",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "peekOfCode": "preferences = bpy.context.preferences.addons[\"cycles\"].preferences\ndevices = preferences.get_devices_for_type(\"CUDA\")\nids = [d.id for d in devices]\nassert any(\"CUDA\" in i for i in ids), f\"CUDA not present in {ids}\"\nprint(\"CUDA is available\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "documentation": {}
    },
    {
        "label": "devices",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "peekOfCode": "devices = preferences.get_devices_for_type(\"CUDA\")\nids = [d.id for d in devices]\nassert any(\"CUDA\" in i for i in ids), f\"CUDA not present in {ids}\"\nprint(\"CUDA is available\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "documentation": {}
    },
    {
        "label": "ids",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "peekOfCode": "ids = [d.id for d in devices]\nassert any(\"CUDA\" in i for i in ids), f\"CUDA not present in {ids}\"\nprint(\"CUDA is available\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.misc.blender.test-cuda",
        "documentation": {}
    },
    {
        "label": "feed",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "peekOfCode": "feed = feedparser.parse('https://www.blogger.com/feeds/8982037438137564684/posts/default')\nhtml_tags = re.compile(r'<[^>]+>')\ntarget_version = sys.argv[1] if len(sys.argv) == 2 else None\nfor entry in feed.entries:\n    url = requests.get(entry.link).url.split('?')[0]\n    if entry.title != 'Stable Channel Update for Desktop':\n        if target_version and entry.title == '':\n            # Workaround for a special case (Chrome Releases bug?):\n            if not 'the-stable-channel-has-been-updated-to' in url:\n                continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "documentation": {}
    },
    {
        "label": "html_tags",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "peekOfCode": "html_tags = re.compile(r'<[^>]+>')\ntarget_version = sys.argv[1] if len(sys.argv) == 2 else None\nfor entry in feed.entries:\n    url = requests.get(entry.link).url.split('?')[0]\n    if entry.title != 'Stable Channel Update for Desktop':\n        if target_version and entry.title == '':\n            # Workaround for a special case (Chrome Releases bug?):\n            if not 'the-stable-channel-has-been-updated-to' in url:\n                continue\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "documentation": {}
    },
    {
        "label": "target_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "peekOfCode": "target_version = sys.argv[1] if len(sys.argv) == 2 else None\nfor entry in feed.entries:\n    url = requests.get(entry.link).url.split('?')[0]\n    if entry.title != 'Stable Channel Update for Desktop':\n        if target_version and entry.title == '':\n            # Workaround for a special case (Chrome Releases bug?):\n            if not 'the-stable-channel-has-been-updated-to' in url:\n                continue\n        else:\n            continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.get-commit-message",
        "documentation": {}
    },
    {
        "label": "load_as_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"\n    json_string = json.dumps(input)\n    nix = subprocess.check_output(['nix-instantiate', '--eval', '--expr', '{ json }: builtins.fromJSON json', '--argstr', 'json', json_string])\n    formatted = subprocess.check_output(['nixfmt'], input=nix)\n    with open(path, 'w') as out:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "save_dict_as_nix",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"\n    json_string = json.dumps(input)\n    nix = subprocess.check_output(['nix-instantiate', '--eval', '--expr', '{ json }: builtins.fromJSON json', '--argstr', 'json', json_string])\n    formatted = subprocess.check_output(['nixfmt'], input=nix)\n    with open(path, 'w') as out:\n        out.write(formatted.decode())\ndef prefetch_src_sri_hash(attr_path, version):\n    \"\"\"Prefetches the fixed-output-derivation source tarball and returns its SRI-Hash.\"\"\"\n    print(f'nix-build (FOD prefetch) {attr_path} {version}')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "prefetch_src_sri_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def prefetch_src_sri_hash(attr_path, version):\n    \"\"\"Prefetches the fixed-output-derivation source tarball and returns its SRI-Hash.\"\"\"\n    print(f'nix-build (FOD prefetch) {attr_path} {version}')\n    out = subprocess.run(\n        [\"nix-build\", \"--expr\", f'(import ./. {{}}).{attr_path}.browser.passthru.recompressTarball {{ version = \"{version}\"; }}'],\n        cwd=NIXPKGS_PATH,\n        stderr=subprocess.PIPE\n    ).stderr.decode()\n    for line in iter(out.split(\"\\n\")):\n        match = re.match(r\"\\s+got:\\s+(.+)$\", line)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def nix_prefetch_url(url, algo='sha256'):\n    \"\"\"Prefetches the content of the given URL.\"\"\"\n    print(f'nix store prefetch-file {url}')\n    out = subprocess.check_output(['nix', 'store', 'prefetch-file', '--json', '--hash-type', algo, url])\n    return json.loads(out)['hash']\ndef nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision of the given repository URL.\"\"\"\n    print(f'nix-prefetch-git {url} {rev}')\n    out = subprocess.check_output(['nix-prefetch-git', '--quiet', '--url', url, '--rev', rev])\n    return json.loads(out)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_git",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision of the given repository URL.\"\"\"\n    print(f'nix-prefetch-git {url} {rev}')\n    out = subprocess.check_output(['nix-prefetch-git', '--quiet', '--url', url, '--rev', rev])\n    return json.loads(out)\ndef get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://chromium.googlesource.com/chromium/src/+/refs/tags/{revision}/{file_path}?format=TEXT'\n    with urlopen(url) as http_response:\n        resp = http_response.read()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_file_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://chromium.googlesource.com/chromium/src/+/refs/tags/{revision}/{file_path}?format=TEXT'\n    with urlopen(url) as http_response:\n        resp = http_response.read()\n        return base64.b64decode(resp)\ndef get_ungoogled_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://raw.githubusercontent.com/ungoogled-software/ungoogled-chromium/{revision}/{file_path}'\n    with urlopen(url) as http_response:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_ungoogled_file_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_ungoogled_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://raw.githubusercontent.com/ungoogled-software/ungoogled-chromium/{revision}/{file_path}'\n    with urlopen(url) as http_response:\n        resp = http_response.read()\n        return resp.decode(\"utf-8\")\ndef get_chromedriver(channel):\n    \"\"\"Get the latest chromedriver builds given a channel\"\"\"\n    # See https://chromedriver.chromium.org/downloads/version-selection#h.4wiyvw42q63v\n    chromedriver_versions_url = f'https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_chromedriver",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_chromedriver(channel):\n    \"\"\"Get the latest chromedriver builds given a channel\"\"\"\n    # See https://chromedriver.chromium.org/downloads/version-selection#h.4wiyvw42q63v\n    chromedriver_versions_url = f'https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json'\n    print(f'GET {chromedriver_versions_url}')\n    with urlopen(chromedriver_versions_url) as http_response:\n        chromedrivers = json.load(http_response)\n        channel = chromedrivers['channels'][channel]\n        downloads = channel['downloads']['chromedriver']\n        def get_chromedriver_url(platform):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_channel_dependencies",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_channel_dependencies(version):\n    \"\"\"Gets all dependencies for the given Chromium version.\"\"\"\n    deps = get_file_revision(version, 'DEPS')\n    gn_pattern = b\"'gn_version': 'git_revision:([0-9a-f]{40})'\"\n    gn_commit = re.search(gn_pattern, deps).group(1).decode()\n    gn = nix_prefetch_git('https://gn.googlesource.com/gn', gn_commit)\n    return {\n        'gn': {\n            'version': datetime.fromisoformat(gn['date']).date().isoformat(),\n            'url': gn['url'],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_latest_ungoogled_chromium_tag",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_latest_ungoogled_chromium_tag(linux_stable_versions):\n    \"\"\"Returns the latest ungoogled-chromium tag for linux using the GitHub API.\"\"\"\n    api_tag_url = 'https://api.github.com/repos/ungoogled-software/ungoogled-chromium/tags'\n    with urlopen(api_tag_url) as http_response:\n        tags = json.load(http_response)\n        for tag in tags:\n            if not tag['name'].split('-')[0] in linux_stable_versions:\n                continue\n            return tag['name']\ndef get_latest_ungoogled_chromium_build(linux_stable_versions):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_latest_ungoogled_chromium_build",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_latest_ungoogled_chromium_build(linux_stable_versions):\n    \"\"\"Returns a dictionary for the latest ungoogled-chromium build.\"\"\"\n    tag = get_latest_ungoogled_chromium_tag(linux_stable_versions)\n    version = tag.split('-')[0]\n    return {\n        'name': 'chrome/platforms/linux/channels/ungoogled-chromium/versions/',\n        'version': version,\n        'ungoogled_rev': tag\n    }\ndef get_ungoogled_chromium_build_by_ref(ungoogled_chromium_ref):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_ungoogled_chromium_build_by_ref",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_ungoogled_chromium_build_by_ref(ungoogled_chromium_ref):\n    \"\"\"Returns a dictionary for an ungoogled-chromium build referenced by a ref in the ungoogled-chromium repository.\"\"\"\n    version = get_ungoogled_file_revision(ungoogled_chromium_ref, \"chromium_version.txt\").strip(\"\\n \")\n    return {\n        'name': 'chrome/platforms/linux/channels/ungoogled-chromium/versions/',\n        'version': version,\n        'ungoogled_rev': ungoogled_chromium_ref\n    }\ndef get_ungoogled_chromium_gn_flags(revision):\n    \"\"\"Returns ungoogled-chromium's GN build flags for the given revision.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_ungoogled_chromium_gn_flags",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_ungoogled_chromium_gn_flags(revision):\n    \"\"\"Returns ungoogled-chromium's GN build flags for the given revision.\"\"\"\n    gn_flags_url = f'https://raw.githubusercontent.com/ungoogled-software/ungoogled-chromium/{revision}/flags.gn'\n    return urlopen(gn_flags_url).read().decode()\ndef channel_name_to_attr_name(channel_name):\n    \"\"\"Maps a channel name to the corresponding main Nixpkgs attribute name.\"\"\"\n    if channel_name == 'stable':\n        return 'chromium'\n    if channel_name == 'ungoogled-chromium':\n        return 'ungoogled-chromium'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "channel_name_to_attr_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def channel_name_to_attr_name(channel_name):\n    \"\"\"Maps a channel name to the corresponding main Nixpkgs attribute name.\"\"\"\n    if channel_name == 'stable':\n        return 'chromium'\n    if channel_name == 'ungoogled-chromium':\n        return 'ungoogled-chromium'\n    print(f'Error: Unexpected channel: {channel_name}', file=sys.stderr)\n    sys.exit(1)\ndef get_channel_key(item):\n    \"\"\"Orders Chromium channels by their name.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "get_channel_key",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def get_channel_key(item):\n    \"\"\"Orders Chromium channels by their name.\"\"\"\n    channel_name = item[0]\n    if channel_name == 'stable':\n        return 0\n    if channel_name == 'beta':\n        return 1\n    if channel_name == 'dev':\n        return 2\n    if channel_name == 'ungoogled-chromium':",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "print_updates",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "def print_updates(channels_old, channels_new):\n    \"\"\"Print a summary of the updates.\"\"\"\n    print('Updates:')\n    for channel_name in channels_old:\n        version_old = channels_old[channel_name][\"version\"]\n        version_new = channels_new[channel_name][\"version\"]\n        if LooseVersion(version_old) < LooseVersion(version_new):\n            attr_name = channel_name_to_attr_name(channel_name)\n            print(f'- {attr_name}: {version_old} -> {version_new}')\nchannels = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "RELEASES_URL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "RELEASES_URL = 'https://versionhistory.googleapis.com/v1/chrome/platforms/linux/channels/all/versions/all/releases'\nPIN_PATH = dirname(abspath(__file__)) + '/upstream-info.nix'\nUNGOOGLED_FLAGS_PATH = dirname(abspath(__file__)) + '/ungoogled-flags.toml'\nCOMMIT_MESSAGE_SCRIPT = dirname(abspath(__file__)) + '/get-commit-message.py'\nNIXPKGS_PATH = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=dirname(PIN_PATH)).strip()\ndef load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "PIN_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "PIN_PATH = dirname(abspath(__file__)) + '/upstream-info.nix'\nUNGOOGLED_FLAGS_PATH = dirname(abspath(__file__)) + '/ungoogled-flags.toml'\nCOMMIT_MESSAGE_SCRIPT = dirname(abspath(__file__)) + '/get-commit-message.py'\nNIXPKGS_PATH = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=dirname(PIN_PATH)).strip()\ndef load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "UNGOOGLED_FLAGS_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "UNGOOGLED_FLAGS_PATH = dirname(abspath(__file__)) + '/ungoogled-flags.toml'\nCOMMIT_MESSAGE_SCRIPT = dirname(abspath(__file__)) + '/get-commit-message.py'\nNIXPKGS_PATH = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=dirname(PIN_PATH)).strip()\ndef load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"\n    json_string = json.dumps(input)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "COMMIT_MESSAGE_SCRIPT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "COMMIT_MESSAGE_SCRIPT = dirname(abspath(__file__)) + '/get-commit-message.py'\nNIXPKGS_PATH = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=dirname(PIN_PATH)).strip()\ndef load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"\n    json_string = json.dumps(input)\n    nix = subprocess.check_output(['nix-instantiate', '--eval', '--expr', '{ json }: builtins.fromJSON json', '--argstr', 'json', json_string])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "NIXPKGS_PATH = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=dirname(PIN_PATH)).strip()\ndef load_as_json(path):\n    \"\"\"Loads the given nix file as JSON.\"\"\"\n    out = subprocess.check_output(['nix-instantiate', '--eval', '--strict', '--json', path])\n    return json.loads(out)\ndef save_dict_as_nix(path, input):\n    \"\"\"Saves the given dict/JSON as nix file.\"\"\"\n    json_string = json.dumps(input)\n    nix = subprocess.check_output(['nix-instantiate', '--eval', '--expr', '{ json }: builtins.fromJSON json', '--argstr', 'json', json_string])\n    formatted = subprocess.check_output(['nixfmt'], input=nix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "channels",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "channels = {}\nlast_channels = load_as_json(PIN_PATH)\nsrc_hash_cache = {}\nprint(f'GET {RELEASES_URL}', file=sys.stderr)\nwith urlopen(RELEASES_URL) as resp:\n    releases = json.load(resp)['releases']\n    if len(sys.argv) == 3 and sys.argv[1] == 'ungoogled-rev':\n        releases.append(get_ungoogled_chromium_build_by_ref(sys.argv[2]))\n    else:\n        linux_stable_versions = [release['version'] for release in releases if release['name'].startswith('chrome/platforms/linux/channels/stable/versions/')]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "last_channels",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "last_channels = load_as_json(PIN_PATH)\nsrc_hash_cache = {}\nprint(f'GET {RELEASES_URL}', file=sys.stderr)\nwith urlopen(RELEASES_URL) as resp:\n    releases = json.load(resp)['releases']\n    if len(sys.argv) == 3 and sys.argv[1] == 'ungoogled-rev':\n        releases.append(get_ungoogled_chromium_build_by_ref(sys.argv[2]))\n    else:\n        linux_stable_versions = [release['version'] for release in releases if release['name'].startswith('chrome/platforms/linux/channels/stable/versions/')]\n        releases.append(get_latest_ungoogled_chromium_build(linux_stable_versions))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "src_hash_cache",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "src_hash_cache = {}\nprint(f'GET {RELEASES_URL}', file=sys.stderr)\nwith urlopen(RELEASES_URL) as resp:\n    releases = json.load(resp)['releases']\n    if len(sys.argv) == 3 and sys.argv[1] == 'ungoogled-rev':\n        releases.append(get_ungoogled_chromium_build_by_ref(sys.argv[2]))\n    else:\n        linux_stable_versions = [release['version'] for release in releases if release['name'].startswith('chrome/platforms/linux/channels/stable/versions/')]\n        releases.append(get_latest_ungoogled_chromium_build(linux_stable_versions))\n    for release in releases:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "sorted_channels",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "peekOfCode": "sorted_channels = OrderedDict(sorted(channels.items(), key=get_channel_key))\nif len(sys.argv) == 2 and sys.argv[1] == '--commit':\n    for channel_name in sorted_channels.keys():\n        version_old = last_channels[channel_name]['version']\n        version_new = sorted_channels[channel_name]['version']\n        if LooseVersion(version_old) < LooseVersion(version_new):\n            last_channels[channel_name] = sorted_channels[channel_name]\n            save_dict_as_nix(PIN_PATH, last_channels)\n            attr_name = channel_name_to_attr_name(channel_name)\n            commit_message = f'{attr_name}: {version_old} -> {version_new}'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.chromium.update",
        "documentation": {}
    },
    {
        "label": "packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "peekOfCode": "def packages():\n    packages_url = 'https://packages.microsoft.com/repos/edge/dists/stable/main/binary-amd64/Packages'\n    handle = request.urlopen(packages_url)\n    return handle\ndef latest_packages(packages: bytes):\n    latest_packages: OrderedDict[str, Packages] = {}\n    for package in Packages.iter_paragraphs(packages, use_apt_pkg=False):\n        name: str = package['Package']\n        if not name.startswith('microsoft-edge-'):\n            continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "documentation": {}
    },
    {
        "label": "latest_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "peekOfCode": "def latest_packages(packages: bytes):\n    latest_packages: OrderedDict[str, Packages] = {}\n    for package in Packages.iter_paragraphs(packages, use_apt_pkg=False):\n        name: str = package['Package']\n        if not name.startswith('microsoft-edge-'):\n            continue\n        channel = name.replace('microsoft-edge-', '')\n        if channel not in latest_packages:\n            latest_packages[channel] = package\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "documentation": {}
    },
    {
        "label": "nix_expressions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "peekOfCode": "def nix_expressions(latest: dict[str, Packages]):\n    channel_strs: list[str] = []\n    for channel, package in latest.items():\n        print(f\"Processing {channel} {package['Version']}\")\n        match = Version.re_valid_version.match(package['Version'])\n        assert match is not None\n        version = match.group('upstream_version')\n        revision = match.group('debian_revision')\n        sri = 'sha256-' + \\\n            base64.b64encode(bytes.fromhex(package['SHA256'])).decode('ascii')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "documentation": {}
    },
    {
        "label": "write_expression",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "peekOfCode": "def write_expression():\n    latest = latest_packages(packages())\n    channel_strs = nix_expressions(latest)\n    nix_expr = '{\\n' + textwrap.indent('\\n'.join(channel_strs), '  ') + '\\n}\\n'\n    with open(PIN_PATH, 'w') as f:\n        f.write(nix_expr)\nwrite_expression()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "documentation": {}
    },
    {
        "label": "PIN_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "peekOfCode": "PIN_PATH = dirname(abspath(__file__)) + '/default.nix'\ndef packages():\n    packages_url = 'https://packages.microsoft.com/repos/edge/dists/stable/main/binary-amd64/Packages'\n    handle = request.urlopen(packages_url)\n    return handle\ndef latest_packages(packages: bytes):\n    latest_packages: OrderedDict[str, Packages] = {}\n    for package in Packages.iter_paragraphs(packages, use_apt_pkg=False):\n        name: str = package['Package']\n        if not name.startswith('microsoft-edge-'):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.browsers.microsoft-edge.update",
        "documentation": {}
    },
    {
        "label": "XDG_CONFIG_HOME",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "peekOfCode": "XDG_CONFIG_HOME = os.environ.get(\"XDG_CONFIG_HOME\") or os.path.join(\n    os.path.expanduser(\"~\"), \".config\"\n)\nsettings_path = Path(f\"{XDG_CONFIG_HOME}/@configDirName@/settings.json\")\nsettings_path_temp = Path(f\"{XDG_CONFIG_HOME}/@configDirName@/settings.json.tmp\")\nif os.path.exists(settings_path):\n    with settings_path.open(encoding=\"utf-8\") as settings_file:\n        try:\n            settings = json.load(settings_file)\n        except json.JSONDecodeError:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "documentation": {}
    },
    {
        "label": "settings_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "peekOfCode": "settings_path = Path(f\"{XDG_CONFIG_HOME}/@configDirName@/settings.json\")\nsettings_path_temp = Path(f\"{XDG_CONFIG_HOME}/@configDirName@/settings.json.tmp\")\nif os.path.exists(settings_path):\n    with settings_path.open(encoding=\"utf-8\") as settings_file:\n        try:\n            settings = json.load(settings_file)\n        except json.JSONDecodeError:\n            print(\"[Nix] settings.json is malformed, letting Discord fix itself\")\n            sys.exit(0)\nelse:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "documentation": {}
    },
    {
        "label": "settings_path_temp",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "peekOfCode": "settings_path_temp = Path(f\"{XDG_CONFIG_HOME}/@configDirName@/settings.json.tmp\")\nif os.path.exists(settings_path):\n    with settings_path.open(encoding=\"utf-8\") as settings_file:\n        try:\n            settings = json.load(settings_file)\n        except json.JSONDecodeError:\n            print(\"[Nix] settings.json is malformed, letting Discord fix itself\")\n            sys.exit(0)\nelse:\n    settings = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.networking.instant-messengers.discord.disable-breaking-updates",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def main():\n    packages = list(get_packages())\n    for x in packages:\n        print(x, file=sys.stderr)\n    print('[')\n    for x in packages:\n        md5 = x['md5']\n        upstream_sha256 = x['sha256']\n        if upstream_sha256:\n            hash = upstream_sha256",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "construct_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def construct_url(x):\n    if x['brief']:\n        return 'https://dev-www.libreoffice.org/src/{}{}'.format(\n            x.get('subdir', ''), x['tarball'])\n    else:\n        return 'https://dev-www.libreoffice.org/src/{}{}-{}'.format(\n            x.get('subdir', ''), x['md5'], x['tarball'])\ndef download(url, name, hash, hashtype):\n    cmd = ['nix-prefetch-url', url, hash, '--print-path',\n           '--type', hashtype, '--name', name]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def download(url, name, hash, hashtype):\n    cmd = ['nix-prefetch-url', url, hash, '--print-path',\n           '--type', hashtype, '--name', name]\n    proc = subprocess.run(cmd, stdout=subprocess.PIPE, check=True,\n                          universal_newlines=True)\n    return proc.stdout.split('\\n')[1].strip()\ndef get_sha256(path):\n    cmd = ['sha256sum', path]\n    proc = subprocess.run(cmd, stdout=subprocess.PIPE, check=True,\n                          universal_newlines=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "get_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def get_sha256(path):\n    cmd = ['sha256sum', path]\n    proc = subprocess.run(cmd, stdout=subprocess.PIPE, check=True,\n                          universal_newlines=True)\n    return proc.stdout.split(' ')[0].strip()\ndef get_packages():\n    \"\"\"\n    All of the package data: What's parsed from download.lst,\n    plus our additions.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "get_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def get_packages():\n    \"\"\"\n    All of the package data: What's parsed from download.lst,\n    plus our additions.\n    \"\"\"\n    return apply_additions(get_packages_from_download_list(),\n                           get_additions())\ndef get_additions():\n    \"\"\"\n    A mapping from package name (the all-caps identifiers used in",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "get_additions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def get_additions():\n    \"\"\"\n    A mapping from package name (the all-caps identifiers used in\n    `download.lst`) to a dict of additional attributes to set on the package.\n    \"\"\"\n    with open('./libreoffice-srcs-additions.json') as f:\n        return json.load(f)\ndef apply_additions(xs, additions):\n    for x in xs:\n        yield dict_merge([x,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "apply_additions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def apply_additions(xs, additions):\n    for x in xs:\n        yield dict_merge([x,\n                          additions.get(x['name'], {})])\ndef get_packages_from_download_list():\n    \"\"\"\n    The result of parsing `download.lst`: A list of dicts containing keys\n    'name', 'tarball', 'md5', 'brief'.\n    \"\"\"\n    def lines():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "get_packages_from_download_list",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def get_packages_from_download_list():\n    \"\"\"\n    The result of parsing `download.lst`: A list of dicts containing keys\n    'name', 'tarball', 'md5', 'brief'.\n    \"\"\"\n    def lines():\n        for x in sub_symbols(parse_lines(get_lines())):\n            interpretation = interpret(x)\n            if interpretation == 'unrecognized':\n                print_skipped_line(x)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "dict_merge",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def dict_merge(xs):\n    \"\"\"\n    >>> dict_merge([{1: 2}, {3: 4}, {3: 5}])\n    {1: 2, 3: 4}\n    \"\"\"\n    return dict(collections.ChainMap(*xs))\ndef groupby(xs, f):\n    \"\"\"\n    >>> groupby([1, 2, 3, 4], lambda x: x % 2)\n    [(0, [2, 4]), (1, [1, 3])]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "groupby",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def groupby(xs, f):\n    \"\"\"\n    >>> groupby([1, 2, 3, 4], lambda x: x % 2)\n    [(0, [2, 4]), (1, [1, 3])]\n    \"\"\"\n    for (k, iter) in itertools.groupby(sorted(xs, key=f), f):\n        group = list(iter)\n        yield (f(group[0]), group)\ndef get_lines():\n    download_list = os.getenv('downloadList')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "get_lines",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def get_lines():\n    download_list = os.getenv('downloadList')\n    with open(download_list) as f:\n        return f.read().splitlines()\ndef print_skipped_line(x):\n    print('Skipped line {}: {}'.format(x['index'],\n                                       x['original']),\n          file=sys.stderr)\ndef parse_lines(lines):\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "print_skipped_line",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def print_skipped_line(x):\n    print('Skipped line {}: {}'.format(x['index'],\n                                       x['original']),\n          file=sys.stderr)\ndef parse_lines(lines):\n    \"\"\"\n    Input: List of strings (the lines from `download.lst`\n    Output: Iterator of dicts with keys 'key', 'value', and 'index'\n    \"\"\"\n    for (index, line) in enumerate(lines):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "parse_lines",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def parse_lines(lines):\n    \"\"\"\n    Input: List of strings (the lines from `download.lst`\n    Output: Iterator of dicts with keys 'key', 'value', and 'index'\n    \"\"\"\n    for (index, line) in enumerate(lines):\n        x = { 'index': index, 'original': line }\n        result = parse_line(line)\n        if result == 'nothing':\n            pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "parse_line",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def parse_line(line):\n    \"\"\"\n    Input: A string\n    Output: One of 1. A dict with keys 'key', 'value'\n                   2. 'nothing' (if the line contains no information)\n                   2. 'unrecognized' (if parsing failed)\n    \"\"\"\n    if re.match('\\s*(#.*)?$', line):\n        return 'nothing'\n    match = re.match('([^:\\s]+)\\s*:=\\s*(.*)$', line)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "sub_symbols",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def sub_symbols(xs):\n    \"\"\"\n    Do substitution of variables across all lines.\n    >>> sub_symbols([{'key': 'a', 'value': 'x'},\n    ...              {'key': 'c': 'value': '$(a)yz'}])\n    [{'key': 'a', 'value': 'x'}, {'key': 'c': 'value': 'xyz'}]\n    \"\"\"\n    xs = list(xs)\n    symbols = {x['key']: x for x in xs}\n    def get_value(k):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "sub_str",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def sub_str(string, func):\n    \"\"\"\n    Do substitution of variables in a single line.\n    >>> sub_str(\"x = $(x)\", lambda k: {'x': 'a'}[k])\n    \"x = a\"\n    \"\"\"\n    def func2(m):\n        x = m.group(1)\n        result = func(x)\n        return result if result is not None else x",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret(x):\n    \"\"\"\n    Input: Dict with keys 'key' and 'value'\n    Output: One of 1. Dict with keys 'name' and 'attrs'\n                   2. 'unrecognized' (if interpretation failed)\n    \"\"\"\n    for f in [interpret_md5, interpret_sha256, interpret_tarball_with_md5, interpret_tarball, interpret_jar]:\n        result = f(x)\n        if result is not None:\n            return result",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret_md5",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret_md5(x):\n    \"\"\"\n    >>> interpret_md5(\"ODFGEN_MD5SUM\", \"32572ea48d9021bbd6fa317ddb697abc\")\n    {'name': 'ODFGEN', 'attrs': {'md5': '32572ea48d9021bbd6fa317ddb697abc'}}\n    \"\"\"\n    match = re.match('^(.*)_MD5SUM$', x['key'])\n    if match:\n        return {'name': match.group(1),\n                'attrs': {'md5': x['value'], 'sha256': ''}}\ndef interpret_sha256(x):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret_sha256(x):\n    match = re.match('^(.*)_SHA256SUM$', x['key'])\n    if match:\n        return {'name': match.group(1),\n                'attrs': {'sha256': x['value'], 'md5': ''}}\ndef interpret_tarball(x):\n    \"\"\"\n    >>> interpret_tarball(\"FREEHAND_TARBALL\", \"libfreehand-0.1.1.tar.bz2\")\n    {'name': 'FREEHAND',\n     'attrs': {'tarball': 'libfreehand-0.1.1.tar.bz2', 'brief': True}}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret_tarball",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret_tarball(x):\n    \"\"\"\n    >>> interpret_tarball(\"FREEHAND_TARBALL\", \"libfreehand-0.1.1.tar.bz2\")\n    {'name': 'FREEHAND',\n     'attrs': {'tarball': 'libfreehand-0.1.1.tar.bz2', 'brief': True}}\n    \"\"\"\n    match = re.match('^(.*)_TARBALL$', x['key'])\n    if match:\n        return {'name': match.group(1),\n                'attrs': {'tarball': x['value'], 'brief': True}}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret_jar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret_jar(x):\n    match = re.match('^(.*)_JAR$', x['key'])\n    if match:\n        return {'name': match.group(1),\n                'attrs': {'tarball': x['value'], 'brief': True}}\ndef interpret_tarball_with_md5(x):\n    \"\"\"\n    >>> interpret_tarball_with_md5(\"CLUCENE_TARBALL\",\\\n        \"48d647fbd8ef8889e5a7f422c1bfda94-clucene-core-2.3.3.4.tar.gz\")\n    {'name': 'CLUCENE',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "interpret_tarball_with_md5",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "peekOfCode": "def interpret_tarball_with_md5(x):\n    \"\"\"\n    >>> interpret_tarball_with_md5(\"CLUCENE_TARBALL\",\\\n        \"48d647fbd8ef8889e5a7f422c1bfda94-clucene-core-2.3.3.4.tar.gz\")\n    {'name': 'CLUCENE',\n     'attrs': {'tarball': 'clucene-core-2.3.3.4.tar.gz',\n               'md5': '48d647fbd8ef8889e5a7f422c1bfda94', 'brief': False}}\n    \"\"\"\n    match = {'key': re.match('^(.*)_(TARBALL|JAR)$', x['key']),\n             'value': re.match('(?P<md5>[0-9a-fA-F]{32})-(?P<tarball>.+)$',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.office.libreoffice.generate-libreoffice-srcs",
        "documentation": {}
    },
    {
        "label": "parse_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "peekOfCode": "def parse_packages(text):\n    res = []\n    for package in resp.text.split(\"\\n\\n\"):\n        if not package: continue\n        pkg = {}\n        for field in package.split(\"\\n\"):\n            if field.startswith(\" \"): # multiline string\n                pkg[k] += \"\\n\" + field[1:]\n            else:\n                [k, v] = field.split(\": \", 1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "documentation": {}
    },
    {
        "label": "generate_sources",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "peekOfCode": "def generate_sources(packages):\n    sources_spec = {}\n    for pkg in pkgs:\n        sources_spec[pkg['Package']] = {\n            \"url\": \"https://labs.picotech.com/rc/picoscope7/debian/\" + pkg[\"Filename\"],\n            \"sha256\": pkg[\"SHA256\"],\n            \"version\": pkg[\"Version\"]\n        }\n    return sources_spec\nout = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "peekOfCode": "out = {}\nfor nix_system, release in {\"x86_64-linux\": \"amd64\"}.items():\n    resp = requests.get(\"https://labs.picotech.com/rc/picoscope7/debian//dists/picoscope/main/binary-\"+release+\"/Packages\")\n    if resp.status_code != 200:\n        print(\"error: could not fetch data for release {} (code {})\".format(release, resp.code), file=sys.stderr)\n        sys.exit(1)\n    pkgs = parse_packages(resp.text)\n    out[nix_system] = generate_sources(pkgs)\nwith open(os.path.dirname(__file__) + \"/sources.json\", \"w\") as f:\n    json.dump(out, f, indent=2, sort_keys=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.science.electronics.picoscope.update",
        "documentation": {}
    },
    {
        "label": "GitLabRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "class GitLabRepo:\n    version_regex = re.compile(r\"^v\\d+\\.\\d+\\.\\d+(\\-rc\\d+)?(\\-ee)?(\\-gitlab)?\")\n    def __init__(self, owner: str = \"gitlab-org\", repo: str = \"gitlab\"):\n        self.owner = owner\n        self.repo = repo\n    @property\n    def url(self):\n        return f\"https://gitlab.com/{self.owner}/{self.repo}\"\n    @property\n    def tags(self) -> Iterable[str]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def cli():\n    pass\n@cli.command(\"update-data\")\n@click.option(\"--rev\", default=\"latest\", help=\"The rev to use (vX.Y.Z-ee), or 'latest'\")\ndef update_data(rev: str):\n    \"\"\"Update data.json\"\"\"\n    logger.info(\"Updating data.json\")\n    repo = GitLabRepo()\n    if rev == \"latest\":\n        # filter out pre and rc releases",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_data",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_data(rev: str):\n    \"\"\"Update data.json\"\"\"\n    logger.info(\"Updating data.json\")\n    repo = GitLabRepo()\n    if rev == \"latest\":\n        # filter out pre and rc releases\n        rev = next(filter(lambda x: not (\"rc\" in x or x.endswith(\"pre\")), repo.tags))\n    data_file_path = pathlib.Path(__file__).parent / \"data.json\"\n    data = repo.get_data(rev)\n    with open(data_file_path.as_posix(), \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_rubyenv",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_rubyenv():\n    \"\"\"Update rubyEnv\"\"\"\n    logger.info(\"Updating gitlab\")\n    repo = GitLabRepo()\n    rubyenv_dir = pathlib.Path(__file__).parent / \"rubyEnv\"\n    # load rev from data.json\n    data = _get_data_json()\n    rev = data[\"rev\"]\n    version = data[\"version\"]\n    for fn in [\"Gemfile.lock\", \"Gemfile\"]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitaly",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitaly():\n    \"\"\"Update gitaly\"\"\"\n    logger.info(\"Updating gitaly\")\n    data = _get_data_json()\n    gitaly_server_version = data['passthru']['GITALY_SERVER_VERSION']\n    _call_nix_update(\"gitaly\", gitaly_server_version)\n@cli.command(\"update-gitlab-pages\")\ndef update_gitlab_pages():\n    \"\"\"Update gitlab-pages\"\"\"\n    logger.info(\"Updating gitlab-pages\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitlab_pages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitlab_pages():\n    \"\"\"Update gitlab-pages\"\"\"\n    logger.info(\"Updating gitlab-pages\")\n    data = _get_data_json()\n    gitlab_pages_version = data[\"passthru\"][\"GITLAB_PAGES_VERSION\"]\n    _call_nix_update(\"gitlab-pages\", gitlab_pages_version)\ndef get_container_registry_version() -> str:\n    \"\"\"Returns the version attribute of gitlab-container-registry\"\"\"\n    return subprocess.check_output(\n        [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "get_container_registry_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def get_container_registry_version() -> str:\n    \"\"\"Returns the version attribute of gitlab-container-registry\"\"\"\n    return subprocess.check_output(\n        [\n            \"nix\",\n            \"--experimental-features\",\n            \"nix-command\",\n            \"eval\",\n            \"-f\",\n            \".\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitlab_shell",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitlab_shell():\n    \"\"\"Update gitlab-shell\"\"\"\n    logger.info(\"Updating gitlab-shell\")\n    data = _get_data_json()\n    gitlab_shell_version = data[\"passthru\"][\"GITLAB_SHELL_VERSION\"]\n    _call_nix_update(\"gitlab-shell\", gitlab_shell_version)\n@cli.command(\"update-gitlab-workhorse\")\ndef update_gitlab_workhorse():\n    \"\"\"Update gitlab-workhorse\"\"\"\n    logger.info(\"Updating gitlab-workhorse\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitlab_workhorse",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitlab_workhorse():\n    \"\"\"Update gitlab-workhorse\"\"\"\n    logger.info(\"Updating gitlab-workhorse\")\n    data = _get_data_json()\n    gitlab_workhorse_version = data[\"passthru\"][\"GITLAB_WORKHORSE_VERSION\"]\n    _call_nix_update(\"gitlab-workhorse\", gitlab_workhorse_version)\n@cli.command(\"update-gitlab-container-registry\")\n@click.option(\"--rev\", default=\"latest\", help=\"The rev to use (vX.Y.Z-ee), or 'latest'\")\n@click.option(\n    \"--commit\", is_flag=True, default=False, help=\"Commit the changes for you\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitlab_container_registry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitlab_container_registry(rev: str, commit: bool):\n    \"\"\"Update gitlab-container-registry\"\"\"\n    logger.info(\"Updading gitlab-container-registry\")\n    repo = GitLabRepo(repo=\"container-registry\")\n    old_container_registry_version = get_container_registry_version()\n    if rev == \"latest\":\n        rev = next(filter(lambda x: not (\"rc\" in x or x.endswith(\"pre\")), repo.tags))\n    version = repo.rev2version(rev)\n    _call_nix_update(\"gitlab-container-registry\", version)\n    if commit:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_gitlab_elasticsearch_indexer",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_gitlab_elasticsearch_indexer():\n    \"\"\"Update gitlab-elasticsearch-indexer\"\"\"\n    data = _get_data_json()\n    gitlab_elasticsearch_indexer_version = data['passthru']['GITLAB_ELASTICSEARCH_INDEXER_VERSION']\n    _call_nix_update('gitlab-elasticsearch-indexer', gitlab_elasticsearch_indexer_version)\n@cli.command(\"update-all\")\n@click.option(\"--rev\", default=\"latest\", help=\"The rev to use (vX.Y.Z-ee), or 'latest'\")\n@click.option(\n    \"--commit\", is_flag=True, default=False, help=\"Commit the changes for you\"\n)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "update_all",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def update_all(ctx, rev: str, commit: bool):\n    \"\"\"Update all gitlab components to the latest stable release\"\"\"\n    old_data_json = _get_data_json()\n    old_container_registry_version = get_container_registry_version()\n    ctx.invoke(update_data, rev=rev)\n    new_data_json = _get_data_json()\n    ctx.invoke(update_rubyenv)\n    ctx.invoke(update_gitaly)\n    ctx.invoke(update_gitlab_pages)\n    ctx.invoke(update_gitlab_shell)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "commit_gitlab",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def commit_gitlab(old_version: str, new_version: str, new_rev: str) -> None:\n    \"\"\"Commits the gitlab changes for you\"\"\"\n    subprocess.run(\n        [\n            \"git\",\n            \"add\",\n            \"data.json\",\n            \"rubyEnv\",\n            \"gitaly\",\n            \"gitlab-pages\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "commit_container_registry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "def commit_container_registry(old_version: str, new_version: str) -> None:\n    \"\"\"Commits the gitlab-container-registry changes for you\"\"\"\n    subprocess.run([\"git\", \"add\", \"gitlab-container-registry\"], cwd=GITLAB_DIR)\n    subprocess.run(\n        [\n            \"git\",\n            \"commit\",\n            \"--message\",\n            f\"gitlab-container-registry: {old_version} -> {new_version}\\n\\nhttps://gitlab.com/gitlab-org/container-registry/-/blob/v{new_version}-gitlab/CHANGELOG.md\",\n        ],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "NIXPKGS_PATH = pathlib.Path(__file__).parent / \"../../../../\"\nGITLAB_DIR = pathlib.Path(__file__).parent\nlogger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass GitLabRepo:\n    version_regex = re.compile(r\"^v\\d+\\.\\d+\\.\\d+(\\-rc\\d+)?(\\-ee)?(\\-gitlab)?\")\n    def __init__(self, owner: str = \"gitlab-org\", repo: str = \"gitlab\"):\n        self.owner = owner\n        self.repo = repo\n    @property",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "GITLAB_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "GITLAB_DIR = pathlib.Path(__file__).parent\nlogger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass GitLabRepo:\n    version_regex = re.compile(r\"^v\\d+\\.\\d+\\.\\d+(\\-rc\\d+)?(\\-ee)?(\\-gitlab)?\")\n    def __init__(self, owner: str = \"gitlab-org\", repo: str = \"gitlab\"):\n        self.owner = owner\n        self.repo = repo\n    @property\n    def url(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass GitLabRepo:\n    version_regex = re.compile(r\"^v\\d+\\.\\d+\\.\\d+(\\-rc\\d+)?(\\-ee)?(\\-gitlab)?\")\n    def __init__(self, owner: str = \"gitlab-org\", repo: str = \"gitlab\"):\n        self.owner = owner\n        self.repo = repo\n    @property\n    def url(self):\n        return f\"https://gitlab.com/{self.owner}/{self.repo}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.gitlab.update",
        "documentation": {}
    },
    {
        "label": "updateCargoLock",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "def updateCargoLock():\n    with tempfile.TemporaryDirectory() as tempDir:\n        tempDir = pathlib.Path(tempDir)\n        # NOTE(strager): We cannot use shutil.tree because it copies the\n        # read-only permissions.\n        for dirpath, dirnames, filenames in os.walk(sourceDirectory):\n            relativeDirpath = os.path.relpath(dirpath, sourceDirectory)\n            for filename in filenames:\n                shutil.copy(os.path.join(dirpath, filename), tempDir / relativeDirpath / filename)\n            for dirname in dirnames:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "nixPrefetchUrl",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "def nixPrefetchUrl(url):\n    return run(\n        [\"nix-prefetch-url\", \"--type\", \"sha256\", url],\n        check=True,\n        text=True,\n        capture_output=True,\n    ).stdout.rstrip()\n# Fetch the `setup.py` source and look for instances of assets being downloaded\n# from files.pythonhosted.org.\nsetupPy = (pathlib.Path(sourceDirectory) / \"eden/scm/setup.py\").read_text()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "releaseMetadata",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "releaseMetadata = get(\"https://api.github.com/repos/facebook/sapling/releases/latest\").json()\nlatestTag = releaseMetadata[\"tag_name\"]\nlatestTarballURL = releaseMetadata[\"tarball_url\"]\n[_tarballHash, sourceDirectory] = run(\n    [\"nix-prefetch-url\", \"--print-path\", \"--unpack\", latestTarballURL],\n    check=True,\n    text=True,\n    stdout=subprocess.PIPE,\n).stdout.rstrip().splitlines()\ndef updateCargoLock():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "latestTag",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "latestTag = releaseMetadata[\"tag_name\"]\nlatestTarballURL = releaseMetadata[\"tarball_url\"]\n[_tarballHash, sourceDirectory] = run(\n    [\"nix-prefetch-url\", \"--print-path\", \"--unpack\", latestTarballURL],\n    check=True,\n    text=True,\n    stdout=subprocess.PIPE,\n).stdout.rstrip().splitlines()\ndef updateCargoLock():\n    with tempfile.TemporaryDirectory() as tempDir:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "latestTarballURL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "latestTarballURL = releaseMetadata[\"tarball_url\"]\n[_tarballHash, sourceDirectory] = run(\n    [\"nix-prefetch-url\", \"--print-path\", \"--unpack\", latestTarballURL],\n    check=True,\n    text=True,\n    stdout=subprocess.PIPE,\n).stdout.rstrip().splitlines()\ndef updateCargoLock():\n    with tempfile.TemporaryDirectory() as tempDir:\n        tempDir = pathlib.Path(tempDir)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "setupPy",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "setupPy = (pathlib.Path(sourceDirectory) / \"eden/scm/setup.py\").read_text()\nfoundUrls = re.findall(r'(https://files\\.pythonhosted\\.org/packages/[^\\s]+)\"', setupPy)\ndataDeps = {\n    \"links\": [{\"url\": url, \"sha256\": nixPrefetchUrl(url)} for url in foundUrls],\n    \"version\": latestTag,\n    # Find latest's git tag which corresponds to the Sapling version. Also\n    # needed is a hash of the version, so calculate that here. Taken from\n    # Sapling source `$root/eden/scm/setup_with_version.py`.\n    \"versionHash\": str(unpack(\">Q\", sha1(latestTag.encode(\"ascii\")).digest()[:8])[0]),\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "foundUrls",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "foundUrls = re.findall(r'(https://files\\.pythonhosted\\.org/packages/[^\\s]+)\"', setupPy)\ndataDeps = {\n    \"links\": [{\"url\": url, \"sha256\": nixPrefetchUrl(url)} for url in foundUrls],\n    \"version\": latestTag,\n    # Find latest's git tag which corresponds to the Sapling version. Also\n    # needed is a hash of the version, so calculate that here. Taken from\n    # Sapling source `$root/eden/scm/setup_with_version.py`.\n    \"versionHash\": str(unpack(\">Q\", sha1(latestTag.encode(\"ascii\")).digest()[:8])[0]),\n}\nopen(\"deps.json\", \"w\").write(json.dumps(dataDeps, indent=2, sort_keys=True) + \"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "dataDeps",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "peekOfCode": "dataDeps = {\n    \"links\": [{\"url\": url, \"sha256\": nixPrefetchUrl(url)} for url in foundUrls],\n    \"version\": latestTag,\n    # Find latest's git tag which corresponds to the Sapling version. Also\n    # needed is a hash of the version, so calculate that here. Taken from\n    # Sapling source `$root/eden/scm/setup_with_version.py`.\n    \"versionHash\": str(unpack(\">Q\", sha1(latestTag.encode(\"ascii\")).digest()[:8])[0]),\n}\nopen(\"deps.json\", \"w\").write(json.dumps(dataDeps, indent=2, sort_keys=True) + \"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.version-management.sapling.gen-deps",
        "documentation": {}
    },
    {
        "label": "chrome_major_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "peekOfCode": "chrome_major_version = chrome_version[0]\nchromeos_tip_build = platform_version[0]\nrelease_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+log/refs/heads/chromeos..{rev}?format=JSON') as resp:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "documentation": {}
    },
    {
        "label": "chromeos_tip_build",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "peekOfCode": "chromeos_tip_build = platform_version[0]\nrelease_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+log/refs/heads/chromeos..{rev}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "documentation": {}
    },
    {
        "label": "release_branch",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "peekOfCode": "release_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform/crosvm/+log/refs/heads/chromeos..{rev}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    branch_commits = json.load(resp)['log']",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.virtualization.crosvm.update",
        "documentation": {}
    },
    {
        "label": "chrome_major_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "chrome_major_version = chrome_version[0]\nchromeos_tip_build = platform_version[0]\nrelease_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+log/refs/heads/main..{rev}/vm_tools/sommelier?format=JSON') as resp:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "chromeos_tip_build",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "chromeos_tip_build = platform_version[0]\nrelease_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+log/refs/heads/main..{rev}/vm_tools/sommelier?format=JSON') as resp:\n    resp.readline() # Remove )]}' header",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "release_branch",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "release_branch = f'release-R{chrome_major_version}-{chromeos_tip_build}.B'\n# Determine the git revision.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+/refs/heads/{release_branch}?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    rev = json.load(resp)['commit']\n# Determine the patch version by counting the commits that have been\n# added to the release branch since it forked off the chromeos branch.\nwith urlopen(f'https://chromium.googlesource.com/chromiumos/platform2/+log/refs/heads/main..{rev}/vm_tools/sommelier?format=JSON') as resp:\n    resp.readline() # Remove )]}' header\n    branch_commits = json.load(resp)['log']",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "argv",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "argv = ['nix-instantiate', '--eval', '--json', '-A', 'sommelier.meta.position']\nposition = json.loads(subprocess.check_output(argv).decode('utf-8'))\nfilename = re.match(r'[^:]*', position)[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "position",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "position = json.loads(subprocess.check_output(argv).decode('utf-8'))\nfilename = re.match(r'[^:]*', position)[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "filename",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "peekOfCode": "filename = re.match(r'[^:]*', position)[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.applications.window-managers.sommelier.update",
        "documentation": {}
    },
    {
        "label": "dropPrefix",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "peekOfCode": "def dropPrefix(path):\n  return path[len(nixPrefix + \"/\"):]\nfor item in closures:\n  narInfoHash = dropPrefix(item[\"path\"]).split(\"-\")[0]\n  xzFile = \"nar/\" + narInfoHash + \".nar.xz\"\n  with open(xzFile, \"w\") as f:\n    subprocess.run(\"nix-store --dump %s | xz -c\" % item[\"path\"], stdout=f, shell=True)\n  fileHash = subprocess.run([\"nix-hash\", \"--base32\", \"--type\", \"sha256\", item[\"path\"]], capture_output=True).stdout.decode().strip()\n  fileSize = os.path.getsize(xzFile)\n  # Rename the .nar.xz file to its own hash to match \"nix copy\" behavior",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "documentation": {}
    },
    {
        "label": "nixPrefix",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "peekOfCode": "nixPrefix = os.environ[\"NIX_STORE\"] # Usually /nix/store\nwith open(\"nix-cache-info\", \"w\") as f:\n  f.write(\"StoreDir: \" + nixPrefix + \"\\n\")\ndef dropPrefix(path):\n  return path[len(nixPrefix + \"/\"):]\nfor item in closures:\n  narInfoHash = dropPrefix(item[\"path\"]).split(\"-\")[0]\n  xzFile = \"nar/\" + narInfoHash + \".nar.xz\"\n  with open(xzFile, \"w\") as f:\n    subprocess.run(\"nix-store --dump %s | xz -c\" % item[\"path\"], stdout=f, shell=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.binary-cache.make-binary-cache",
        "documentation": {}
    },
    {
        "label": "eprint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "peekOfCode": "def eprint(text: str):\n    print(text, file=sys.stderr)\nif not os.path.exists(\"dub.selections.json\"):\n    eprint(\"The file `dub.selections.json` does not exist in the current working directory\")\n    eprint(\"run `dub upgrade --annotate` to generate it\")\n    sys.exit(1)\nwith open(\"dub.selections.json\") as f:\n    selectionsJson = json.load(f)\ndepsDict: dict = selectionsJson[\"versions\"]\n# For each dependency expand non-expanded version into a dict with a \"version\" key",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "documentation": {}
    },
    {
        "label": "depsDict",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "peekOfCode": "depsDict = {pname: (versionOrDepDict if isinstance(versionOrDepDict, dict) else {\"version\": versionOrDepDict}) for (pname, versionOrDepDict) in depsDict.items()}\n# Don't process path-type selections\ndepsDict = {pname: depDict for (pname, depDict) in depsDict.items() if \"path\" not in depDict}\n# Pre-validate selections before trying to fetch\nfor pname in depsDict:\n    depDict = depsDict[pname]\n    version = depDict[\"version\"]\n    if version.startswith(\"~\"):\n        eprint(f'Expected version of \"{pname}\" to be non-branch type')\n        eprint(f'Found: \"{version}\"')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "documentation": {}
    },
    {
        "label": "depsDict",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "peekOfCode": "depsDict = {pname: depDict for (pname, depDict) in depsDict.items() if \"path\" not in depDict}\n# Pre-validate selections before trying to fetch\nfor pname in depsDict:\n    depDict = depsDict[pname]\n    version = depDict[\"version\"]\n    if version.startswith(\"~\"):\n        eprint(f'Expected version of \"{pname}\" to be non-branch type')\n        eprint(f'Found: \"{version}\"')\n        eprint(\"Please specify a non-branch version inside `dub.selections.json`\")\n        eprint(\"When packaging, you might also need to patch the version value in the appropriate places (`dub.selections.json`, dub.sdl`, `dub.json`)\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dlang.dub-to-nix.dub-to-nix",
        "documentation": {}
    },
    {
        "label": "makedet",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "peekOfCode": "def makedet(j, safedels):\n    for k,v in safedels.items():\n        if k not in j:\n            continue\n        if type(v) == dict:\n            makedet(j[k], v)\n        elif j[k] == v:\n            del j[k]\ndef main():\n    j = json.load(sys.stdin)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "peekOfCode": "def main():\n    j = json.load(sys.stdin)\n    makedet(j, SAFEDELS)\n    json.dump(j, sys.stdout, sort_keys=True)\nif __name__ == '__main__':\n    main()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "documentation": {}
    },
    {
        "label": "SAFEDELS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "peekOfCode": "SAFEDELS = {\n    \"Size\": 0,\n    \"config\": {\n        \"ExposedPorts\": None,\n        \"MacAddress\": \"\",\n        \"NetworkDisabled\": False,\n        \"PortSpecs\": None,\n        \"VolumeDriver\": \"\"\n    }\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "documentation": {}
    },
    {
        "label": "SAFEDELS[\"container_config\"]",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "peekOfCode": "SAFEDELS[\"container_config\"] = SAFEDELS[\"config\"]\ndef makedet(j, safedels):\n    for k,v in safedels.items():\n        if k not in j:\n            continue\n        if type(v) == dict:\n            makedet(j[k], v)\n        elif j[k] == v:\n            del j[k]\ndef main():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.detjson",
        "documentation": {}
    },
    {
        "label": "ExtractChecksum",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "class ExtractChecksum:\n    \"\"\"\n    A writable stream which only calculates the final file size and\n    sha256sum, while discarding the actual contents.\n    \"\"\"\n    def __init__(self):\n        self._digest = hashlib.sha256()\n        self._size = 0\n    def write(self, data):\n        self._digest.update(data)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "archive_paths_to",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def archive_paths_to(obj, paths, mtime, uid, gid, uname, gname):\n    \"\"\"\n    Writes the given store paths as a tar file to the given stream.\n    obj: Stream to write to. Should have a 'write' method.\n    paths: List of store paths.\n    \"\"\"\n    # gettarinfo makes the paths relative, this makes them\n    # absolute again\n    def append_root(ti):\n        ti.name = \"/\" + ti.name",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "load_from_image",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def load_from_image(from_image_str):\n    \"\"\"\n    Loads the given base image, if any.\n    from_image_str: Path to the base image archive.\n    Returns: A 'FromImage' object with references to the loaded base image,\n             or 'None' if no base image was provided.\n    \"\"\"\n    if from_image_str is None:\n        return None\n    base_tar = tarfile.open(from_image_str)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "add_base_layers",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def add_base_layers(tar, from_image):\n    \"\"\"\n    Adds the layers from the given base image to the final image.\n    tar: 'tarfile.TarFile' object for new layers to be added to.\n    from_image: 'FromImage' object with references to the loaded base image.\n    \"\"\"\n    if from_image is None:\n        print(\"No 'fromImage' provided\", file=sys.stderr)\n        return []\n    layers = from_image.manifest_json[0][\"Layers\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "overlay_base_config",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def overlay_base_config(from_image, final_config):\n    \"\"\"\n    Overlays the final image 'config' JSON on top of selected defaults from the\n    base image 'config' JSON.\n    from_image: 'FromImage' object with references to the loaded base image.\n    final_config: 'dict' object of the final image 'config' JSON.\n    \"\"\"\n    if from_image is None:\n        return final_config\n    base_config = from_image.image_json[\"config\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "add_layer_dir",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def add_layer_dir(tar, paths, store_dir, mtime, uid, gid, uname, gname):\n    \"\"\"\n    Appends given store paths to a TarFile object as a new layer.\n    tar: 'tarfile.TarFile' object for the new layer to be added to.\n    paths: List of store paths.\n    store_dir: the root directory of the nix store\n    mtime: 'mtime' of the added files and the layer tarball.\n           Should be an integer representing a POSIX time.\n    Returns: A 'LayerInfo' object containing some metadata of\n             the layer added.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "add_customisation_layer",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def add_customisation_layer(target_tar, customisation_layer, mtime):\n    \"\"\"\n    Adds the customisation layer as a new layer. This is layer is structured\n    differently; given store path has the 'layer.tar' and corresponding\n    sha256sum ready.\n    tar: 'tarfile.TarFile' object for the new layer to be added to.\n    customisation_layer: Path containing the layer archive.\n    mtime: 'mtime' of the added layer tarball.\n    \"\"\"\n    checksum_path = os.path.join(customisation_layer, \"checksum\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "add_bytes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def add_bytes(tar, path, content, mtime):\n    \"\"\"\n    Adds a file to the tarball with given path and contents.\n    tar: 'tarfile.TarFile' object.\n    path: Path of the file as a string.\n    content: Contents of the file.\n    mtime: 'mtime' of the file. Should be an integer representing a POSIX time.\n    \"\"\"\n    assert type(content) is bytes\n    ti = tarfile.TarInfo(path)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "def main():\n    with open(sys.argv[1], \"r\") as f:\n        conf = json.load(f)\n    created = (\n      datetime.now(tz=timezone.utc)\n      if conf[\"created\"] == \"now\"\n      else datetime.fromisoformat(conf[\"created\"])\n    )\n    mtime = int(created.timestamp())\n    uid = int(conf[\"uid\"])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "FromImage",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "FromImage = namedtuple(\"FromImage\", [\"tar\", \"manifest_json\", \"image_json\"])\n# Some metadata for a layer\nLayerInfo = namedtuple(\"LayerInfo\", [\"size\", \"checksum\", \"path\", \"paths\"])\ndef load_from_image(from_image_str):\n    \"\"\"\n    Loads the given base image, if any.\n    from_image_str: Path to the base image archive.\n    Returns: A 'FromImage' object with references to the loaded base image,\n             or 'None' if no base image was provided.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "LayerInfo",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "peekOfCode": "LayerInfo = namedtuple(\"LayerInfo\", [\"size\", \"checksum\", \"path\", \"paths\"])\ndef load_from_image(from_image_str):\n    \"\"\"\n    Loads the given base image, if any.\n    from_image_str: Path to the base image archive.\n    Returns: A 'FromImage' object with references to the loaded base image,\n             or 'None' if no base image was provided.\n    \"\"\"\n    if from_image_str is None:\n        return None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.docker.stream_layered_image",
        "documentation": {}
    },
    {
        "label": "all_licenses",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "peekOfCode": "all_licenses = set()\nif len(sys.argv) < 2:\n    print(f\"Usage: {sys.argv[0]} DIRECTORY\")\n    sys.exit(1)\nnupkg_dir = Path(sys.argv[1])\nfor nupkg_name in glob(\"*.nupkg\", root_dir=nupkg_dir):\n    with zipfile.ZipFile(nupkg_dir / nupkg_name) as nupkg:\n        for nuspec_name in [name for name in nupkg.namelist() if name.endswith(\".nuspec\")]:\n            with nupkg.open(nuspec_name) as nuspec_stream:\n                nuspec = ET.parse(nuspec_stream)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "documentation": {}
    },
    {
        "label": "nupkg_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "peekOfCode": "nupkg_dir = Path(sys.argv[1])\nfor nupkg_name in glob(\"*.nupkg\", root_dir=nupkg_dir):\n    with zipfile.ZipFile(nupkg_dir / nupkg_name) as nupkg:\n        for nuspec_name in [name for name in nupkg.namelist() if name.endswith(\".nuspec\")]:\n            with nupkg.open(nuspec_name) as nuspec_stream:\n                nuspec = ET.parse(nuspec_stream)\n                licenses = nuspec.findall(\".//{*}license[@type='expression']\")\n                all_licenses.update([license.text for license in licenses])\nprint(\"\\n\".join(sorted(all_licenses)))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.dotnet.make-nuget-source.extract-licenses-from-nupkgs",
        "documentation": {}
    },
    {
        "label": "Pep503",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "peekOfCode": "class Pep503(HTMLParser):\n    def __init__(self) -> None:\n        super().__init__()\n        self.sources: dict[str, str] = {}\n        self.url: Optional[str] = None\n        self.name: Optional[str] = None\n    def handle_data(self, data: str) -> None:\n        if self.url is not None:\n            self.name = data\n    def handle_starttag(self, tag: str, attrs: list[tuple[str, Optional[str]]]) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "documentation": {}
    },
    {
        "label": "try_fetch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "peekOfCode": "def try_fetch(url: str, package_name: str, package_filename: str) -> None:\n    index_url = url + \"/\" + package_name + \"/\"\n    # Parse username and password for this host from the netrc file if given.\n    username: Optional[str] = None\n    password: Optional[str] = None\n    if os.environ.get(\"NETRC\", \"\") != \"\":\n        netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n        host = urlparse(index_url).netloc\n        # Strip port number if present\n        if \":\" in host:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "documentation": {}
    },
    {
        "label": "argparser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "peekOfCode": "argparser = argparse.ArgumentParser(description=\"Fetch file from legacy pypi API\")\nargparser.add_argument(\"--url\", action=\"append\", required=True)\nargparser.add_argument(\"--pname\", action=\"store\", required=True)\nargparser.add_argument(\"--filename\", action=\"store\", required=True)\nif __name__ == \"__main__\":\n    args = argparser.parse_args()\n    for url in args.url:\n        try:\n            try_fetch(url, args.pname, args.filename)\n        except urllib.error.HTTPError as e:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.fetchpypilegacy.fetch-legacy",
        "documentation": {}
    },
    {
        "label": "TestFindRoots",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestFindRoots(unittest.TestCase):\n    def test_find_roots(self):\n        self.assertCountEqual(\n            find_roots([\n                {\n                    \"path\": \"/nix/store/foo\",\n                    \"references\": [\n                        \"/nix/store/foo\",\n                        \"/nix/store/bar\"\n                    ]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestAnyReferTo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestAnyReferTo(unittest.TestCase):\n    def test_has_references(self):\n        self.assertTrue(\n            any_refer_to(\n                \"/nix/store/bar\",\n                [\n                    {\n                        \"path\": \"/nix/store/foo\",\n                        \"references\": [\n                            \"/nix/store/bar\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestAllPaths",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestAllPaths(unittest.TestCase):\n    def test_returns_all_paths(self):\n        self.assertCountEqual(\n            all_paths([\n                {\n                    \"path\": \"/nix/store/foo\",\n                    \"references\": [\n                        \"/nix/store/foo\",\n                        \"/nix/store/bar\"\n                    ]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestMakeLookup",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestMakeLookup(unittest.TestCase):\n    def test_returns_lookp(self):\n        self.assertDictEqual(\n            make_lookup([\n                {\n                    \"path\": \"/nix/store/foo\",\n                    \"references\": [\n                        \"/nix/store/foo\",\n                        \"/nix/store/bar\"\n                    ]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestMakeGraphSegmentFromRoot",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestMakeGraphSegmentFromRoot(unittest.TestCase):\n    def test_returns_graph(self):\n        self.assertDictEqual(\n            make_graph_segment_from_root(\"/nix/store/foo\", {\n                \"/nix/store/foo\": [ \"/nix/store/bar\" ],\n                \"/nix/store/bar\": [ \"/nix/store/tux\" ],\n                \"/nix/store/tux\": [ ],\n                \"/nix/store/hello\": [ ],\n            }),\n            {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestGraphPopularityContest",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestGraphPopularityContest(unittest.TestCase):\n    def test_counts_popularity(self):\n        self.assertDictEqual(\n            graph_popularity_contest({\n                \"/nix/store/foo\": {\n                    \"/nix/store/bar\": {\n                        \"/nix/store/baz\": {\n                            \"/nix/store/tux\": {}\n                        }\n                    },",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "TestOrderByPopularity",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "class TestOrderByPopularity(unittest.TestCase):\n    def test_returns_in_order(self):\n        self.assertEqual(\n            order_by_popularity({\n                   \"/nix/store/foo\": 1,\n                   \"/nix/store/bar\": 1,\n                   \"/nix/store/baz\": 2,\n                   \"/nix/store/tux\": 2,\n            }),\n            [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "debug",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def debug(msg, *args, **kwargs):\n    if False:\n        print(\n            \"DEBUG: {}\".format(\n                msg.format(*args, **kwargs)\n            ),\n            file=sys.stderr\n        )\n# Find paths in the original dataset which are never referenced by\n# any other paths",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "find_roots",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def find_roots(closures):\n    roots = [];\n    for closure in closures:\n        path = closure['path']\n        if not any_refer_to(path, closures):\n            roots.append(path)\n    return roots\nclass TestFindRoots(unittest.TestCase):\n    def test_find_roots(self):\n        self.assertCountEqual(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "any_refer_to",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def any_refer_to(path, closures):\n    for closure in closures:\n        if path != closure['path']:\n            if path in closure['references']:\n                return True\n    return False\nclass TestAnyReferTo(unittest.TestCase):\n    def test_has_references(self):\n        self.assertTrue(\n            any_refer_to(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "all_paths",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def all_paths(closures):\n    paths = []\n    for closure in closures:\n        paths.append(closure['path'])\n        paths.extend(closure['references'])\n    paths.sort()\n    return list(set(paths))\nclass TestAllPaths(unittest.TestCase):\n    def test_returns_all_paths(self):\n        self.assertCountEqual(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "make_lookup",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def make_lookup(closures):\n    lookup = {}\n    for closure in closures:\n        # paths often self-refer\n        nonreferential_paths = [ref for ref in closure['references'] if ref != closure['path']]\n        lookup[closure['path']] = nonreferential_paths\n    return lookup\nclass TestMakeLookup(unittest.TestCase):\n    def test_returns_lookp(self):\n        self.assertDictEqual(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "make_graph_segment_from_root",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def make_graph_segment_from_root(root, lookup):\n    global subgraphs_cache\n    children = {}\n    for ref in lookup[root]:\n        # make_graph_segment_from_root is a pure function, and will\n        # always return the same result based on a given input. Thus,\n        # cache computation.\n        #\n        # Python's assignment will use a pointer, preventing memory\n        # bloat for large graphs.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "graph_popularity_contest",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def graph_popularity_contest(full_graph):\n    global popularity_cache\n    popularity = defaultdict(int)\n    for path, subgraph in full_graph.items():\n        popularity[path] += 1\n        # graph_popularity_contest is a pure function, and will\n        # always return the same result based on a given input. Thus,\n        # cache computation.\n        #\n        # Python's assignment will use a pointer, preventing memory",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "order_by_popularity",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def order_by_popularity(paths):\n    paths_by_popularity = defaultdict(list)\n    popularities = []\n    for path, popularity in paths.items():\n        popularities.append(popularity)\n        paths_by_popularity[popularity].append(path)\n    popularities = list(set(popularities))\n    popularities.sort()\n    flat_ordered = []\n    for popularity in popularities:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def package_name(path):\n    parts = path.split('-')\n    start = parts.pop(0)\n    # don't throw away any data, so the order is always the same.\n    # even in cases where only the hash at the start has changed.\n    parts.append(start)\n    return '-'.join(parts)\ndef main():\n    filename = sys.argv[1]\n    key = sys.argv[2]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "def main():\n    filename = sys.argv[1]\n    key = sys.argv[2]\n    debug(\"Loading from {}\", filename)\n    with open(filename) as f:\n        data = json.load(f)\n    # Data comes in as:\n    # [\n    #    { path: /nix/store/foo, references: [ /nix/store/foo, /nix/store/bar, /nix/store/baz ] },\n    #    { path: /nix/store/bar, references: [ /nix/store/bar, /nix/store/baz ] },",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "subgraphs_cache",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "subgraphs_cache = {}\ndef make_graph_segment_from_root(root, lookup):\n    global subgraphs_cache\n    children = {}\n    for ref in lookup[root]:\n        # make_graph_segment_from_root is a pure function, and will\n        # always return the same result based on a given input. Thus,\n        # cache computation.\n        #\n        # Python's assignment will use a pointer, preventing memory",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "popularity_cache",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "peekOfCode": "popularity_cache = {}\ndef graph_popularity_contest(full_graph):\n    global popularity_cache\n    popularity = defaultdict(int)\n    for path, subgraph in full_graph.items():\n        popularity[path] += 1\n        # graph_popularity_contest is a pure function, and will\n        # always return the same result based on a given input. Thus,\n        # cache computation.\n        #",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.references-by-popularity.closure-graph",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "peekOfCode": "description = \"\"\"\nReplace a string in one file with a secret from a second file.\nSince the secret is read from a file, it won't be leaked through\n'/proc/<pid>/cmdline', unlike when 'sed' or 'replace' is used.\n\"\"\"\nparser = argparse.ArgumentParser(\n    description=description,\n    formatter_class=RawDescriptionHelpFormatter\n)\nparser.add_argument(\"string_to_replace\", help=\"the string to replace\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "peekOfCode": "parser = argparse.ArgumentParser(\n    description=description,\n    formatter_class=RawDescriptionHelpFormatter\n)\nparser.add_argument(\"string_to_replace\", help=\"the string to replace\")\nparser.add_argument(\"secret_file\", help=\"the file containing the secret\")\nparser.add_argument(\"file\", help=\"the file to perform the replacement on\")\nargs = parser.parse_args()\nwith open(args.secret_file) as sf, open(args.file, 'r+') as f:\n    old = f.read()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "peekOfCode": "args = parser.parse_args()\nwith open(args.secret_file) as sf, open(args.file, 'r+') as f:\n    old = f.read()\n    secret = sf.read().strip(\"\\n\")\n    new_content = old.replace(args.string_to_replace, secret)\n    f.seek(0)\n    f.write(new_content)\n    f.truncate()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.replace-secret.replace-secret",
        "documentation": {}
    },
    {
        "label": "quote",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "peekOfCode": "def quote(s: str) -> str:\n    escaped = s.replace('\"', r\"\\\"\").replace(\"\\n\", r\"\\n\").replace(\"\\\\\", \"\\\\\\\\\")\n    return '\"{}\"'.format(escaped)\ndef main() -> None:\n    data = toml.load(sys.stdin)\n    # There is no dependency to vendor in this project.\n    if not list(data.keys()) == [\"source\"]:\n        return\n    # this value is non deterministic\n    data[\"source\"][\"vendored-sources\"][\"directory\"] = \"@vendor@\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "peekOfCode": "def main() -> None:\n    data = toml.load(sys.stdin)\n    # There is no dependency to vendor in this project.\n    if not list(data.keys()) == [\"source\"]:\n        return\n    # this value is non deterministic\n    data[\"source\"][\"vendored-sources\"][\"directory\"] = \"@vendor@\"\n    lines = []\n    inner = data[\"source\"]\n    for source, attrs in sorted(inner.items()):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.fetch-cargo-tarball.cargo-vendor-normalise",
        "documentation": {}
    },
    {
        "label": "rust_src",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "peekOfCode": "rust_src = os.environ['RUSTC_SRC']\norig_cargo = os.environ['ORIG_CARGO'] if 'ORIG_CARGO' in os.environ else None\nbase = {\n  'package': {\n    'name': 'nixpkgs-sysroot-stub-crate',\n    'version': '0.0.0',\n    'authors': ['The Rust Project Developers'],\n    'edition': '2018',\n  },\n  'dependencies': {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "documentation": {}
    },
    {
        "label": "orig_cargo",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "peekOfCode": "orig_cargo = os.environ['ORIG_CARGO'] if 'ORIG_CARGO' in os.environ else None\nbase = {\n  'package': {\n    'name': 'nixpkgs-sysroot-stub-crate',\n    'version': '0.0.0',\n    'authors': ['The Rust Project Developers'],\n    'edition': '2018',\n  },\n  'dependencies': {\n    'compiler_builtins': {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "peekOfCode": "base = {\n  'package': {\n    'name': 'nixpkgs-sysroot-stub-crate',\n    'version': '0.0.0',\n    'authors': ['The Rust Project Developers'],\n    'edition': '2018',\n  },\n  'dependencies': {\n    'compiler_builtins': {\n      'version': '0.1.0',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "peekOfCode": "out = toml.dumps(base)\nwith open('Cargo.toml', 'x') as f:\n  f.write(out)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.sysroot.cargo",
        "documentation": {}
    },
    {
        "label": "load_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "peekOfCode": "def load_file(path: str) -> dict[str, Any]:\n    with open(path, \"rb\") as f:\n        return tomli.load(f)\n# This replicates the dependency merging logic from Cargo.\n# See `inner_dependency_inherit_with`:\n# https://github.com/rust-lang/cargo/blob/4de0094ac78743d2c8ff682489e35c8a7cafe8e4/src/cargo/util/toml/mod.rs#L982\ndef replace_key(\n    workspace_manifest: dict[str, Any], table: dict[str, Any], section: str, key: str\n) -> bool:\n    if (",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "documentation": {}
    },
    {
        "label": "replace_key",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "peekOfCode": "def replace_key(\n    workspace_manifest: dict[str, Any], table: dict[str, Any], section: str, key: str\n) -> bool:\n    if (\n        isinstance(table[key], dict)\n        and \"workspace\" in table[key]\n        and table[key][\"workspace\"] is True\n    ):\n        print(\"replacing \" + key)\n        local_dep = table[key]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "documentation": {}
    },
    {
        "label": "replace_dependencies",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "peekOfCode": "def replace_dependencies(\n    workspace_manifest: dict[str, Any], root: dict[str, Any]\n) -> bool:\n    changed = False\n    for key in [\"dependencies\", \"dev-dependencies\", \"build-dependencies\"]:\n        if key in root:\n            for k in root[key].keys():\n                changed |= replace_key(workspace_manifest, root[key], \"dependencies\", k)\n    return changed\ndef main() -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "peekOfCode": "def main() -> None:\n    top_cargo_toml = load_file(sys.argv[2])\n    if \"workspace\" not in top_cargo_toml:\n        # If top_cargo_toml is not a workspace manifest, then this script was probably\n        # ran on something that does not actually use workspace dependencies\n        print(f\"{sys.argv[2]} is not a workspace manifest, doing nothing.\")\n        return\n    crate_manifest = load_file(sys.argv[1])\n    workspace_manifest = top_cargo_toml[\"workspace\"]\n    if \"workspace\" in crate_manifest:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.rust.replace-workspace-values",
        "documentation": {}
    },
    {
        "label": "Dependency",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "class Dependency:\n    file: Path              # The file that contains the dependency\n    name: Path              # The name of the dependency\n    found: bool = False     # Whether it was found somewhere\ndef auto_patchelf_file(path: Path, runtime_deps: list[Path], append_rpaths: List[Path] = [], extra_args: List[str] = []) -> list[Dependency]:\n    try:\n        with open_elf(path) as elf:\n            if is_static_executable(elf):\n                # No point patching these\n                print(f\"skipping {path} because it is statically linked\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "open_elf",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def open_elf(path: Path) -> Iterator[ELFFile]:\n    with path.open('rb') as stream:\n        yield ELFFile(stream)\ndef is_static_executable(elf: ELFFile) -> bool:\n    # Statically linked executables have an ELF type of EXEC but no INTERP.\n    return (elf.header[\"e_type\"] == 'ET_EXEC'\n            and not elf.get_section_by_name(\".interp\"))\ndef is_dynamic_executable(elf: ELFFile) -> bool:\n    # We do not require an ELF type of EXEC. This also catches\n    # position-independent executables, as they typically have an INTERP",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "is_static_executable",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def is_static_executable(elf: ELFFile) -> bool:\n    # Statically linked executables have an ELF type of EXEC but no INTERP.\n    return (elf.header[\"e_type\"] == 'ET_EXEC'\n            and not elf.get_section_by_name(\".interp\"))\ndef is_dynamic_executable(elf: ELFFile) -> bool:\n    # We do not require an ELF type of EXEC. This also catches\n    # position-independent executables, as they typically have an INTERP\n    # section but their ELF type is DYN.\n    return bool(elf.get_section_by_name(\".interp\"))\ndef get_dependencies(elf: ELFFile) -> List[str]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "is_dynamic_executable",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def is_dynamic_executable(elf: ELFFile) -> bool:\n    # We do not require an ELF type of EXEC. This also catches\n    # position-independent executables, as they typically have an INTERP\n    # section but their ELF type is DYN.\n    return bool(elf.get_section_by_name(\".interp\"))\ndef get_dependencies(elf: ELFFile) -> List[str]:\n    dependencies = []\n    # This convoluted code is here on purpose. For some reason, using\n    # elf.get_section_by_name(\".dynamic\") does not always return an\n    # instance of DynamicSection, but that is required to call iter_tags",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "get_dependencies",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def get_dependencies(elf: ELFFile) -> List[str]:\n    dependencies = []\n    # This convoluted code is here on purpose. For some reason, using\n    # elf.get_section_by_name(\".dynamic\") does not always return an\n    # instance of DynamicSection, but that is required to call iter_tags\n    for section in elf.iter_sections():\n        if isinstance(section, DynamicSection):\n            for tag in section.iter_tags('DT_NEEDED'):\n                dependencies.append(tag.needed)\n            break # There is only one dynamic section",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "get_rpath",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def get_rpath(elf: ELFFile) -> List[str]:\n    # This convoluted code is here on purpose. For some reason, using\n    # elf.get_section_by_name(\".dynamic\") does not always return an\n    # instance of DynamicSection, but that is required to call iter_tags\n    for section in elf.iter_sections():\n        if isinstance(section, DynamicSection):\n            for tag in section.iter_tags('DT_RUNPATH'):\n                return tag.runpath.split(':')\n            for tag in section.iter_tags('DT_RPATH'):\n                return tag.rpath.split(':')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "get_arch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def get_arch(elf: ELFFile) -> str:\n    return elf.get_machine_arch()\ndef get_osabi(elf: ELFFile) -> str:\n    return elf.header[\"e_ident\"][\"EI_OSABI\"]\ndef osabi_are_compatible(wanted: str, got: str) -> bool:\n    \"\"\"\n    Tests whether two OS ABIs are compatible, taking into account the\n    generally accepted compatibility of SVR4 ABI with other ABIs.\n    \"\"\"\n    if not wanted or not got:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "get_osabi",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def get_osabi(elf: ELFFile) -> str:\n    return elf.header[\"e_ident\"][\"EI_OSABI\"]\ndef osabi_are_compatible(wanted: str, got: str) -> bool:\n    \"\"\"\n    Tests whether two OS ABIs are compatible, taking into account the\n    generally accepted compatibility of SVR4 ABI with other ABIs.\n    \"\"\"\n    if not wanted or not got:\n        # One of the types couldn't be detected, so as a fallback we'll\n        # assume they're compatible.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "osabi_are_compatible",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def osabi_are_compatible(wanted: str, got: str) -> bool:\n    \"\"\"\n    Tests whether two OS ABIs are compatible, taking into account the\n    generally accepted compatibility of SVR4 ABI with other ABIs.\n    \"\"\"\n    if not wanted or not got:\n        # One of the types couldn't be detected, so as a fallback we'll\n        # assume they're compatible.\n        return True\n    # Generally speaking, the base ABI (0x00), which is represented by",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def glob(path: Path, pattern: str, recursive: bool) -> Iterator[Path]:\n    if path.is_dir():\n        return path.rglob(pattern) if recursive else path.glob(pattern)\n    else:\n        # path.glob won't return anything if the path is not a directory.\n        # We extend that behavior by matching the file name against the pattern.\n        # This allows to pass single files instead of dirs to auto_patchelf,\n        # for greater control on the files to consider.\n        return [path] if path.match(pattern) else []\ncached_paths: Set[Path] = set()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "populate_cache",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def populate_cache(initial: List[Path], recursive: bool =False) -> None:\n    lib_dirs = list(initial)\n    while lib_dirs:\n        lib_dir = lib_dirs.pop(0)\n        if lib_dir in cached_paths:\n            continue\n        cached_paths.add(lib_dir)\n        for path in glob(lib_dir, \"*.so*\", recursive):\n            if not path.is_file():\n                continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "find_dependency",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def find_dependency(soname: str, soarch: str, soabi: str) -> Optional[Path]:\n    for lib, libabi in soname_cache[(soname, soarch)]:\n        if osabi_are_compatible(soabi, libabi):\n            return lib\n    return None\n@dataclass\nclass Dependency:\n    file: Path              # The file that contains the dependency\n    name: Path              # The name of the dependency\n    found: bool = False     # Whether it was found somewhere",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "auto_patchelf_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def auto_patchelf_file(path: Path, runtime_deps: list[Path], append_rpaths: List[Path] = [], extra_args: List[str] = []) -> list[Dependency]:\n    try:\n        with open_elf(path) as elf:\n            if is_static_executable(elf):\n                # No point patching these\n                print(f\"skipping {path} because it is statically linked\")\n                return []\n            if elf.num_segments() == 0:\n                # no segment (e.g. object file)\n                print(f\"skipping {path} because it contains no segment\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "auto_patchelf",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def auto_patchelf(\n        paths_to_patch: List[Path],\n        lib_dirs: List[Path],\n        runtime_deps: List[Path],\n        recursive: bool = True,\n        ignore_missing: List[str] = [],\n        append_rpaths: List[Path] = [],\n        extra_args: List[str] = []) -> None:\n    if not paths_to_patch:\n        sys.exit(\"No paths to patch, stopping.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        prog=\"auto-patchelf\",\n        description='auto-patchelf tries as hard as possible to patch the'\n                    ' provided binary files by looking for compatible'\n                    'libraries in the provided paths.')\n    parser.add_argument(\n        \"--ignore-missing\",\n        nargs=\"*\",\n        type=str,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.build-support.setup-hooks.auto-patchelf",
        "documentation": {}
    },
    {
        "label": "to_java_string",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "peekOfCode": "def to_java_string(string) -> bytes:\n  string_bytes = string.encode(\"utf-8\")\n  # Java constant pool string entries are prefixed by 0x01 and 16-bit big-endian string length.\n  return pack(\">BH\", 1, len(string_bytes)) + string_bytes\nclass_file = Path(sys.argv[1])\nclazz = class_file.read_bytes()\n# We want to fix these package names so they work with the open-source Java EE releases instead of OpenJDK 8.\npatches = [\n  ( \"com/sun/xml/internal/ws/developer/WSBindingProvider\", \"com/sun/xml/ws/developer/WSBindingProvider\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Header\", \"com/sun/xml/ws/api/message/Header\" ),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "documentation": {}
    },
    {
        "label": "class_file",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "peekOfCode": "class_file = Path(sys.argv[1])\nclazz = class_file.read_bytes()\n# We want to fix these package names so they work with the open-source Java EE releases instead of OpenJDK 8.\npatches = [\n  ( \"com/sun/xml/internal/ws/developer/WSBindingProvider\", \"com/sun/xml/ws/developer/WSBindingProvider\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Header\", \"com/sun/xml/ws/api/message/Header\" ),\n  ( \"com.sun.xml.internal.ws.transport.http.client.streaming.chunk.size\", \"com.sun.xml.ws.transport.http.client.streaming.chunk.size\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Headers\", \"com/sun/xml/ws/api/message/Headers\" ),\n  ( \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/internal/ws/api/message/Header;\", \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/ws/api/message/Header;\" ),\n  ( \"([Lcom/sun/xml/internal/ws/api/message/Header;)V\", \"([Lcom/sun/xml/ws/api/message/Header;)V\" ),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "documentation": {}
    },
    {
        "label": "clazz",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "peekOfCode": "clazz = class_file.read_bytes()\n# We want to fix these package names so they work with the open-source Java EE releases instead of OpenJDK 8.\npatches = [\n  ( \"com/sun/xml/internal/ws/developer/WSBindingProvider\", \"com/sun/xml/ws/developer/WSBindingProvider\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Header\", \"com/sun/xml/ws/api/message/Header\" ),\n  ( \"com.sun.xml.internal.ws.transport.http.client.streaming.chunk.size\", \"com.sun.xml.ws.transport.http.client.streaming.chunk.size\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Headers\", \"com/sun/xml/ws/api/message/Headers\" ),\n  ( \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/internal/ws/api/message/Header;\", \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/ws/api/message/Header;\" ),\n  ( \"([Lcom/sun/xml/internal/ws/api/message/Header;)V\", \"([Lcom/sun/xml/ws/api/message/Header;)V\" ),\n]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "documentation": {}
    },
    {
        "label": "patches",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "peekOfCode": "patches = [\n  ( \"com/sun/xml/internal/ws/developer/WSBindingProvider\", \"com/sun/xml/ws/developer/WSBindingProvider\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Header\", \"com/sun/xml/ws/api/message/Header\" ),\n  ( \"com.sun.xml.internal.ws.transport.http.client.streaming.chunk.size\", \"com.sun.xml.ws.transport.http.client.streaming.chunk.size\" ),\n  ( \"com/sun/xml/internal/ws/api/message/Headers\", \"com/sun/xml/ws/api/message/Headers\" ),\n  ( \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/internal/ws/api/message/Header;\", \"(Lorg/w3c/dom/Element;)Lcom/sun/xml/ws/api/message/Header;\" ),\n  ( \"([Lcom/sun/xml/internal/ws/api/message/Header;)V\", \"([Lcom/sun/xml/ws/api/message/Header;)V\" ),\n]\nfor old, new in patches:\n  old_java = to_java_string(old)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.patch_paths",
        "documentation": {}
    },
    {
        "label": "save_api",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "peekOfCode": "save_api = waybackpy.WaybackMachineSaveAPI(\"https://nav.gov.hu/pfile/programFile?path=/nyomtatvanyok/letoltesek/nyomtatvanykitolto_programok/nyomtatvany_apeh/keretprogramok/AbevJava\")\nurl = save_api.save()\nprint(\"Prefetching...\")\nsha256, unpack_path = subprocess.check_output([\"nix-prefetch-url\", \"--unpack\", \"--print-path\", url], universal_newlines=True).split(\"\\n\")[:2]\nprint(\"Extracting version...\")\nmanifest = (Path(unpack_path) / \"META-INF\" / \"MANIFEST.MF\").read_text()\nversion = re.search(\"Implementation-Version: (.+)\", manifest).group(1)\nprint(\"Writing version.json...\")\n(Path(__file__).parent / \"version.json\").write_text(json.dumps({\n  \"url\": url,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "peekOfCode": "url = save_api.save()\nprint(\"Prefetching...\")\nsha256, unpack_path = subprocess.check_output([\"nix-prefetch-url\", \"--unpack\", \"--print-path\", url], universal_newlines=True).split(\"\\n\")[:2]\nprint(\"Extracting version...\")\nmanifest = (Path(unpack_path) / \"META-INF\" / \"MANIFEST.MF\").read_text()\nversion = re.search(\"Implementation-Version: (.+)\", manifest).group(1)\nprint(\"Writing version.json...\")\n(Path(__file__).parent / \"version.json\").write_text(json.dumps({\n  \"url\": url,\n  \"sha256\": sha256,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "documentation": {}
    },
    {
        "label": "manifest",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "peekOfCode": "manifest = (Path(unpack_path) / \"META-INF\" / \"MANIFEST.MF\").read_text()\nversion = re.search(\"Implementation-Version: (.+)\", manifest).group(1)\nprint(\"Writing version.json...\")\n(Path(__file__).parent / \"version.json\").write_text(json.dumps({\n  \"url\": url,\n  \"sha256\": sha256,\n  \"version\": version,\n}, indent=2) + \"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "peekOfCode": "version = re.search(\"Implementation-Version: (.+)\", manifest).group(1)\nprint(\"Writing version.json...\")\n(Path(__file__).parent / \"version.json\").write_text(json.dumps({\n  \"url\": url,\n  \"sha256\": sha256,\n  \"version\": version,\n}, indent=2) + \"\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.an.anyk.update",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "peekOfCode": "parser = ArgumentParser()\nparser.add_argument('input', type=Path)\nparser.add_argument('output', type=Path)\nargs = parser.parse_args()\ninput_bytes = args.input.read_bytes()\noutput_bytes = bg.remove(\n  input_bytes,\n)\nargs.output.write_bytes(output_bytes)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "peekOfCode": "args = parser.parse_args()\ninput_bytes = args.input.read_bytes()\noutput_bytes = bg.remove(\n  input_bytes,\n)\nargs.output.write_bytes(output_bytes)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "documentation": {}
    },
    {
        "label": "input_bytes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "peekOfCode": "input_bytes = args.input.read_bytes()\noutput_bytes = bg.remove(\n  input_bytes,\n)\nargs.output.write_bytes(output_bytes)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "documentation": {}
    },
    {
        "label": "output_bytes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "peekOfCode": "output_bytes = bg.remove(\n  input_bytes,\n)\nargs.output.write_bytes(output_bytes)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ba.backgroundremover.test-script",
        "documentation": {}
    },
    {
        "label": "parsers",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "peekOfCode": "parsers = {}\ndir = Path(__file__).parent\nregex = re.compile(r\"^TREESITTER_([A-Z_]+)_(URL|SHA256)\\s+(.+)$\")\nsrc = subprocess.check_output(\n    [\n        \"nix-build\",\n        dir.parent.parent.parent.parent,\n        \"-A\",\n        \"neovim-unwrapped.src\",\n        \"--no-out-link\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "documentation": {}
    },
    {
        "label": "dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "peekOfCode": "dir = Path(__file__).parent\nregex = re.compile(r\"^TREESITTER_([A-Z_]+)_(URL|SHA256)\\s+(.+)$\")\nsrc = subprocess.check_output(\n    [\n        \"nix-build\",\n        dir.parent.parent.parent.parent,\n        \"-A\",\n        \"neovim-unwrapped.src\",\n        \"--no-out-link\",\n    ],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "documentation": {}
    },
    {
        "label": "regex",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "peekOfCode": "regex = re.compile(r\"^TREESITTER_([A-Z_]+)_(URL|SHA256)\\s+(.+)$\")\nsrc = subprocess.check_output(\n    [\n        \"nix-build\",\n        dir.parent.parent.parent.parent,\n        \"-A\",\n        \"neovim-unwrapped.src\",\n        \"--no-out-link\",\n    ],\n    text=True,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "documentation": {}
    },
    {
        "label": "src",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "peekOfCode": "src = subprocess.check_output(\n    [\n        \"nix-build\",\n        dir.parent.parent.parent.parent,\n        \"-A\",\n        \"neovim-unwrapped.src\",\n        \"--no-out-link\",\n    ],\n    text=True,\n).strip()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ne.neovim-unwrapped.update-treesitter-parsers",
        "documentation": {}
    },
    {
        "label": "read_edges",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "peekOfCode": "def read_edges(path: str | dict) -> list[str | dict]:\n    if isinstance(path, dict):\n        return [path]\n    assert isinstance(path, str)\n    if not path.startswith(store_dir):\n        return [path]\n    if path in cache:\n        return cache[path]\n    name = f\"references-{path.removeprefix(store_dir)}\"\n    assert os.path.exists(name)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "documentation": {}
    },
    {
        "label": "host_path",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "peekOfCode": "def host_path(mount: str | dict) -> str:\n    if isinstance(mount, dict):\n        return mount[\"host\"]\n    assert isinstance(mount, str), mount\n    return mount\nfor pattern in config:\n    closure = []\n    for path in config[pattern][\"paths\"]:\n        closure.append(path)\n        closure.extend(read_edges(path))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "documentation": {}
    },
    {
        "label": "store_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "peekOfCode": "store_dir = os.environ[\"storeDir\"]\nwith open(os.environ[\"shallowConfigPath\"], \"r\") as f:\n    config = json.load(f)\ncache = {}\ndef read_edges(path: str | dict) -> list[str | dict]:\n    if isinstance(path, dict):\n        return [path]\n    assert isinstance(path, str)\n    if not path.startswith(store_dir):\n        return [path]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "documentation": {}
    },
    {
        "label": "cache",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "peekOfCode": "cache = {}\ndef read_edges(path: str | dict) -> list[str | dict]:\n    if isinstance(path, dict):\n        return [path]\n    assert isinstance(path, str)\n    if not path.startswith(store_dir):\n        return [path]\n    if path in cache:\n        return cache[path]\n    name = f\"references-{path.removeprefix(store_dir)}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.scripts.nix_required_mounts_closure",
        "documentation": {}
    },
    {
        "label": "Mount",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "class Mount(TypedDict):\n    host: PathString\n    guest: PathString\nclass Pattern(TypedDict):\n    onFeatures: List[str]\n    paths: List[Glob | Mount]\n    unsafeFollowSymlinks: bool\nAllowedPatterns: TypeAlias = Dict[str, Pattern]\nparser = ArgumentParser(\"pre-build-hook\")\nparser.add_argument(\"derivation_path\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "class Pattern(TypedDict):\n    onFeatures: List[str]\n    paths: List[Glob | Mount]\n    unsafeFollowSymlinks: bool\nAllowedPatterns: TypeAlias = Dict[str, Pattern]\nparser = ArgumentParser(\"pre-build-hook\")\nparser.add_argument(\"derivation_path\")\nparser.add_argument(\"sandbox_path\", nargs=\"?\")\nparser.add_argument(\"--patterns\", type=Path, required=True)\nparser.add_argument(\"--nix-exe\", type=Path, required=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "symlink_parents",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "def symlink_parents(p: Path) -> List[Path]:\n    out = []\n    while p.is_symlink() and p not in out:\n        parent = p.readlink()\n        if parent.is_relative_to(\".\"):\n            p = p / parent\n        else:\n            p = parent\n        out.append(p)\n    return out",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "get_strings",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "def get_strings(drv_env: dict, name: str) -> List[str]:\n    if \"__json\" in drv_env:\n        return list(json.loads(drv_env[\"__json\"]).get(name, []))\n    else:\n        return drv_env.get(name, \"\").split()\ndef validate_mounts(pattern: Pattern) -> List[Tuple[PathString, PathString, bool]]:\n    roots = []\n    for mount in pattern[\"paths\"]:\n        if isinstance(mount, PathString):\n            matches = glob.glob(mount)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "validate_mounts",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "def validate_mounts(pattern: Pattern) -> List[Tuple[PathString, PathString, bool]]:\n    roots = []\n    for mount in pattern[\"paths\"]:\n        if isinstance(mount, PathString):\n            matches = glob.glob(mount)\n            assert matches, f\"Specified host paths do not exist: {mount}\"\n            roots.extend((m, m, pattern[\"unsafeFollowSymlinks\"]) for m in matches)\n        else:\n            assert isinstance(mount, dict) and \"host\" in mount, mount\n            assert Path(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "entrypoint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "def entrypoint():\n    args = parser.parse_args()\n    VERBOSITY_LEVELS = [logging.ERROR, logging.INFO, logging.DEBUG]\n    level_index = min(args.verbose, len(VERBOSITY_LEVELS) - 1)\n    logging.basicConfig(level=VERBOSITY_LEVELS[level_index])\n    drv_path = args.derivation_path\n    with open(args.patterns, \"r\") as f:\n        allowed_patterns = json.load(f)\n    if not Path(drv_path).exists():\n        logging.error(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "peekOfCode": "parser = ArgumentParser(\"pre-build-hook\")\nparser.add_argument(\"derivation_path\")\nparser.add_argument(\"sandbox_path\", nargs=\"?\")\nparser.add_argument(\"--patterns\", type=Path, required=True)\nparser.add_argument(\"--nix-exe\", type=Path, required=True)\nparser.add_argument(\n    \"--issue-command\",\n    choices=(\"always\", \"conditional\", \"never\"),\n    default=\"conditional\",\n    help=\"Whether to print extra-sandbox-paths\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.by-name.ni.nix-required-mounts.nix_required_mounts",
        "documentation": {}
    },
    {
        "label": "fetch_extension_data",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "def fetch_extension_data(uuid: str, version: str) -> Tuple[str, str]:\n    \"\"\"\n    Download the extension and hash it. We use `nix-prefetch-url` for this for efficiency reasons.\n    Returns a tuple with the hash (Nix-compatible) of the zip file's content and the base64-encoded content of its metadata.json.\n    \"\"\"\n    # The download URLs follow this schema\n    uuid = uuid.replace(\"@\", \"\")\n    url: str = f\"https://extensions.gnome.org/extension-data/{uuid}.v{version}.shell-extension.zip\"\n    # Download extension and add the zip content to nix-store\n    process = subprocess.run(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "generate_extension_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "def generate_extension_versions(\n        extension_version_map: Dict[ShellVersion, ExtensionVersion], uuid: str\n) -> Dict[ShellVersion, Dict[str, str]]:\n    \"\"\"\n    Takes in a mapping from shell versions to extension versions and transforms it the way we need it:\n    - Only take one extension version per GNOME Shell major version (as per `supported_versions`)\n    - Filter out versions that only support old GNOME versions\n    - Download the extension and hash it\n    \"\"\"\n    # Determine extension version per shell version",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "pname_from_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "def pname_from_url(url: str) -> Tuple[str, str]:\n    \"\"\"\n    Parse something like \"/extension/1475/battery-time/\" and output (\"battery-time\", \"1475\")\n    \"\"\"\n    url = url.split(\"/\")  # type: ignore\n    return url[3], url[2]\ndef process_extension(extension: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Process an extension. It takes in raw scraped data and downloads all the necessary information that buildGnomeExtension.nix requires\n        Input: a json object of one extension queried from the site. It has the following schema (only important key listed):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "process_extension",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "def process_extension(extension: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Process an extension. It takes in raw scraped data and downloads all the necessary information that buildGnomeExtension.nix requires\n        Input: a json object of one extension queried from the site. It has the following schema (only important key listed):\n            {\n                \"uuid\": str,\n                \"name\": str,\n                \"description\": str,\n                \"link\": str,\n                \"shell_version_map\": {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "scrape_extensions_index",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "def scrape_extensions_index() -> List[Dict[str, Any]]:\n    \"\"\"\n    Scrape the list of extensions by sending search queries to the API. We simply go over it\n    page by page until we hit a non-full page or a 404 error.\n    The returned list is sorted by the age of the extension, in order to be deterministic.\n    \"\"\"\n    page = 0\n    extensions = []\n    while True:\n        page += 1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "supported_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "supported_versions = {\n    \"38\": \"3.38\",\n    \"40\": \"40\",\n    \"41\": \"41\",\n    \"42\": \"42\",\n    \"43\": \"43\",\n    \"44\": \"44\",\n    \"45\": \"45\",\n    \"46\": \"46\",\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "PackageName",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "PackageName = str\nShellVersion = str\nUuid = str\nExtensionVersion = int\n# Keep track of all names that have been used till now to detect collisions.\n# This works because we deterministically process all extensions in historical order\n# The outer dict level is the shell version, as we are tracking duplicates only per same Shell version.\n# key: shell version, value: Dict with key: pname, value: list of UUIDs with that pname\npackage_name_registry: Dict[ShellVersion, Dict[PackageName, List[Uuid]]] = {}\nfor shell_version in supported_versions.keys():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "ShellVersion",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "ShellVersion = str\nUuid = str\nExtensionVersion = int\n# Keep track of all names that have been used till now to detect collisions.\n# This works because we deterministically process all extensions in historical order\n# The outer dict level is the shell version, as we are tracking duplicates only per same Shell version.\n# key: shell version, value: Dict with key: pname, value: list of UUIDs with that pname\npackage_name_registry: Dict[ShellVersion, Dict[PackageName, List[Uuid]]] = {}\nfor shell_version in supported_versions.keys():\n    package_name_registry[shell_version] = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "Uuid",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "Uuid = str\nExtensionVersion = int\n# Keep track of all names that have been used till now to detect collisions.\n# This works because we deterministically process all extensions in historical order\n# The outer dict level is the shell version, as we are tracking duplicates only per same Shell version.\n# key: shell version, value: Dict with key: pname, value: list of UUIDs with that pname\npackage_name_registry: Dict[ShellVersion, Dict[PackageName, List[Uuid]]] = {}\nfor shell_version in supported_versions.keys():\n    package_name_registry[shell_version] = {}\nupdater_dir_path = Path(__file__).resolve().parent",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "ExtensionVersion",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "ExtensionVersion = int\n# Keep track of all names that have been used till now to detect collisions.\n# This works because we deterministically process all extensions in historical order\n# The outer dict level is the shell version, as we are tracking duplicates only per same Shell version.\n# key: shell version, value: Dict with key: pname, value: list of UUIDs with that pname\npackage_name_registry: Dict[ShellVersion, Dict[PackageName, List[Uuid]]] = {}\nfor shell_version in supported_versions.keys():\n    package_name_registry[shell_version] = {}\nupdater_dir_path = Path(__file__).resolve().parent\ndef fetch_extension_data(uuid: str, version: str) -> Tuple[str, str]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "updater_dir_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "peekOfCode": "updater_dir_path = Path(__file__).resolve().parent\ndef fetch_extension_data(uuid: str, version: str) -> Tuple[str, str]:\n    \"\"\"\n    Download the extension and hash it. We use `nix-prefetch-url` for this for efficiency reasons.\n    Returns a tuple with the hash (Nix-compatible) of the zip file's content and the base64-encoded content of its metadata.json.\n    \"\"\"\n    # The download URLs follow this schema\n    uuid = uuid.replace(\"@\", \"\")\n    url: str = f\"https://extensions.gnome.org/extension-data/{uuid}.v{version}.shell-extension.zip\"\n    # Download extension and add the zip content to nix-store",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.extensions.update-extensions",
        "documentation": {}
    },
    {
        "label": "Stability",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "class Stability(Enum):\n    STABLE = \"stable\"\n    UNSTABLE = \"unstable\"\nVersionPolicy = Callable[[Version], bool]\nVersionPredicate = Callable[[Version, Stability], bool]\nclass VersionPredicateHolder(NamedTuple):\n    function: VersionPredicate\ndef version_to_list(version: str) -> List[int]:\n    return list(map(int, version.split(\".\")))\ndef odd_unstable(version: Version, selected: Stability) -> bool:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "VersionPredicateHolder",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "class VersionPredicateHolder(NamedTuple):\n    function: VersionPredicate\ndef version_to_list(version: str) -> List[int]:\n    return list(map(int, version.split(\".\")))\ndef odd_unstable(version: Version, selected: Stability) -> bool:\n    try:\n        version_parts = version_to_list(version.value)\n    except:\n        # Failing to parse as a list of numbers likely means the version contains a string tag like beta, therefore it is not a stable release.\n        return selected != Stability.STABLE",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "VersionPolicyKind",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "class VersionPolicyKind(Enum):\n    # HACK: Using function as values directly would make Enum\n    # think they are methods and skip them.\n    ODD_UNSTABLE = VersionPredicateHolder(odd_unstable)\n    TAGGED = VersionPredicateHolder(tagged)\n    NONE = VersionPredicateHolder(no_policy)\ndef make_version_policy(\n    version_policy_kind: VersionPolicyKind,\n    selected: Stability,\n    upper_bound: Optional[Version],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "enum_to_arg",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def enum_to_arg(enum: Enum) -> str:\n    return enum.name.lower().replace(\"_\", \"-\")\ndef arg_to_enum(enum_meta: Type[EnumValue], name: str) -> EnumValue:\n    return enum_meta[name.upper().replace(\"-\", \"_\")]\ndef enum_to_arg_choices(enum_meta: Type[EnumValue]) -> Tuple[str, ...]:\n    return tuple(enum_to_arg(v) for v in cast(Iterable[EnumValue], enum_meta))\nclass Stability(Enum):\n    STABLE = \"stable\"\n    UNSTABLE = \"unstable\"\nVersionPolicy = Callable[[Version], bool]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "arg_to_enum",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def arg_to_enum(enum_meta: Type[EnumValue], name: str) -> EnumValue:\n    return enum_meta[name.upper().replace(\"-\", \"_\")]\ndef enum_to_arg_choices(enum_meta: Type[EnumValue]) -> Tuple[str, ...]:\n    return tuple(enum_to_arg(v) for v in cast(Iterable[EnumValue], enum_meta))\nclass Stability(Enum):\n    STABLE = \"stable\"\n    UNSTABLE = \"unstable\"\nVersionPolicy = Callable[[Version], bool]\nVersionPredicate = Callable[[Version, Stability], bool]\nclass VersionPredicateHolder(NamedTuple):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "enum_to_arg_choices",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def enum_to_arg_choices(enum_meta: Type[EnumValue]) -> Tuple[str, ...]:\n    return tuple(enum_to_arg(v) for v in cast(Iterable[EnumValue], enum_meta))\nclass Stability(Enum):\n    STABLE = \"stable\"\n    UNSTABLE = \"unstable\"\nVersionPolicy = Callable[[Version], bool]\nVersionPredicate = Callable[[Version, Stability], bool]\nclass VersionPredicateHolder(NamedTuple):\n    function: VersionPredicate\ndef version_to_list(version: str) -> List[int]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "version_to_list",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def version_to_list(version: str) -> List[int]:\n    return list(map(int, version.split(\".\")))\ndef odd_unstable(version: Version, selected: Stability) -> bool:\n    try:\n        version_parts = version_to_list(version.value)\n    except:\n        # Failing to parse as a list of numbers likely means the version contains a string tag like beta, therefore it is not a stable release.\n        return selected != Stability.STABLE\n    if len(version_parts) < 2:\n        return True",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "odd_unstable",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def odd_unstable(version: Version, selected: Stability) -> bool:\n    try:\n        version_parts = version_to_list(version.value)\n    except:\n        # Failing to parse as a list of numbers likely means the version contains a string tag like beta, therefore it is not a stable release.\n        return selected != Stability.STABLE\n    if len(version_parts) < 2:\n        return True\n    even = version_parts[1] % 2 == 0\n    prerelease = (version_parts[1] >= 90 and version_parts[1] < 100) or (version_parts[1] >= 900 and version_parts[1] < 1000)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "tagged",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def tagged(version: Version, selected: Stability) -> bool:\n    if selected == Stability.STABLE:\n        return not (\"alpha\" in version.value or \"beta\" in version.value or \"rc\" in version.value)\n    else:\n        return True\ndef no_policy(version: Version, selected: Stability) -> bool:\n    return True\nclass VersionPolicyKind(Enum):\n    # HACK: Using function as values directly would make Enum\n    # think they are methods and skip them.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "no_policy",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def no_policy(version: Version, selected: Stability) -> bool:\n    return True\nclass VersionPolicyKind(Enum):\n    # HACK: Using function as values directly would make Enum\n    # think they are methods and skip them.\n    ODD_UNSTABLE = VersionPredicateHolder(odd_unstable)\n    TAGGED = VersionPredicateHolder(tagged)\n    NONE = VersionPredicateHolder(no_policy)\ndef make_version_policy(\n    version_policy_kind: VersionPolicyKind,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "make_version_policy",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def make_version_policy(\n    version_policy_kind: VersionPolicyKind,\n    selected: Stability,\n    upper_bound: Optional[Version],\n) -> VersionPolicy:\n    version_predicate = version_policy_kind.value.function\n    if not upper_bound:\n        return lambda version: version_predicate(version, selected)\n    else:\n        return lambda version: version_predicate(version, selected) and version < upper_bound",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "find_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "def find_versions(package_name: str, version_policy: VersionPolicy) -> List[Version]:\n    # The structure of cache.json: https://gitlab.gnome.org/Infrastructure/sysadmin-bin/blob/master/ftpadmin#L762\n    cache = json.loads(requests.get(f\"https://ftp.gnome.org/pub/GNOME/sources/{package_name}/cache.json\").text)\n    if type(cache) != list or cache[0] != 4:\n        raise Exception(\"Unknown format of cache.json file.\")\n    versions: Iterable[Version] = map(Version, cache[2][package_name])\n    versions = sorted(filter(version_policy, versions))\n    return versions\nparser = argparse.ArgumentParser(\n    description=\"Find latest version for a GNOME package by crawling their release server.\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "EnumValue",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "EnumValue = TypeVar(\"EnumValue\", bound=Enum)\ndef enum_to_arg(enum: Enum) -> str:\n    return enum.name.lower().replace(\"_\", \"-\")\ndef arg_to_enum(enum_meta: Type[EnumValue], name: str) -> EnumValue:\n    return enum_meta[name.upper().replace(\"-\", \"_\")]\ndef enum_to_arg_choices(enum_meta: Type[EnumValue]) -> Tuple[str, ...]:\n    return tuple(enum_to_arg(v) for v in cast(Iterable[EnumValue], enum_meta))\nclass Stability(Enum):\n    STABLE = \"stable\"\n    UNSTABLE = \"unstable\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "VersionPolicy",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "VersionPolicy = Callable[[Version], bool]\nVersionPredicate = Callable[[Version, Stability], bool]\nclass VersionPredicateHolder(NamedTuple):\n    function: VersionPredicate\ndef version_to_list(version: str) -> List[int]:\n    return list(map(int, version.split(\".\")))\ndef odd_unstable(version: Version, selected: Stability) -> bool:\n    try:\n        version_parts = version_to_list(version.value)\n    except:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "VersionPredicate",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "VersionPredicate = Callable[[Version, Stability], bool]\nclass VersionPredicateHolder(NamedTuple):\n    function: VersionPredicate\ndef version_to_list(version: str) -> List[int]:\n    return list(map(int, version.split(\".\")))\ndef odd_unstable(version: Version, selected: Stability) -> bool:\n    try:\n        version_parts = version_to_list(version.value)\n    except:\n        # Failing to parse as a list of numbers likely means the version contains a string tag like beta, therefore it is not a stable release.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "peekOfCode": "parser = argparse.ArgumentParser(\n    description=\"Find latest version for a GNOME package by crawling their release server.\",\n)\nparser.add_argument(\n    \"package-name\",\n    help=\"Name of the directory in https://ftp.gnome.org/pub/GNOME/sources/ containing the package.\",\n)\nparser.add_argument(\n    \"version-policy\",\n    help=\"Policy determining which versions are considered stable. GNOME packages usually denote stability by alpha/beta/rc tag in the version. For older packages, odd minor versions are unstable but there are exceptions.\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.desktops.gnome.find-latest-version",
        "documentation": {}
    },
    {
        "label": "get_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "def get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:\n        print(\"error: could not fetch checksum from url {}: code {}\".format(url, resp.status_code), file=sys.stderr)\n        sys.exit(1)\n    return resp.text.strip().split(\" \")[0]\ndef generate_sources(release, assets):\n    out = {}\n    for asset in assets:\n        if asset[\"os\"] not in oses: continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "generate_sources",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "def generate_sources(release, assets):\n    out = {}\n    for asset in assets:\n        if asset[\"os\"] not in oses: continue\n        if asset[\"binary_type\"] not in types: continue\n        if asset[\"openjdk_impl\"] not in impls: continue\n        if asset[\"heap_size\"] != \"normal\": continue\n        if asset[\"architecture\"] not in arch_to_nixos: continue\n        # examples: 11.0.1+13, 8.0.222+10\n        version, build = asset[\"version_data\"][\"semver\"].split(\"+\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "releases",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "releases = (\"openjdk8\", \"openjdk11\", \"openjdk13\", \"openjdk14\", \"openjdk15\", \"openjdk16\", \"openjdk17\")\noses = (\"mac\", \"linux\", \"alpine_linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"hotspot\", \"openj9\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "oses",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "oses = (\"mac\", \"linux\", \"alpine_linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"hotspot\", \"openj9\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef get_sha256(url):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "types = (\"jre\", \"jdk\")\nimpls = (\"hotspot\", \"openj9\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef get_sha256(url):\n    resp = requests.get(url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "impls",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "impls = (\"hotspot\", \"openj9\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "arch_to_nixos",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "arch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:\n        print(\"error: could not fetch checksum from url {}: code {}\".format(url, resp.status_code), file=sys.stderr)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "peekOfCode": "out = {}\nfor release in releases:\n    resp = requests.get(\"https://api.adoptopenjdk.net/v2/latestAssets/releases/\" + release)\n    if resp.status_code != 200:\n        print(\"error: could not fetch data for release {} (code {})\".format(release, resp.code), file=sys.stderr)\n        sys.exit(1)\n    out[release] = generate_sources(release, resp.json())\nwith open(\"sources.json\", \"w\") as f:\n    json.dump(out, f, indent=2, sort_keys=True)\n    f.write('\\n')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.adoptopenjdk-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "SetConfigPath",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "peekOfCode": "def SetConfigPath(options):\n  \"\"\"Set the PKG_CONFIG_LIBDIR environment variable.\n  This takes into account any sysroot and architecture specification from the\n  options on the given command line.\n  \"\"\"\n  sysroot = options.sysroot\n  assert sysroot\n  # Compute the library path name based on the architecture.\n  arch = options.arch\n  if sysroot and not arch:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "documentation": {}
    },
    {
        "label": "GetPkgConfigPrefixToStrip",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "peekOfCode": "def GetPkgConfigPrefixToStrip(options, args):\n  \"\"\"Returns the prefix from pkg-config where packages are installed.\n  This returned prefix is the one that should be stripped from the beginning of\n  directory names to take into account sysroots.\n  \"\"\"\n  # Some sysroots, like the Chromium OS ones, may generate paths that are not\n  # relative to the sysroot. For example,\n  # /path/to/chroot/build/x86-generic/usr/lib/pkgconfig/pkg.pc may have all\n  # paths relative to /path/to/chroot (i.e. prefix=/build/x86-generic/usr)\n  # instead of relative to /path/to/chroot/build/x86-generic (i.e prefix=/usr).",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "documentation": {}
    },
    {
        "label": "MatchesAnyRegexp",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "peekOfCode": "def MatchesAnyRegexp(flag, list_of_regexps):\n  \"\"\"Returns true if the first argument matches any regular expression in the\n  given list.\"\"\"\n  for regexp in list_of_regexps:\n    if regexp.search(flag) != None:\n      return True\n  return False\ndef RewritePath(path, strip_prefix, sysroot):\n  \"\"\"Rewrites a path by stripping the prefix and prepending the sysroot.\"\"\"\n  if os.path.isabs(path) and not path.startswith(sysroot):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "documentation": {}
    },
    {
        "label": "RewritePath",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "peekOfCode": "def RewritePath(path, strip_prefix, sysroot):\n  \"\"\"Rewrites a path by stripping the prefix and prepending the sysroot.\"\"\"\n  if os.path.isabs(path) and not path.startswith(sysroot):\n    if path.startswith(strip_prefix):\n      path = path[len(strip_prefix):]\n    path = path.lstrip('/')\n    return os.path.join(sysroot, path)\n  else:\n    return path\ndef main():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "peekOfCode": "def main():\n  # If this is run on non-Linux platforms, just return nothing and indicate\n  # success. This allows us to \"kind of emulate\" a Linux build from other\n  # platforms.\n  if \"linux\" not in sys.platform:\n    print(\"[[],[],[],[],[]]\")\n    return 0\n  parser = OptionParser()\n  parser.add_option('-d', '--debug', action='store_true')\n  parser.add_option('-p', action='store', dest='pkg_config', type='string',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.engine.pkg-config",
        "documentation": {}
    },
    {
        "label": "load_code",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def load_code(name, **kwargs):\n    with open(f\"{NIXPKGS_ROOT}/pkgs/development/compilers/flutter/update/{name}.in\", 'r') as f:\n        code = f.read()\n    for (key, value) in kwargs.items():\n        code = code.replace(f\"@{key}@\", value)\n    return code\n# Return out paths\ndef nix_build(code):\n    temp = tempfile.NamedTemporaryFile(mode='w')\n    temp.write(code)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "nix_build",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def nix_build(code):\n    temp = tempfile.NamedTemporaryFile(mode='w')\n    temp.write(code)\n    temp.flush()\n    os.fsync(temp.fileno())\n    process = subprocess.Popen(\n        [\n            \"nix-build\",\n            \"--impure\",\n            \"--no-out-link\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "nix_build_to_fail",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def nix_build_to_fail(code):\n    temp = tempfile.NamedTemporaryFile(mode='w')\n    temp.write(code)\n    temp.flush()\n    os.fsync(temp.fileno())\n    process = subprocess.Popen(\n        [\n            \"nix-build\",\n            \"--impure\",\n            \"--keep-going\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_engine_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_engine_hashes(engine_version):\n    code = load_code(\"get-engine-hashes.nix\",\n                     nixpkgs_root=NIXPKGS_ROOT,\n                     engine_version=engine_version)\n    stderr = nix_build_to_fail(code)\n    pattern = re.compile(\n        r\"/nix/store/.*-flutter-engine-source-(.+?)-(.+?).drv':\\n\\s+specified: .*\\n\\s+got:\\s+(.+?)\\n\")\n    matches = pattern.findall(stderr)\n    result_dict = {}\n    for match in matches:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_artifact_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_artifact_hashes(flutter_compact_version):\n    code = load_code(\"get-artifact-hashes.nix\",\n                     nixpkgs_root=NIXPKGS_ROOT,\n                     flutter_compact_version=flutter_compact_version)\n    stderr = nix_build_to_fail(code)\n    pattern = re.compile(\n        r\"/nix/store/.*-flutter-artifacts-(.+?)-(.+?).drv':\\n\\s+specified: .*\\n\\s+got:\\s+(.+?)\\n\")\n    matches = pattern.findall(stderr)\n    result_dict = {}\n    for match in matches:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_dart_hashes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_dart_hashes(dart_version, channel):\n    platforms = [\n        \"x86_64-linux\",\n        \"aarch64-linux\",\n        \"x86_64-darwin\",\n        \"aarch64-darwin\"]\n    result_dict = {}\n    for platform in platforms:\n        code = load_code(\n            \"get-dart-hashes.nix\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_flutter_hash_and_src",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_flutter_hash_and_src(flutter_version):\n    code = load_code(\n        \"get-flutter.nix\",\n        flutter_version=flutter_version,\n        hash=\"\")\n    stderr = nix_build_to_fail(code)\n    pattern = re.compile(r\"got:\\s+(.+?)\\n\")\n    hash = pattern.findall(stderr)[0]\n    code = load_code(\n        \"get-flutter.nix\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_pubspec_lock",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_pubspec_lock(flutter_compact_version, flutter_src):\n    code = load_code(\n        \"get-pubspec-lock.nix\",\n        flutter_compact_version=flutter_compact_version,\n        flutter_src=flutter_src,\n        hash=\"\")\n    stderr = nix_build_to_fail(code)\n    pattern = re.compile(r\"got:\\s+(.+?)\\n\")\n    hash = pattern.findall(stderr)[0]\n    code = load_code(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_engine_swiftshader_rev",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_engine_swiftshader_rev(engine_version):\n    with urllib.request.urlopen(f\"https://github.com/flutter/engine/raw/{engine_version}/DEPS\") as f:\n        deps = f.read().decode('utf-8')\n        pattern = re.compile(r\"Var\\('swiftshader_git'\\) \\+ '\\/SwiftShader\\.git' \\+ '@' \\+ \\'([0-9a-fA-F]{40})\\'\\,\")\n        rev = pattern.findall(deps)[0]\n        return rev\ndef get_engine_swiftshader_hash(engine_swiftshader_rev):\n    code = load_code(\n        \"get-engine-swiftshader.nix\",\n        engine_swiftshader_rev=engine_swiftshader_rev,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_engine_swiftshader_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def get_engine_swiftshader_hash(engine_swiftshader_rev):\n    code = load_code(\n        \"get-engine-swiftshader.nix\",\n        engine_swiftshader_rev=engine_swiftshader_rev,\n        hash=\"\")\n    stderr = nix_build_to_fail(code)\n    pattern = re.compile(r\"got:\\s+(.+?)\\n\")\n    return pattern.findall(stderr)[0]\ndef write_data(\n        nixpkgs_flutter_version_directory,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "write_data",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def write_data(\n        nixpkgs_flutter_version_directory,\n        flutter_version,\n        channel,\n        engine_hash,\n        engine_hashes,\n        engine_swiftshader_hash,\n        engine_swiftshader_rev,\n        dart_version,\n        dart_hash,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "update_all_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def update_all_packages():\n    versions_directory = f\"{NIXPKGS_ROOT}/pkgs/development/compilers/flutter/versions\"\n    versions = [directory for directory in os.listdir(versions_directory)]\n    versions = sorted(versions, key=lambda x: (\n        int(x.split('_')[0]), int(x.split('_')[1])), reverse=True)\n    new_content = [\n        \"flutterPackages-bin = recurseIntoAttrs (callPackage ../development/compilers/flutter { });\",\n        \"flutterPackages-source = recurseIntoAttrs (callPackage ../development/compilers/flutter { useNixpkgsEngine = true; });\",\n        \"flutterPackages = flutterPackages-bin;\"\n        \"flutter = flutterPackages.stable;\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "find_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def find_versions(flutter_version=None, channel=None):\n    engine_hash = None\n    dart_version = None\n    releases = json.load(urllib.request.urlopen(\n        \"https://storage.googleapis.com/flutter_infra_release/releases/releases_linux.json\"))\n    if not channel:\n        channel = 'stable'\n    if not flutter_version:\n        hash = releases['current_release'][channel]\n        release = next(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description='Update Flutter in Nixpkgs')\n    parser.add_argument('--version', type=str, help='Specify Flutter version')\n    parser.add_argument('--channel', type=str, help='Specify Flutter release channel')\n    parser.add_argument('--artifact-hashes', action='store_true',\n                        help='Whether to get artifact hashes')\n    args = parser.parse_args()\n    (flutter_version, engine_hash, dart_version, channel) = find_versions(args.version, args.channel)\n    flutter_compact_version = '_'.join(flutter_version.split('.')[:2])\n    if args.artifact_hashes:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "FAKE_HASH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "FAKE_HASH = 'sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA='\nNIXPKGS_ROOT = subprocess.Popen(['git',\n                                 'rev-parse',\n                                 '--show-toplevel'],\n                                stdout=subprocess.PIPE,\n                                text=True).communicate()[0].strip()\ndef load_code(name, **kwargs):\n    with open(f\"{NIXPKGS_ROOT}/pkgs/development/compilers/flutter/update/{name}.in\", 'r') as f:\n        code = f.read()\n    for (key, value) in kwargs.items():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "peekOfCode": "NIXPKGS_ROOT = subprocess.Popen(['git',\n                                 'rev-parse',\n                                 '--show-toplevel'],\n                                stdout=subprocess.PIPE,\n                                text=True).communicate()[0].strip()\ndef load_code(name, **kwargs):\n    with open(f\"{NIXPKGS_ROOT}/pkgs/development/compilers/flutter/update/{name}.in\", 'r') as f:\n        code = f.read()\n    for (key, value) in kwargs.items():\n        code = code.replace(f\"@{key}@\", value)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.flutter.update.update",
        "documentation": {}
    },
    {
        "label": "get_latest_chromium_build",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "def get_latest_chromium_build():\n    RELEASES_URL = 'https://versionhistory.googleapis.com/v1/chrome/platforms/linux/channels/dev/versions/all/releases?filter=endtime=none&order_by=version%20desc'\n    print(f'GET {RELEASES_URL}')\n    with urlopen(RELEASES_URL) as resp:\n        return json.load(resp)['releases'][0]\ndef get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://raw.githubusercontent.com/chromium/chromium/{revision}/{file_path}'\n    with urlopen(url) as http_response:\n        return http_response.read().decode()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "get_file_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "def get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://raw.githubusercontent.com/chromium/chromium/{revision}/{file_path}'\n    with urlopen(url) as http_response:\n        return http_response.read().decode()\ndef get_commit(ref):\n    url = f'https://api.github.com/repos/llvm/llvm-project/commits/{ref}'\n    headers = {'Accept': 'application/vnd.github.v3+json'}\n    request = Request(url, headers=headers)\n    with urlopen(request) as http_response:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "get_commit",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "def get_commit(ref):\n    url = f'https://api.github.com/repos/llvm/llvm-project/commits/{ref}'\n    headers = {'Accept': 'application/vnd.github.v3+json'}\n    request = Request(url, headers=headers)\n    with urlopen(request) as http_response:\n        return json.loads(http_response.read().decode())\ndef get_current_revision():\n    \"\"\"Get the current revision of llvmPackages_git.\"\"\"\n    with open(DEFAULT_NIX) as f:\n        for line in f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "get_current_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "def get_current_revision():\n    \"\"\"Get the current revision of llvmPackages_git.\"\"\"\n    with open(DEFAULT_NIX) as f:\n        for line in f:\n            rev = re.search(r'^    rev = \"(.*)\";', line)\n            if rev:\n                return rev.group(1)\n    sys.exit(1)\ndef nix_prefetch_url(url, algo='sha256'):\n    \"\"\"Prefetches the content of the given URL.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "def nix_prefetch_url(url, algo='sha256'):\n    \"\"\"Prefetches the content of the given URL.\"\"\"\n    print(f'nix-prefetch-url {url}')\n    out = subprocess.check_output(['nix-prefetch-url', '--type', algo, '--unpack', url])\n    return out.decode('utf-8').rstrip()\nchromium_build = get_latest_chromium_build()\nchromium_version = chromium_build['version']\nprint(f'chromiumDev version: {chromium_version}')\nprint('Getting LLVM commit...')\nclang_update_script = get_file_revision(chromium_version, 'tools/clang/scripts/update.py')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "DEFAULT_NIX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "DEFAULT_NIX = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'git/default.nix')\ndef get_latest_chromium_build():\n    RELEASES_URL = 'https://versionhistory.googleapis.com/v1/chrome/platforms/linux/channels/dev/versions/all/releases?filter=endtime=none&order_by=version%20desc'\n    print(f'GET {RELEASES_URL}')\n    with urlopen(RELEASES_URL) as resp:\n        return json.load(resp)['releases'][0]\ndef get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://raw.githubusercontent.com/chromium/chromium/{revision}/{file_path}'\n    with urlopen(url) as http_response:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "chromium_build",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "chromium_build = get_latest_chromium_build()\nchromium_version = chromium_build['version']\nprint(f'chromiumDev version: {chromium_version}')\nprint('Getting LLVM commit...')\nclang_update_script = get_file_revision(chromium_version, 'tools/clang/scripts/update.py')\nclang_revision = re.search(r\"^CLANG_REVISION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\nclang_commit_short = re.search(r\"llvmorg-[0-9]+-init-[0-9]+-g([0-9a-f]{8})\", clang_revision).group(1)\nrelease_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "chromium_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "chromium_version = chromium_build['version']\nprint(f'chromiumDev version: {chromium_version}')\nprint('Getting LLVM commit...')\nclang_update_script = get_file_revision(chromium_version, 'tools/clang/scripts/update.py')\nclang_revision = re.search(r\"^CLANG_REVISION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\nclang_commit_short = re.search(r\"llvmorg-[0-9]+-init-[0-9]+-g([0-9a-f]{8})\", clang_revision).group(1)\nrelease_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "clang_update_script",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "clang_update_script = get_file_revision(chromium_version, 'tools/clang/scripts/update.py')\nclang_revision = re.search(r\"^CLANG_REVISION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\nclang_commit_short = re.search(r\"llvmorg-[0-9]+-init-[0-9]+-g([0-9a-f]{8})\", clang_revision).group(1)\nrelease_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')\n    sys.exit(0)\ndate = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "clang_revision",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "clang_revision = re.search(r\"^CLANG_REVISION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\nclang_commit_short = re.search(r\"llvmorg-[0-9]+-init-[0-9]+-g([0-9a-f]{8})\", clang_revision).group(1)\nrelease_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')\n    sys.exit(0)\ndate = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'\nprint('Prefetching source tarball...')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "clang_commit_short",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "clang_commit_short = re.search(r\"llvmorg-[0-9]+-init-[0-9]+-g([0-9a-f]{8})\", clang_revision).group(1)\nrelease_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')\n    sys.exit(0)\ndate = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'\nprint('Prefetching source tarball...')\nhash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "release_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "release_version = re.search(r\"^RELEASE_VERSION = '(.+)'$\", clang_update_script, re.MULTILINE).group(1)\ncommit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')\n    sys.exit(0)\ndate = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'\nprint('Prefetching source tarball...')\nhash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')\nprint('Updating default.nix...')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "commit",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "commit = get_commit(clang_commit_short)\nif get_current_revision() == commit[\"sha\"]:\n    print('No new update available.')\n    sys.exit(0)\ndate = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'\nprint('Prefetching source tarball...')\nhash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')\nprint('Updating default.nix...')\nwith fileinput.FileInput(DEFAULT_NIX, inplace=True) as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "date",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "date = datetime.fromisoformat(commit['commit']['committer']['date'].rstrip('Z')).date().isoformat()\nversion = f'unstable-{date}'\nprint('Prefetching source tarball...')\nhash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')\nprint('Updating default.nix...')\nwith fileinput.FileInput(DEFAULT_NIX, inplace=True) as f:\n    for line in f:\n        if match := re.search(r'^    rev-version = \"unstable-(.+)\";', line):\n                old_date = match.group(1)\n        result = re.sub(r'^    version = \".+\";', f'    version = \"{release_version}\";', line)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "version = f'unstable-{date}'\nprint('Prefetching source tarball...')\nhash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')\nprint('Updating default.nix...')\nwith fileinput.FileInput(DEFAULT_NIX, inplace=True) as f:\n    for line in f:\n        if match := re.search(r'^    rev-version = \"unstable-(.+)\";', line):\n                old_date = match.group(1)\n        result = re.sub(r'^    version = \".+\";', f'    version = \"{release_version}\";', line)\n        result = re.sub(r'^    rev = \".*\";', f'    rev = \"{commit[\"sha\"]}\";', result)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "hash",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "hash = nix_prefetch_url(f'https://github.com/llvm/llvm-project/archive/{commit[\"sha\"]}.tar.gz')\nprint('Updating default.nix...')\nwith fileinput.FileInput(DEFAULT_NIX, inplace=True) as f:\n    for line in f:\n        if match := re.search(r'^    rev-version = \"unstable-(.+)\";', line):\n                old_date = match.group(1)\n        result = re.sub(r'^    version = \".+\";', f'    version = \"{release_version}\";', line)\n        result = re.sub(r'^    rev = \".*\";', f'    rev = \"{commit[\"sha\"]}\";', result)\n        result = re.sub(r'^    rev-version = \".+\";', f'    rev-version = \"{version}\";', result)\n        result = re.sub(r'^    sha256 = \".+\";', f'    sha256 = \"{hash}\";', result)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "commit_message",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "peekOfCode": "commit_message = f\"llvmPackages_git: {old_date} -> {date}\"\nsubprocess.run(['git', 'add', DEFAULT_NIX], check=True)\nsubprocess.run(['git', 'commit', '--file=-'], input=commit_message.encode(), check=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.llvm.update-git",
        "documentation": {}
    },
    {
        "label": "get_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "def get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:\n        print(\"error: could not fetch checksum from url {}: code {}\".format(url, resp.status_code), file=sys.stderr)\n        sys.exit(1)\n    return resp.text.strip().split(\" \")[0]\ndef generate_sources(releases, feature_version, out):\n    latest_version = None\n    for release in releases:\n        if release[\"prerelease\"]: continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "generate_sources",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "def generate_sources(releases, feature_version, out):\n    latest_version = None\n    for release in releases:\n        if release[\"prerelease\"]: continue\n        if not re.search(\"_openj9-\", release[\"name\"]): continue\n        for asset in release[\"assets\"]:\n            match = re.match(\"ibm-semeru-open-(?P<image_type>[a-z]*)_(?P<architecture>[a-z0-9]*)_(?P<os>[a-z]*)_(?:(?P<major1>[0-9]*)u(?P<security1>[0-9]*)b(?P<build1>[0-9]*)|(?P<major2>[0-9]*)\\\\.(?P<minor2>[0-9]*)\\\\.(?P<security2>[0-9]*)_(?P<build2>[0-9]*))_(?P<jvm_impl>[a-z0-9]*)-[0-9]*\\\\.[0-9]*\\\\.[0-9]\\\\.tar\\\\.gz$\", asset[\"name\"])\n            if not match: continue\n            if match[\"os\"] not in oses: continue\n            if match[\"image_type\"] not in types: continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "feature_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "feature_versions = (8, 11, 16, 17, 21)\noses = (\"mac\", \"linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"openj9\",)\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n}\ndef get_sha256(url):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "oses",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "oses = (\"mac\", \"linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"openj9\",)\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n}\ndef get_sha256(url):\n    resp = requests.get(url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "types = (\"jre\", \"jdk\")\nimpls = (\"openj9\",)\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n}\ndef get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "impls",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "impls = (\"openj9\",)\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n}\ndef get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:\n        print(\"error: could not fetch checksum from url {}: code {}\".format(url, resp.status_code), file=sys.stderr)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "arch_to_nixos",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "arch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n}\ndef get_sha256(url):\n    resp = requests.get(url)\n    if resp.status_code != 200:\n        print(\"error: could not fetch checksum from url {}: code {}\".format(url, resp.status_code), file=sys.stderr)\n        sys.exit(1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "peekOfCode": "out = {}\nfor feature_version in feature_versions:\n    resp = requests.get(f\"https://api.github.com/repos/ibmruntimes/semeru{feature_version}-binaries/releases\")\n    if resp.status_code != 200:\n        print(\"error: could not fetch data for release {} (code {}) {}\".format(feature_version, resp.status_code, resp.content), file=sys.stderr)\n        sys.exit(1)\n    generate_sources(resp.json(), f\"openjdk{feature_version}\", out)\nwith open(\"sources.json\", \"w\") as f:\n    json.dump(out, f, indent=2, sort_keys=True)\n    f.write('\\n')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.semeru-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "generate_sources",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "def generate_sources(assets, feature_version, out):\n    for asset in assets:\n        binary = asset[\"binary\"]\n        if binary[\"os\"] not in oses: continue\n        if binary[\"image_type\"] not in types: continue\n        if binary[\"jvm_impl\"] not in impls: continue\n        if binary[\"heap_size\"] != \"normal\": continue\n        if binary[\"architecture\"] not in arch_to_nixos: continue\n        version = \".\".join(str(v) for v in [\n            asset[\"version\"][\"major\"],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "feature_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "feature_versions = (8, 11, 16, 17, 18, 19, 20, 21)\noses = (\"mac\", \"linux\", \"alpine-linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"hotspot\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "oses",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "oses = (\"mac\", \"linux\", \"alpine-linux\")\ntypes = (\"jre\", \"jdk\")\nimpls = (\"hotspot\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef generate_sources(assets, feature_version, out):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "types = (\"jre\", \"jdk\")\nimpls = (\"hotspot\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef generate_sources(assets, feature_version, out):\n    for asset in assets:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "impls",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "impls = (\"hotspot\")\narch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef generate_sources(assets, feature_version, out):\n    for asset in assets:\n        binary = asset[\"binary\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "arch_to_nixos",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "arch_to_nixos = {\n    \"x64\": (\"x86_64\",),\n    \"aarch64\": (\"aarch64\",),\n    \"arm\": (\"armv6l\", \"armv7l\"),\n    \"ppc64le\": (\"powerpc64le\",),\n}\ndef generate_sources(assets, feature_version, out):\n    for asset in assets:\n        binary = asset[\"binary\"]\n        if binary[\"os\"] not in oses: continue",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "peekOfCode": "out = {}\nfor feature_version in feature_versions:\n    # Default user-agenet is blocked by Azure WAF.\n    headers = {'user-agent': 'nixpkgs-temurin-generate-sources/1.0.0'}\n    resp = requests.get(f\"https://api.adoptium.net/v3/assets/latest/{feature_version}/hotspot\", headers=headers)\n    if resp.status_code != 200:\n        print(\"error: could not fetch data for release {} (code {}) {}\".format(feature_version, resp.status_code, resp.content), file=sys.stderr)\n        sys.exit(1)\n    generate_sources(resp.json(), f\"openjdk{feature_version}\", out)\nwith open(\"sources.json\", \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.compilers.temurin-bin.generate-sources",
        "documentation": {}
    },
    {
        "label": "get_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "peekOfCode": "def get_name(dist: PathDistribution) -> str:\n    return dist.metadata['name'].lower().replace('-', '_')\n# pretty print a package\ndef describe_package(dist: PathDistribution) -> str:\n    return f\"{get_name(dist)} {dist.version} ({dist._path})\"\n# pretty print a list of parents (dependency chain)\ndef describe_parents(parents: List[str]) -> str:\n    if not parents:\n        return \"\"\n    return \\",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "documentation": {}
    },
    {
        "label": "describe_package",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "peekOfCode": "def describe_package(dist: PathDistribution) -> str:\n    return f\"{get_name(dist)} {dist.version} ({dist._path})\"\n# pretty print a list of parents (dependency chain)\ndef describe_parents(parents: List[str]) -> str:\n    if not parents:\n        return \"\"\n    return \\\n        f\"    dependency chain:\\n      \" \\\n        + str(f\"\\n      ...depending on: \".join(parents))\n# inserts an entry into 'packages'",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "documentation": {}
    },
    {
        "label": "describe_parents",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "peekOfCode": "def describe_parents(parents: List[str]) -> str:\n    if not parents:\n        return \"\"\n    return \\\n        f\"    dependency chain:\\n      \" \\\n        + str(f\"\\n      ...depending on: \".join(parents))\n# inserts an entry into 'packages'\ndef add_entry(name: str, version: str, store_path: str, parents: List[str]) -> None:\n    packages[name][store_path] = dict(\n        version=version,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "documentation": {}
    },
    {
        "label": "add_entry",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "peekOfCode": "def add_entry(name: str, version: str, store_path: str, parents: List[str]) -> None:\n    packages[name][store_path] = dict(\n        version=version,\n        parents=parents,\n    )\n# transitively discover python dependencies and store them in 'packages'\ndef find_packages(store_path: Path, site_packages_path: str, parents: List[str]) -> None:\n    site_packages: Path = (store_path / site_packages_path)\n    propagated_build_inputs: Path = (store_path / \"nix-support/propagated-build-inputs\")\n    # only visit each path once, to avoid exponential complexity with highly",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "peekOfCode": "def find_packages(store_path: Path, site_packages_path: str, parents: List[str]) -> None:\n    site_packages: Path = (store_path / site_packages_path)\n    propagated_build_inputs: Path = (store_path / \"nix-support/propagated-build-inputs\")\n    # only visit each path once, to avoid exponential complexity with highly\n    # connected dependency graphs\n    if store_path in found_paths:\n        return\n    found_paths.add(store_path)\n    # add the current package to the list\n    if site_packages.exists():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts",
        "documentation": {}
    },
    {
        "label": "do_abort",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "peekOfCode": "do_abort = False\npackages = collections.defaultdict(list)\nfor f in sys.path:\n    for req in pkg_resources.find_distributions(f):\n        if req not in packages[req.project_name]:\n            # some exceptions inside buildPythonPackage\n            if req.project_name in ['setuptools', 'pip', 'wheel']:\n                continue\n            packages[req.project_name].append(req)\nfor name, duplicates in packages.items():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "documentation": {}
    },
    {
        "label": "packages",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "peekOfCode": "packages = collections.defaultdict(list)\nfor f in sys.path:\n    for req in pkg_resources.find_distributions(f):\n        if req not in packages[req.project_name]:\n            # some exceptions inside buildPythonPackage\n            if req.project_name in ['setuptools', 'pip', 'wheel']:\n                continue\n            packages[req.project_name].append(req)\nfor name, duplicates in packages.items():\n    if len(duplicates) > 1:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.catch_conflicts.catch_conflicts_py2",
        "documentation": {}
    },
    {
        "label": "error",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "def error(msg: str) -> None:\n    print(f\"  - {msg}\", file=sys.stderr)\ndef normalize_name(name: str) -> str:\n    \"\"\"\n    Normalize package names according to PEP503\n    \"\"\"\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\ndef get_manifest_text_from_wheel(wheel: str) -> str:\n    \"\"\"\n    Given a path to a wheel, this function will try to extract the",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "normalize_name",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "def normalize_name(name: str) -> str:\n    \"\"\"\n    Normalize package names according to PEP503\n    \"\"\"\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\ndef get_manifest_text_from_wheel(wheel: str) -> str:\n    \"\"\"\n    Given a path to a wheel, this function will try to extract the\n    METADATA file in the wheels .dist-info directory.\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "get_manifest_text_from_wheel",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "def get_manifest_text_from_wheel(wheel: str) -> str:\n    \"\"\"\n    Given a path to a wheel, this function will try to extract the\n    METADATA file in the wheels .dist-info directory.\n    \"\"\"\n    with ZipFile(wheel) as zipfile:\n        for zipinfo in zipfile.infolist():\n            if zipinfo.filename.endswith(\".dist-info/METADATA\"):\n                with tempfile.TemporaryDirectory() as tmp:\n                    path = zipfile.extract(zipinfo, path=tmp)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "get_metadata",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "def get_metadata(wheel: str) -> Metadata:\n    \"\"\"\n    Given a path to a wheel, returns a parsed Metadata object.\n    \"\"\"\n    text = get_manifest_text_from_wheel(wheel)\n    raw, _ = parse_email(text)\n    metadata = Metadata.from_raw(raw)\n    return metadata\ndef test_requirement(requirement: Requirement) -> bool:\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "test_requirement",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "def test_requirement(requirement: Requirement) -> bool:\n    \"\"\"\n    Given a requirement specification, tests whether the dependency can\n    be resolved in the local environment, and whether it satisfies the\n    specified version constraints.\n    \"\"\"\n    if requirement.marker and not requirement.marker.evaluate():\n        # ignore requirements with incompatible markers\n        return True\n    package_name = normalize_name(requirement.name)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "argparser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "peekOfCode": "argparser = ArgumentParser()\nargparser.add_argument(\"wheel\", help=\"Path to the .whl file to test\")\ndef error(msg: str) -> None:\n    print(f\"  - {msg}\", file=sys.stderr)\ndef normalize_name(name: str) -> str:\n    \"\"\"\n    Normalize package names according to PEP503\n    \"\"\"\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\ndef get_manifest_text_from_wheel(wheel: str) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.hooks.python-runtime-deps-check-hook",
        "documentation": {}
    },
    {
        "label": "TestCasePython",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "class TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")\n    def test_prefix(self):\n        self.assertEqual(sys.prefix, ENV)\n        self.assertEqual(sys.prefix, sys.exec_prefix)\n    def test_site_prefix(self):\n        self.assertTrue(sys.prefix in site.PREFIXES)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "ENV",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "ENV = \"@env@\"\nINTERPRETER = \"@interpreter@\"\nPYTHON_VERSION = \"@pythonVersion@\"\nIS_VIRTUALENV = @is_virtualenv@\nIS_VENV = @is_venv@\nIS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "INTERPRETER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "INTERPRETER = \"@interpreter@\"\nPYTHON_VERSION = \"@pythonVersion@\"\nIS_VIRTUALENV = @is_virtualenv@\nIS_VENV = @is_venv@\nIS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "PYTHON_VERSION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "PYTHON_VERSION = \"@pythonVersion@\"\nIS_VIRTUALENV = @is_virtualenv@\nIS_VENV = @is_venv@\nIS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "IS_VIRTUALENV",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "IS_VIRTUALENV = @is_virtualenv@\nIS_VENV = @is_venv@\nIS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")\n    def test_prefix(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "IS_VENV",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "IS_VENV = @is_venv@\nIS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")\n    def test_prefix(self):\n        self.assertEqual(sys.prefix, ENV)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "IS_NIXENV",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "IS_NIXENV = @is_nixenv@\nIS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")\n    def test_prefix(self):\n        self.assertEqual(sys.prefix, ENV)\n        self.assertEqual(sys.prefix, sys.exec_prefix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "IS_PYPY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "peekOfCode": "IS_PYPY = platform.python_implementation() == \"PyPy\"\nclass TestCasePython(unittest.TestCase):\n    @unittest.skipIf(IS_PYPY, \"Executable is incorrect and needs to be fixed.\")\n    def test_interpreter(self):\n        self.assertEqual(sys.executable, INTERPRETER)\n    @unittest.skipIf(IS_PYPY, \"Prefix is incorrect and needs to be fixed.\")\n    def test_prefix(self):\n        self.assertEqual(sys.prefix, ENV)\n        self.assertEqual(sys.prefix, sys.exec_prefix)\n    def test_site_prefix(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_environments.test_python",
        "documentation": {}
    },
    {
        "label": "echo",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_nix_pythonprefix.typeddep.typeddep.util",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_nix_pythonprefix.typeddep.typeddep.util",
        "peekOfCode": "def echo(s: str) -> str:\n    return s",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.tests.test_nix_pythonprefix.typeddep.typeddep.util",
        "documentation": {}
    },
    {
        "label": "Version",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "class Version(_Version, collections.abc.Sequence):\n    def __init__(self, version):\n        super().__init__(version)\n        # We cannot use `str(Version(0.04.21))` because that becomes `0.4.21`\n        # https://github.com/avian2/unidecode/issues/13#issuecomment-354538882\n        self.raw_version = version\n    def __getitem__(self, i):\n        return self._version.release[i]\n    def __len__(self):\n        return len(self._version.release)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "def main():\n    epilog = \"\"\"\nenvironment variables:\n  GITHUB_API_TOKEN\\tGitHub API token used when updating github packages\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter, epilog=epilog\n    )\n    parser.add_argument(\"package\", type=str, nargs=\"+\")\n    parser.add_argument(\"--target\", type=str, choices=SEMVER.keys(), default=\"major\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "INDEX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "INDEX = \"https://pypi.io/pypi\"\n\"\"\"url of PyPI\"\"\"\nEXTENSIONS = [\"tar.gz\", \"tar.bz2\", \"tar\", \"zip\", \".whl\"]\n\"\"\"Permitted file extensions. These are evaluated from left to right and the first occurance is returned.\"\"\"\nPRERELEASES = False\nBULK_UPDATE = False\nGIT = \"git\"\nNIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "EXTENSIONS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "EXTENSIONS = [\"tar.gz\", \"tar.bz2\", \"tar\", \"zip\", \".whl\"]\n\"\"\"Permitted file extensions. These are evaluated from left to right and the first occurance is returned.\"\"\"\nPRERELEASES = False\nBULK_UPDATE = False\nGIT = \"git\"\nNIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")\n    .strip()\n)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "PRERELEASES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "PRERELEASES = False\nBULK_UPDATE = False\nGIT = \"git\"\nNIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")\n    .strip()\n)\nlogging.basicConfig(level=logging.INFO)\nclass Version(_Version, collections.abc.Sequence):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "BULK_UPDATE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "BULK_UPDATE = False\nGIT = \"git\"\nNIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")\n    .strip()\n)\nlogging.basicConfig(level=logging.INFO)\nclass Version(_Version, collections.abc.Sequence):\n    def __init__(self, version):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "GIT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "GIT = \"git\"\nNIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")\n    .strip()\n)\nlogging.basicConfig(level=logging.INFO)\nclass Version(_Version, collections.abc.Sequence):\n    def __init__(self, version):\n        super().__init__(version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "NIXPKGS_ROOT = (\n    subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n    .decode(\"utf-8\")\n    .strip()\n)\nlogging.basicConfig(level=logging.INFO)\nclass Version(_Version, collections.abc.Sequence):\n    def __init__(self, version):\n        super().__init__(version)\n        # We cannot use `str(Version(0.04.21))` because that becomes `0.4.21`",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "SEMVER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "SEMVER = {\n    \"major\": 0,\n    \"minor\": 1,\n    \"patch\": 2,\n}\ndef _determine_latest_version(current_version, target, versions):\n    \"\"\"Determine latest version, given `target`.\"\"\"\n    current_version = Version(current_version)\n    def _parse_versions(versions):\n        for v in versions:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "FETCHERS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "FETCHERS = {\n    \"fetchFromGitHub\": _get_latest_version_github,\n    \"fetchPypi\": _get_latest_version_pypi,\n    \"fetchurl\": _get_latest_version_pypi,\n}\nDEFAULT_SETUPTOOLS_EXTENSION = \"tar.gz\"\nFORMATS = {\n    \"setuptools\": DEFAULT_SETUPTOOLS_EXTENSION,\n    \"wheel\": \"whl\",\n    \"pyproject\": \"tar.gz\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SETUPTOOLS_EXTENSION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "DEFAULT_SETUPTOOLS_EXTENSION = \"tar.gz\"\nFORMATS = {\n    \"setuptools\": DEFAULT_SETUPTOOLS_EXTENSION,\n    \"wheel\": \"whl\",\n    \"pyproject\": \"tar.gz\",\n    \"flit\": \"tar.gz\",\n}\ndef _determine_fetcher(text):\n    # Count occurrences of fetchers.\n    nfetchers = sum(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "FORMATS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "peekOfCode": "FORMATS = {\n    \"setuptools\": DEFAULT_SETUPTOOLS_EXTENSION,\n    \"wheel\": \"whl\",\n    \"pyproject\": \"tar.gz\",\n    \"flit\": \"tar.gz\",\n}\ndef _determine_fetcher(text):\n    # Count occurrences of fetchers.\n    nfetchers = sum(\n        text.count(\"src = {}\".format(fetcher)) for fetcher in FETCHERS.keys()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.update-python-libraries.update-python-libraries",
        "documentation": {}
    },
    {
        "label": "paths",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "peekOfCode": "paths = os.environ.pop('NIX_PYTHONPATH', None)\nif paths:\n    functools.reduce(lambda k, p: site.addsitedir(p, k), paths.split(':'), site._init_pathinfo())\n# Check whether we are in a venv or virtualenv.\n# For Python 3 we check whether our `base_prefix` is different from our current `prefix`.\n# For Python 2 we check whether the non-standard `real_prefix` is set.\n# https://stackoverflow.com/questions/1871549/determine-if-python-is-running-inside-virtualenv\nin_venv = (sys.version_info.major == 3 and sys.prefix != sys.base_prefix) or (sys.version_info.major == 2 and hasattr(sys, \"real_prefix\"))\nif not in_venv:\n    executable = os.environ.pop('NIX_PYTHONEXECUTABLE', None)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "documentation": {}
    },
    {
        "label": "in_venv",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "peekOfCode": "in_venv = (sys.version_info.major == 3 and sys.prefix != sys.base_prefix) or (sys.version_info.major == 2 and hasattr(sys, \"real_prefix\"))\nif not in_venv:\n    executable = os.environ.pop('NIX_PYTHONEXECUTABLE', None)\n    prefix = os.environ.pop('NIX_PYTHONPREFIX', None)\n    if 'PYTHONEXECUTABLE' not in os.environ and executable is not None:\n        sys.executable = executable\n    if prefix is not None:\n        # Sysconfig does not like it when sys.prefix is set to None\n        sys.prefix = sys.exec_prefix = prefix\n        site.PREFIXES.insert(0, prefix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.interpreters.python.sitecustomize",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "peekOfCode": "class Node:\n    def __init__(self, name):\n        self.name = name\n        self.dependencies = set()\nclass DAG:\n    def __init__(self):\n        self.nodes = {}\n    def add_node(self, node_name, dependencies=None):\n        if node_name in self.nodes:\n            raise ValueError(f\"Node '{node_name}' already exists in the graph.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "documentation": {}
    },
    {
        "label": "DAG",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "peekOfCode": "class DAG:\n    def __init__(self):\n        self.nodes = {}\n    def add_node(self, node_name, dependencies=None):\n        if node_name in self.nodes:\n            raise ValueError(f\"Node '{node_name}' already exists in the graph.\")\n        node = Node(node_name)\n        if dependencies:\n            node.dependencies.update(dependencies)\n        self.nodes[node_name] = node",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dag",
        "documentation": {}
    },
    {
        "label": "overrides_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "peekOfCode": "overrides_path = Path(sys.argv[1])\nout_path = Path(sys.argv[2])\nwith open(overrides_path, \"r\") as f:\n  overrides = json.loads(f.read())\nwith open(out_path, \"w\") as f:\n  toml.dump(overrides, f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "peekOfCode": "out_path = Path(sys.argv[2])\nwith open(overrides_path, \"r\") as f:\n  overrides = json.loads(f.read())\nwith open(out_path, \"w\") as f:\n  toml.dump(overrides, f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.dedup_overrides",
        "documentation": {}
    },
    {
        "label": "get_archive_derivation",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "def get_archive_derivation(uuid, artifact_name, url, sha256):\n  depends_on = set()\n  if closure_dependencies_dag.has_node(uuid):\n    depends_on = set(closure_dependencies_dag.get_dependencies(uuid)).intersection(dependency_uuids)\n  other_libs = extra_libs.get(uuid, [])\n  fixup = f\"\"\"fixupPhase = let\n          libs = lib.concatMap (lib.mapAttrsToList (k: v: v.path))\n                               [{\" \".join([\"uuid-\" + x for x in depends_on])}];\n          in ''\n            find $out -type f -executable -exec \\",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "get_plain_derivation",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "def get_plain_derivation(url, sha256):\n  return f\"\"\"fetchurl {{\n        url = \"{url}\";\n        sha256 = \"{sha256}\";\n      }}\"\"\"\nwith open(out_path, \"w\") as f:\n  f.write(\"{ lib, fetchurl, glibc, pkgs, stdenv }:\\n\\n\")\n  f.write(\"rec {\\n\")\n  def process_item(item):\n    uuid, src = item",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "archive_extensions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "archive_extensions = [\n  # xz extensions\n  \".tar.xz\",\n  \".tar.lzma\",\n  \".txz\",\n  # *.tar or *.tar.*\n  \".tar\",\n  \".tar.Z\",\n  \".tar.bz2\",\n  \".tar.gz\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "dependencies_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "dependencies_path = Path(sys.argv[1])\nclosure_yaml_path = Path(sys.argv[2])\njulia_path = Path(sys.argv[3])\nextract_artifacts_script = Path(sys.argv[4])\nextra_libs = json.loads(sys.argv[5])\nout_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "closure_yaml_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "closure_yaml_path = Path(sys.argv[2])\njulia_path = Path(sys.argv[3])\nextract_artifacts_script = Path(sys.argv[4])\nextra_libs = json.loads(sys.argv[5])\nout_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:\n  # Build up a map of UUID -> closure information",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "julia_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "julia_path = Path(sys.argv[3])\nextract_artifacts_script = Path(sys.argv[4])\nextra_libs = json.loads(sys.argv[5])\nout_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:\n  # Build up a map of UUID -> closure information\n  closure_yaml_list = yaml.safe_load(f) or []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "extract_artifacts_script",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "extract_artifacts_script = Path(sys.argv[4])\nextra_libs = json.loads(sys.argv[5])\nout_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:\n  # Build up a map of UUID -> closure information\n  closure_yaml_list = yaml.safe_load(f) or []\n  closure_yaml = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "extra_libs",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "extra_libs = json.loads(sys.argv[5])\nout_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:\n  # Build up a map of UUID -> closure information\n  closure_yaml_list = yaml.safe_load(f) or []\n  closure_yaml = {}\n  for item in closure_yaml_list:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "peekOfCode": "out_path = Path(sys.argv[6])\nwith open(dependencies_path, \"r\") as f:\n  dependencies = yaml.safe_load(f)\n  dependency_uuids = dependencies.keys()\nwith open(closure_yaml_path, \"r\") as f:\n  # Build up a map of UUID -> closure information\n  closure_yaml_list = yaml.safe_load(f) or []\n  closure_yaml = {}\n  for item in closure_yaml_list:\n    closure_yaml[item[\"uuid\"]] = item",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.extract_artifacts",
        "documentation": {}
    },
    {
        "label": "dependencies_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "peekOfCode": "dependencies_path = Path(sys.argv[1])\npackage_implications_json = sys.argv[2]\nout_path = Path(sys.argv[3])\npackage_implications = json.loads(package_implications_json)\nwith open(dependencies_path) as f:\n  desired_packages = yaml.safe_load(f) or []\nextra_package_names = []\nfor pkg in desired_packages:\n  if pkg[\"name\"] in package_implications:\n    extra_package_names.extend(package_implications[pkg[\"name\"]])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "documentation": {}
    },
    {
        "label": "package_implications_json",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "peekOfCode": "package_implications_json = sys.argv[2]\nout_path = Path(sys.argv[3])\npackage_implications = json.loads(package_implications_json)\nwith open(dependencies_path) as f:\n  desired_packages = yaml.safe_load(f) or []\nextra_package_names = []\nfor pkg in desired_packages:\n  if pkg[\"name\"] in package_implications:\n    extra_package_names.extend(package_implications[pkg[\"name\"]])\nif len(extra_package_names) > 0:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "peekOfCode": "out_path = Path(sys.argv[3])\npackage_implications = json.loads(package_implications_json)\nwith open(dependencies_path) as f:\n  desired_packages = yaml.safe_load(f) or []\nextra_package_names = []\nfor pkg in desired_packages:\n  if pkg[\"name\"] in package_implications:\n    extra_package_names.extend(package_implications[pkg[\"name\"]])\nif len(extra_package_names) > 0:\n  with open(out_path, \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "documentation": {}
    },
    {
        "label": "package_implications",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "peekOfCode": "package_implications = json.loads(package_implications_json)\nwith open(dependencies_path) as f:\n  desired_packages = yaml.safe_load(f) or []\nextra_package_names = []\nfor pkg in desired_packages:\n  if pkg[\"name\"] in package_implications:\n    extra_package_names.extend(package_implications[pkg[\"name\"]])\nif len(extra_package_names) > 0:\n  with open(out_path, \"w\") as f:\n    f.write(\"\\n\".join(extra_package_names))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "documentation": {}
    },
    {
        "label": "extra_package_names",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "peekOfCode": "extra_package_names = []\nfor pkg in desired_packages:\n  if pkg[\"name\"] in package_implications:\n    extra_package_names.extend(package_implications[pkg[\"name\"]])\nif len(extra_package_names) > 0:\n  with open(out_path, \"w\") as f:\n    f.write(\"\\n\".join(extra_package_names))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.find_package_implications",
        "documentation": {}
    },
    {
        "label": "overrides_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "peekOfCode": "overrides_path = Path(sys.argv[1])\nout_path = Path(sys.argv[2])\nwith open(overrides_path, \"r\") as f:\n  overrides = json.loads(f.read())\nresult = {}\nfor (uuid, artifacts) in overrides.items():\n  if len(artifacts) == 0: continue\n  for (name, info) in artifacts.items():\n    result[info[\"sha1\"]] = info[\"path\"]\nwith open(out_path, \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "peekOfCode": "out_path = Path(sys.argv[2])\nwith open(overrides_path, \"r\") as f:\n  overrides = json.loads(f.read())\nresult = {}\nfor (uuid, artifacts) in overrides.items():\n  if len(artifacts) == 0: continue\n  for (name, info) in artifacts.items():\n    result[info[\"sha1\"]] = info[\"path\"]\nwith open(out_path, \"w\") as f:\n  toml.dump(result, f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "peekOfCode": "result = {}\nfor (uuid, artifacts) in overrides.items():\n  if len(artifacts) == 0: continue\n  for (name, info) in artifacts.items():\n    result[info[\"sha1\"]] = info[\"path\"]\nwith open(out_path, \"w\") as f:\n  toml.dump(result, f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.format_overrides",
        "documentation": {}
    },
    {
        "label": "registry_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "registry_path = Path(sys.argv[1])\ndesired_packages_path = Path(sys.argv[2])\npackage_overrides = json.loads(sys.argv[3])\ndependencies_path = Path(sys.argv[4])\nout_path = Path(sys.argv[5])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nuuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "desired_packages_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "desired_packages_path = Path(sys.argv[2])\npackage_overrides = json.loads(sys.argv[3])\ndependencies_path = Path(sys.argv[4])\nout_path = Path(sys.argv[5])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nuuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])\nwith open(dependencies_path, \"r\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "package_overrides",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "package_overrides = json.loads(sys.argv[3])\ndependencies_path = Path(sys.argv[4])\nout_path = Path(sys.argv[5])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nuuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])\nwith open(dependencies_path, \"r\") as f:\n  uuid_to_store_path = yaml.safe_load(f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "dependencies_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "dependencies_path = Path(sys.argv[4])\nout_path = Path(sys.argv[5])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nuuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])\nwith open(dependencies_path, \"r\") as f:\n  uuid_to_store_path = yaml.safe_load(f)\nos.makedirs(out_path)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "out_path = Path(sys.argv[5])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nuuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])\nwith open(dependencies_path, \"r\") as f:\n  uuid_to_store_path = yaml.safe_load(f)\nos.makedirs(out_path)\nregistry = toml.load(registry_path / \"Registry.toml\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "uuid_to_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "uuid_to_versions = defaultdict(list)\nfor pkg in desired_packages:\n    uuid_to_versions[pkg[\"uuid\"]].append(pkg[\"version\"])\nwith open(dependencies_path, \"r\") as f:\n  uuid_to_store_path = yaml.safe_load(f)\nos.makedirs(out_path)\nregistry = toml.load(registry_path / \"Registry.toml\")\nregistry[\"packages\"] = {k: v for k, v in registry[\"packages\"].items() if k in uuid_to_versions}\nfor (uuid, versions) in uuid_to_versions.items():\n  if uuid in package_overrides:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "registry",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "registry = toml.load(registry_path / \"Registry.toml\")\nregistry[\"packages\"] = {k: v for k, v in registry[\"packages\"].items() if k in uuid_to_versions}\nfor (uuid, versions) in uuid_to_versions.items():\n  if uuid in package_overrides:\n    info = package_overrides[uuid]\n    # Make a registry entry based on the info from the package override\n    path = Path(info[\"name\"][0].upper()) / Path(info[\"name\"])\n    registry[\"packages\"][uuid] = {\n      \"name\": info[\"name\"],\n      \"path\": str(path),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "registry[\"packages\"]",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "peekOfCode": "registry[\"packages\"] = {k: v for k, v in registry[\"packages\"].items() if k in uuid_to_versions}\nfor (uuid, versions) in uuid_to_versions.items():\n  if uuid in package_overrides:\n    info = package_overrides[uuid]\n    # Make a registry entry based on the info from the package override\n    path = Path(info[\"name\"][0].upper()) / Path(info[\"name\"])\n    registry[\"packages\"][uuid] = {\n      \"name\": info[\"name\"],\n      \"path\": str(path),\n    }",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.minimal_registry",
        "documentation": {}
    },
    {
        "label": "ensure_version_valid",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "def ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.\n  It doesn't really matter what it looks like as it's just used for overrides.\n  \"\"\"\n  return re.sub('[^0-9\\.]','', version)\nwith open(out_path, \"w\") as f:\n  f.write(\"{fetchgit}:\\n\")\n  f.write(\"{\\n\")\n  for pkg in desired_packages:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "registry_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "registry_path = Path(sys.argv[1])\npackage_overrides = json.loads(sys.argv[2])\ndesired_packages_path = Path(sys.argv[3])\nout_path = Path(sys.argv[4])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nregistry = toml.load(registry_path / \"Registry.toml\")\ndef ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "package_overrides",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "package_overrides = json.loads(sys.argv[2])\ndesired_packages_path = Path(sys.argv[3])\nout_path = Path(sys.argv[4])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nregistry = toml.load(registry_path / \"Registry.toml\")\ndef ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.\n  It doesn't really matter what it looks like as it's just used for overrides.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "desired_packages_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "desired_packages_path = Path(sys.argv[3])\nout_path = Path(sys.argv[4])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nregistry = toml.load(registry_path / \"Registry.toml\")\ndef ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.\n  It doesn't really matter what it looks like as it's just used for overrides.\n  \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "out_path = Path(sys.argv[4])\nwith open(desired_packages_path, \"r\") as f:\n  desired_packages = yaml.safe_load(f) or []\nregistry = toml.load(registry_path / \"Registry.toml\")\ndef ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.\n  It doesn't really matter what it looks like as it's just used for overrides.\n  \"\"\"\n  return re.sub('[^0-9\\.]','', version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "registry",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "peekOfCode": "registry = toml.load(registry_path / \"Registry.toml\")\ndef ensure_version_valid(version):\n  \"\"\"\n  Ensure a version string is a valid Julia-parsable version.\n  It doesn't really matter what it looks like as it's just used for overrides.\n  \"\"\"\n  return re.sub('[^0-9\\.]','', version)\nwith open(out_path, \"w\") as f:\n  f.write(\"{fetchgit}:\\n\")\n  f.write(\"{\\n\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.sources_nix",
        "documentation": {}
    },
    {
        "label": "get_commit_info",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.util",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.util",
        "peekOfCode": "def get_commit_info(repo):\n  with tempfile.TemporaryDirectory() as home_dir:\n    env_with_home = os.environ.copy()\n    env_with_home[\"HOME\"] = home_dir\n    subprocess.check_output([\"git\", \"config\", \"--global\", \"--add\", \"safe.directory\", repo], env=env_with_home)\n    lines = subprocess.check_output([\"git\", \"log\", \"--pretty=raw\"], cwd=repo, env=env_with_home).decode().split(\"\\n\")\n    return dict([x.split() for x in lines if len(x.split()) == 2])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.python.util",
        "documentation": {}
    },
    {
        "label": "requests_csv_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "requests_csv_path = Path(sys.argv[1])\nregistry_path = Path(sys.argv[2])\n# Generate list of tuples (UUID, count)\nrows = []\nwith open(requests_csv_path) as f:\n  reader = csv.reader(f)\n  for row in reader:\n    if row[2] == \"user\":\n      # Get UUID and request_count\n      rows.append((row[0], int(row[4])))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "registry_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "registry_path = Path(sys.argv[2])\n# Generate list of tuples (UUID, count)\nrows = []\nwith open(requests_csv_path) as f:\n  reader = csv.reader(f)\n  for row in reader:\n    if row[2] == \"user\":\n      # Get UUID and request_count\n      rows.append((row[0], int(row[4])))\nrows.sort(key=(lambda x: x[1]), reverse=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "rows",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "rows = []\nwith open(requests_csv_path) as f:\n  reader = csv.reader(f)\n  for row in reader:\n    if row[2] == \"user\":\n      # Get UUID and request_count\n      rows.append((row[0], int(row[4])))\nrows.sort(key=(lambda x: x[1]), reverse=True)\n# Build a map from UUID -> name\nregistry = toml.load(registry_path / \"Registry.toml\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "registry",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "registry = toml.load(registry_path / \"Registry.toml\")\nuuid_to_name = {k: v[\"name\"] for k, v in registry[\"packages\"].items()}\nresults = []\nfor (uuid, count) in rows:\n  name = uuid_to_name.get(uuid)\n  if not name: continue\n  results.append({ \"uuid\": uuid, \"name\": uuid_to_name.get(uuid), \"count\": count })\nyaml.dump(results, sys.stdout, default_flow_style=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "uuid_to_name",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "uuid_to_name = {k: v[\"name\"] for k, v in registry[\"packages\"].items()}\nresults = []\nfor (uuid, count) in rows:\n  name = uuid_to_name.get(uuid)\n  if not name: continue\n  results.append({ \"uuid\": uuid, \"name\": uuid_to_name.get(uuid), \"count\": count })\nyaml.dump(results, sys.stdout, default_flow_style=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "peekOfCode": "results = []\nfor (uuid, count) in rows:\n  name = uuid_to_name.get(uuid)\n  if not name: continue\n  results.append({ \"uuid\": uuid, \"name\": uuid_to_name.get(uuid), \"count\": count })\nyaml.dump(results, sys.stdout, default_flow_style=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.julia-modules.tests.process_top_n",
        "documentation": {}
    },
    {
        "label": "get_latest_chromium_stable_release",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "def get_latest_chromium_stable_release():\n    RELEASES_URL = 'https://versionhistory.googleapis.com/v1/chrome/platforms/linux/channels/stable/versions/all/releases'\n    print(f'GET {RELEASES_URL}')\n    with urlopen(RELEASES_URL) as resp:\n        return json.load(resp)['releases'][0]\ndef get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://chromium.googlesource.com/chromium/src/+/refs/tags/{revision}/{file_path}?format=TEXT'\n    with urlopen(url) as http_response:\n        resp = http_response.read()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "get_file_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "def get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://chromium.googlesource.com/chromium/src/+/refs/tags/{revision}/{file_path}?format=TEXT'\n    with urlopen(url) as http_response:\n        resp = http_response.read()\n        return base64.b64decode(resp)\ndef nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision of the given repository URL.\"\"\"\n    print(f'nix-prefetch-git {url} {rev}')\n    out = subprocess.check_output(['nix-prefetch-git', '--quiet', '--url', url, '--rev', rev])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_git",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "def nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision of the given repository URL.\"\"\"\n    print(f'nix-prefetch-git {url} {rev}')\n    out = subprocess.check_output(['nix-prefetch-git', '--quiet', '--url', url, '--rev', rev])\n    return json.loads(out)\ndef get_current_revision():\n    with open(DICTIONARIES_CHROMIUM_NIX) as f:\n        for line in f:\n            rev = re.search(r'^        rev = \"(.*)\";', line)\n            if rev:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "get_current_revision",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "def get_current_revision():\n    with open(DICTIONARIES_CHROMIUM_NIX) as f:\n        for line in f:\n            rev = re.search(r'^        rev = \"(.*)\";', line)\n            if rev:\n                return rev.group(1)\n    sys.exit(1)\nprint('Getting latest chromium version...')\nchromium_release = get_latest_chromium_stable_release()\nchromium_version = chromium_release['version']",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "DICTIONARIES_CHROMIUM_NIX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "DICTIONARIES_CHROMIUM_NIX = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'dictionaries-chromium.nix')\ndef get_latest_chromium_stable_release():\n    RELEASES_URL = 'https://versionhistory.googleapis.com/v1/chrome/platforms/linux/channels/stable/versions/all/releases'\n    print(f'GET {RELEASES_URL}')\n    with urlopen(RELEASES_URL) as resp:\n        return json.load(resp)['releases'][0]\ndef get_file_revision(revision, file_path):\n    \"\"\"Fetches the requested Git revision of the given Chromium file.\"\"\"\n    url = f'https://chromium.googlesource.com/chromium/src/+/refs/tags/{revision}/{file_path}?format=TEXT'\n    with urlopen(url) as http_response:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "chromium_release",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "chromium_release = get_latest_chromium_stable_release()\nchromium_version = chromium_release['version']\nprint(f'chromium version: {chromium_version}')\nprint('Getting corresponding hunspell_dictionaries commit...')\ndeps = get_file_revision(chromium_version, 'DEPS')\nhunspell_dictionaries_pattern = r\"^\\s*Var\\('chromium_git'\\)\\s*\\+\\s*'\\/chromium\\/deps\\/hunspell_dictionaries\\.git'\\s*\\+\\s*'@'\\s*\\+\\s*'(\\w*)',$\"\nhunspell_dictionaries_commit = re.search(hunspell_dictionaries_pattern, deps.decode(), re.MULTILINE).group(1)\nprint(f'hunspell_dictionaries commit: {hunspell_dictionaries_commit}')\ncurrent_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "chromium_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "chromium_version = chromium_release['version']\nprint(f'chromium version: {chromium_version}')\nprint('Getting corresponding hunspell_dictionaries commit...')\ndeps = get_file_revision(chromium_version, 'DEPS')\nhunspell_dictionaries_pattern = r\"^\\s*Var\\('chromium_git'\\)\\s*\\+\\s*'\\/chromium\\/deps\\/hunspell_dictionaries\\.git'\\s*\\+\\s*'@'\\s*\\+\\s*'(\\w*)',$\"\nhunspell_dictionaries_commit = re.search(hunspell_dictionaries_pattern, deps.decode(), re.MULTILINE).group(1)\nprint(f'hunspell_dictionaries commit: {hunspell_dictionaries_commit}')\ncurrent_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:\n    print('Commit is already packaged, no update needed.')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "deps",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "deps = get_file_revision(chromium_version, 'DEPS')\nhunspell_dictionaries_pattern = r\"^\\s*Var\\('chromium_git'\\)\\s*\\+\\s*'\\/chromium\\/deps\\/hunspell_dictionaries\\.git'\\s*\\+\\s*'@'\\s*\\+\\s*'(\\w*)',$\"\nhunspell_dictionaries_commit = re.search(hunspell_dictionaries_pattern, deps.decode(), re.MULTILINE).group(1)\nprint(f'hunspell_dictionaries commit: {hunspell_dictionaries_commit}')\ncurrent_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:\n    print('Commit is already packaged, no update needed.')\n    sys.exit(0)\nprint('Commit has changed compared to the current package, updating...')\nprint('Getting hash of hunspell_dictionaries revision...')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "hunspell_dictionaries_pattern",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "hunspell_dictionaries_pattern = r\"^\\s*Var\\('chromium_git'\\)\\s*\\+\\s*'\\/chromium\\/deps\\/hunspell_dictionaries\\.git'\\s*\\+\\s*'@'\\s*\\+\\s*'(\\w*)',$\"\nhunspell_dictionaries_commit = re.search(hunspell_dictionaries_pattern, deps.decode(), re.MULTILINE).group(1)\nprint(f'hunspell_dictionaries commit: {hunspell_dictionaries_commit}')\ncurrent_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:\n    print('Commit is already packaged, no update needed.')\n    sys.exit(0)\nprint('Commit has changed compared to the current package, updating...')\nprint('Getting hash of hunspell_dictionaries revision...')\nhunspell_dictionaries_git = nix_prefetch_git(\"https://chromium.googlesource.com/chromium/deps/hunspell_dictionaries\", hunspell_dictionaries_commit)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "hunspell_dictionaries_commit",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "hunspell_dictionaries_commit = re.search(hunspell_dictionaries_pattern, deps.decode(), re.MULTILINE).group(1)\nprint(f'hunspell_dictionaries commit: {hunspell_dictionaries_commit}')\ncurrent_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:\n    print('Commit is already packaged, no update needed.')\n    sys.exit(0)\nprint('Commit has changed compared to the current package, updating...')\nprint('Getting hash of hunspell_dictionaries revision...')\nhunspell_dictionaries_git = nix_prefetch_git(\"https://chromium.googlesource.com/chromium/deps/hunspell_dictionaries\", hunspell_dictionaries_commit)\nhunspell_dictionaries_hash = hunspell_dictionaries_git['hash']",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "current_commit",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "current_commit = get_current_revision()\nif current_commit == hunspell_dictionaries_commit:\n    print('Commit is already packaged, no update needed.')\n    sys.exit(0)\nprint('Commit has changed compared to the current package, updating...')\nprint('Getting hash of hunspell_dictionaries revision...')\nhunspell_dictionaries_git = nix_prefetch_git(\"https://chromium.googlesource.com/chromium/deps/hunspell_dictionaries\", hunspell_dictionaries_commit)\nhunspell_dictionaries_hash = hunspell_dictionaries_git['hash']\nprint(f'hunspell_dictionaries commit hash: {hunspell_dictionaries_hash}')\nwith fileinput.FileInput(DICTIONARIES_CHROMIUM_NIX, inplace=True) as file:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "hunspell_dictionaries_git",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "hunspell_dictionaries_git = nix_prefetch_git(\"https://chromium.googlesource.com/chromium/deps/hunspell_dictionaries\", hunspell_dictionaries_commit)\nhunspell_dictionaries_hash = hunspell_dictionaries_git['hash']\nprint(f'hunspell_dictionaries commit hash: {hunspell_dictionaries_hash}')\nwith fileinput.FileInput(DICTIONARIES_CHROMIUM_NIX, inplace=True) as file:\n    for line in file:\n        result = re.sub(r'^      version = \".+\";', f'      version = \"{chromium_version}\";', line)\n        result = re.sub(r'^        rev = \".*\";', f'        rev = \"{hunspell_dictionaries_commit}\";', result)\n        result = re.sub(r'^        hash = \".+\";', f'        hash = \"{hunspell_dictionaries_hash}\";', result)\n        print(result, end='')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "hunspell_dictionaries_hash",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "peekOfCode": "hunspell_dictionaries_hash = hunspell_dictionaries_git['hash']\nprint(f'hunspell_dictionaries commit hash: {hunspell_dictionaries_hash}')\nwith fileinput.FileInput(DICTIONARIES_CHROMIUM_NIX, inplace=True) as file:\n    for line in file:\n        result = re.sub(r'^      version = \".+\";', f'      version = \"{chromium_version}\";', line)\n        result = re.sub(r'^        rev = \".*\";', f'        rev = \"{hunspell_dictionaries_commit}\";', result)\n        result = re.sub(r'^        hash = \".+\";', f'        hash = \"{hunspell_dictionaries_hash}\";', result)\n        print(result, end='')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.hunspell.update-chromium-dictionaries",
        "documentation": {}
    },
    {
        "label": "process_columns",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "peekOfCode": "def process_columns(line: list[str]) -> tuple[str, list[str]]:\n    match line:\n        case [name, h_prefix, nrbytes, flags]:\n            return (h_prefix, flags.lower().split(\",\"))\n        case other:\n            raise Exception(\"Unsupported hashes.conf line format\", other)\ndef find_tar_file(tar: tarfile.TarFile, requested_name: str):\n    \"\"\"Attempts to find a single file with given name in tarball.\"\"\"\n    all_names = tar.getnames()\n    if requested_name in all_names:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "documentation": {}
    },
    {
        "label": "find_tar_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "peekOfCode": "def find_tar_file(tar: tarfile.TarFile, requested_name: str):\n    \"\"\"Attempts to find a single file with given name in tarball.\"\"\"\n    all_names = tar.getnames()\n    if requested_name in all_names:\n        return requested_name\n    requested_suffix = f\"/{requested_name}\"\n    candidate_names = [name for name in all_names if name.endswith(requested_suffix)]\n    match candidate_names:\n        case [real_name]:\n            return real_name",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "peekOfCode": "def main() -> None:\n    match sys.argv:\n        case [_name, src, enable_hashes, \"--\", *enabled_crypt_scheme_ids]:\n            pass\n        case other:\n            raise Exception(\n                \"Incorrect number of arguments. Usage: check_passthru_matches.py <src> <enable_hashes> -- <enabled_crypt_scheme_ids...>\"\n            )\n    with tarfile.open(src, \"r\") as tar:\n        real_hashes_path = find_tar_file(tar, hashes_path)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "documentation": {}
    },
    {
        "label": "hashes_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "peekOfCode": "hashes_path = \"lib/hashes.conf\"\ndef main() -> None:\n    match sys.argv:\n        case [_name, src, enable_hashes, \"--\", *enabled_crypt_scheme_ids]:\n            pass\n        case other:\n            raise Exception(\n                \"Incorrect number of arguments. Usage: check_passthru_matches.py <src> <enable_hashes> -- <enabled_crypt_scheme_ids...>\"\n            )\n    with tarfile.open(src, \"r\") as tar:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.libxcrypt.check_passthru_matches",
        "documentation": {}
    },
    {
        "label": "find_version_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "def find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:\n        if os.path.exists(path):\n            return path\n    raise Exception(\n        \"Couldn't figure out where to write version.json; try specifying --out\"\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "fetch_tarball",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "def fetch_tarball() -> bytes:\n    r = requests.get(NDI_SDK_URL)\n    r.raise_for_status()\n    return r.content\ndef read_version(tarball: bytes) -> str:\n    # Find the inner script.\n    outer_tarfile = tarfile.open(fileobj=io.BytesIO(tarball), mode=\"r:gz\")\n    eula_script = outer_tarfile.extractfile(NDI_EXEC).read()\n    # Now find the archive embedded within the script.\n    archive_start = eula_script.find(NDI_ARCHIVE_MAGIC) + len(NDI_ARCHIVE_MAGIC)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "read_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "def read_version(tarball: bytes) -> str:\n    # Find the inner script.\n    outer_tarfile = tarfile.open(fileobj=io.BytesIO(tarball), mode=\"r:gz\")\n    eula_script = outer_tarfile.extractfile(NDI_EXEC).read()\n    # Now find the archive embedded within the script.\n    archive_start = eula_script.find(NDI_ARCHIVE_MAGIC) + len(NDI_ARCHIVE_MAGIC)\n    inner_tarfile = tarfile.open(\n        fileobj=io.BytesIO(eula_script[archive_start:]), mode=\"r:gz\"\n    )\n    # Now find Version.txt...",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "def main(argv):\n    tarball = fetch_tarball()\n    sha256 = hashlib.sha256(tarball).hexdigest()\n    version = {\n        \"hash\": f\"sha256:{sha256}\",\n        \"version\": read_version(tarball),\n    }\n    out_path = find_version_json()\n    with open(out_path, \"w\") as f:\n        json.dump(version, f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "BASE_NAME",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "BASE_NAME = \"Install_NDI_SDK_v5_Linux\"\nNDI_SDK_URL = f\"https://downloads.ndi.tv/SDK/NDI_SDK_Linux/{BASE_NAME}.tar.gz\"\nNDI_EXEC = f\"{BASE_NAME}.sh\"\nNDI_ARCHIVE_MAGIC = b\"__NDI_ARCHIVE_BEGIN__\\n\"\nFLAG_out = flags.DEFINE_string(\"out\", None, \"Path to read/write version.json from/to.\")\ndef find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "NDI_SDK_URL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "NDI_SDK_URL = f\"https://downloads.ndi.tv/SDK/NDI_SDK_Linux/{BASE_NAME}.tar.gz\"\nNDI_EXEC = f\"{BASE_NAME}.sh\"\nNDI_ARCHIVE_MAGIC = b\"__NDI_ARCHIVE_BEGIN__\\n\"\nFLAG_out = flags.DEFINE_string(\"out\", None, \"Path to read/write version.json from/to.\")\ndef find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:\n        if os.path.exists(path):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "NDI_EXEC",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "NDI_EXEC = f\"{BASE_NAME}.sh\"\nNDI_ARCHIVE_MAGIC = b\"__NDI_ARCHIVE_BEGIN__\\n\"\nFLAG_out = flags.DEFINE_string(\"out\", None, \"Path to read/write version.json from/to.\")\ndef find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:\n        if os.path.exists(path):\n            return path",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "NDI_ARCHIVE_MAGIC",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "NDI_ARCHIVE_MAGIC = b\"__NDI_ARCHIVE_BEGIN__\\n\"\nFLAG_out = flags.DEFINE_string(\"out\", None, \"Path to read/write version.json from/to.\")\ndef find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:\n        if os.path.exists(path):\n            return path\n    raise Exception(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "FLAG_out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "peekOfCode": "FLAG_out = flags.DEFINE_string(\"out\", None, \"Path to read/write version.json from/to.\")\ndef find_version_json() -> str:\n    if FLAG_out.value:\n        return FLAG_out.value\n    try_paths = [\"pkgs/development/libraries/ndi/version.json\", \"version.json\"]\n    for path in try_paths:\n        if os.path.exists(path):\n            return path\n    raise Exception(\n        \"Couldn't figure out where to write version.json; try specifying --out\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.libraries.ndi.update",
        "documentation": {}
    },
    {
        "label": "LuaPlugin",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "class LuaPlugin:\n    name: str\n    \"\"\"Name of the plugin, as seen on luarocks.org\"\"\"\n    rockspec: str\n    \"\"\"Full path towards the rockspec\"\"\"\n    ref: Optional[str]\n    \"\"\"git reference (branch name/tag)\"\"\"\n    version: Optional[str]\n    \"\"\"Set it to pin a package \"\"\"\n    server: Optional[str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "LuaEditor",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "class LuaEditor(pluginupdate.Editor):\n    def create_parser(self):\n        parser = super().create_parser()\n        parser.set_defaults(proc=1)\n        return parser\n    def get_current_plugins(self):\n        return []\n    def load_plugin_spec(self, input_file) -> List[LuaPlugin]:\n        luaPackages = []\n        csvfilename = input_file",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "generate_pkg_nix",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "def generate_pkg_nix(plug: LuaPlugin):\n    \"\"\"\n    Generate nix expression for a luarocks package\n    Our cache key associates \"p.name-p.version\" to its rockspec\n    \"\"\"\n    log.debug(\"Generating nix expression for %s\", plug.name)\n    cmd = [\"luarocks\", \"nix\"]\n    if plug.maintainers:\n        cmd.append(f\"--maintainers={plug.maintainers}\")\n    if plug.rockspec != \"\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "def main():\n    editor = LuaEditor(\n        \"lua\",\n        ROOT,\n        \"\",\n        default_in=PKG_LIST,\n        default_out=GENERATED_NIXFILE,\n    )\n    editor.run()\nif __name__ == \"__main__\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "log = logging.getLogger()\nlog.addHandler(logging.StreamHandler())\nROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))).parent.parent  # type: ignore\nPKG_LIST = \"maintainers/scripts/luarocks-packages.csv\"\nTMP_FILE = \"$(mktemp)\"\nGENERATED_NIXFILE = \"pkgs/development/lua-modules/generated-packages.nix\"\nHEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "ROOT = Path(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))).parent.parent  # type: ignore\nPKG_LIST = \"maintainers/scripts/luarocks-packages.csv\"\nTMP_FILE = \"$(mktemp)\"\nGENERATED_NIXFILE = \"pkgs/development/lua-modules/generated-packages.nix\"\nHEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/\n\"\"\".format(\n    GENERATED_NIXFILE=GENERATED_NIXFILE",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "PKG_LIST",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "PKG_LIST = \"maintainers/scripts/luarocks-packages.csv\"\nTMP_FILE = \"$(mktemp)\"\nGENERATED_NIXFILE = \"pkgs/development/lua-modules/generated-packages.nix\"\nHEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/\n\"\"\".format(\n    GENERATED_NIXFILE=GENERATED_NIXFILE\n)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "TMP_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "TMP_FILE = \"$(mktemp)\"\nGENERATED_NIXFILE = \"pkgs/development/lua-modules/generated-packages.nix\"\nHEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/\n\"\"\".format(\n    GENERATED_NIXFILE=GENERATED_NIXFILE\n)\nFOOTER = \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "GENERATED_NIXFILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "GENERATED_NIXFILE = \"pkgs/development/lua-modules/generated-packages.nix\"\nHEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/\n\"\"\".format(\n    GENERATED_NIXFILE=GENERATED_NIXFILE\n)\nFOOTER = \"\"\"\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "HEADER = \"\"\"/* {GENERATED_NIXFILE} is an auto-generated file -- DO NOT EDIT!\nRegenerate it with: nix run nixpkgs#luarocks-packages-updater\nYou can customize the generated packages in pkgs/development/lua-modules/overrides.nix\n*/\n\"\"\".format(\n    GENERATED_NIXFILE=GENERATED_NIXFILE\n)\nFOOTER = \"\"\"\n}\n/* GENERATED - do not edit this file */",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "FOOTER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "peekOfCode": "FOOTER = \"\"\"\n}\n/* GENERATED - do not edit this file */\n\"\"\"\n@dataclass\nclass LuaPlugin:\n    name: str\n    \"\"\"Name of the plugin, as seen on luarocks.org\"\"\"\n    rockspec: str\n    \"\"\"Full path towards the rockspec\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.lua-modules.updater.updater",
        "documentation": {}
    },
    {
        "label": "remove",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.node-packages.remove-attr",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.node-packages.remove-attr",
        "peekOfCode": "def remove(attr):\n    with open(os.path.join(os.path.dirname(__file__), 'node-packages.json'), 'r+') as node_packages_json:\n        packages = json.load(node_packages_json)\n        idx = 0\n        while idx < len(packages):\n            if packages[idx] == attr or (isinstance(packages[idx], collections.abc.Mapping) and next(iter(packages[idx].keys())) == attr):\n                del packages[idx]\n            else:\n                idx += 1\n        node_packages_json.seek(0)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.node-packages.remove-attr",
        "documentation": {}
    },
    {
        "label": "example_data_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "example_data_dir = os.environ['BPY_EXAMPLE_DATA']\nout_dir = Path(os.environ['out'])\nout_dir.mkdir(parents=True, exist_ok=True)\nmodels = sorted(glob.glob(os.path.join(example_data_dir, \"model\", \"*\", \"*.obj\")))\ncat_id_to_model_path = dict(enumerate(sorted(models), 1))\ndistractors = sorted(glob.glob(os.path.join(example_data_dir, \"distractor\", \"*.obj\")))\nbpycv.clear_all()\nbpy.context.scene.frame_set(1)\nbpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "out_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "out_dir = Path(os.environ['out'])\nout_dir.mkdir(parents=True, exist_ok=True)\nmodels = sorted(glob.glob(os.path.join(example_data_dir, \"model\", \"*\", \"*.obj\")))\ncat_id_to_model_path = dict(enumerate(sorted(models), 1))\ndistractors = sorted(glob.glob(os.path.join(example_data_dir, \"distractor\", \"*.obj\")))\nbpycv.clear_all()\nbpy.context.scene.frame_set(1)\nbpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "models = sorted(glob.glob(os.path.join(example_data_dir, \"model\", \"*\", \"*.obj\")))\ncat_id_to_model_path = dict(enumerate(sorted(models), 1))\ndistractors = sorted(glob.glob(os.path.join(example_data_dir, \"distractor\", \"*.obj\")))\nbpycv.clear_all()\nbpy.context.scene.frame_set(1)\nbpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "cat_id_to_model_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "cat_id_to_model_path = dict(enumerate(sorted(models), 1))\ndistractors = sorted(glob.glob(os.path.join(example_data_dir, \"distractor\", \"*.obj\")))\nbpycv.clear_all()\nbpy.context.scene.frame_set(1)\nbpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "distractors",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "distractors = sorted(glob.glob(os.path.join(example_data_dir, \"distractor\", \"*.obj\")))\nbpycv.clear_all()\nbpy.context.scene.frame_set(1)\nbpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "bpy.context.scene.render.engine",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "bpy.context.scene.render.engine = \"CYCLES\"\nbpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "bpy.context.scene.cycles.samples",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "bpy.context.scene.cycles.samples = 32\nbpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "bpy.context.scene.render.resolution_y",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "bpy.context.scene.render.resolution_y = 1024\nbpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "bpy.context.scene.render.resolution_x",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "bpy.context.scene.render.resolution_x = 1024\nbpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven\nhdri_path = hdri_manager.sample()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "bpy.context.view_layer.cycles.denoising_store_passes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "bpy.context.view_layer.cycles.denoising_store_passes = False\n# A transparency stage for holding rigid body\nstage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven\nhdri_path = hdri_manager.sample()\nbpycv.load_hdri_world(hdri_path, random_rotate_z=True)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "stage",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "stage = bpycv.add_stage(transparency=True)\nbpycv.set_cam_pose(cam_radius=1, cam_deg=45)\nhdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven\nhdri_path = hdri_manager.sample()\nbpycv.load_hdri_world(hdri_path, random_rotate_z=True)\n# load 5 objects\nfor index in range(5):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "hdri_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "hdri_dir = os.path.join(example_data_dir, \"background_and_light\")\nhdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven\nhdri_path = hdri_manager.sample()\nbpycv.load_hdri_world(hdri_path, random_rotate_z=True)\n# load 5 objects\nfor index in range(5):\n    cat_id = random.choice(list(cat_id_to_model_path))\n    model_path = cat_id_to_model_path[cat_id]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "hdri_manager",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "hdri_manager = bpycv.HdriManager(\n    hdri_dir=hdri_dir, download=False\n)  # if download is True, will auto download .hdr file from HDRI Haven\nhdri_path = hdri_manager.sample()\nbpycv.load_hdri_world(hdri_path, random_rotate_z=True)\n# load 5 objects\nfor index in range(5):\n    cat_id = random.choice(list(cat_id_to_model_path))\n    model_path = cat_id_to_model_path[cat_id]\n    obj = bpycv.load_obj(model_path)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "hdri_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "hdri_path = hdri_manager.sample()\nbpycv.load_hdri_world(hdri_path, random_rotate_z=True)\n# load 5 objects\nfor index in range(5):\n    cat_id = random.choice(list(cat_id_to_model_path))\n    model_path = cat_id_to_model_path[cat_id]\n    obj = bpycv.load_obj(model_path)\n    obj.location = (\n        random.uniform(-0.2, 0.2),\n        random.uniform(-0.2, 0.2),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "peekOfCode": "result = bpycv.render_data()\nresult.save(dataset_dir=str(out_dir.resolve()), fname=\"0\", save_blend=True)\nprint(f'Save to \"{out_dir}\"')\nprint(f'Open \"{out_dir}/vis/\" to see visualize result.')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.bpycv.bpycv-test",
        "documentation": {}
    },
    {
        "label": "NixNetworkAccessDeniedError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "class NixNetworkAccessDeniedError(BaseException):\n    pass\ndef pytest_runtest_makereport(item, call):\n    \"\"\"\n    Modifies test results after-the-fact. The function name is magic, see:\n    https://docs.pytest.org/en/7.1.x/reference/reference.html?highlight=pytest_runtest_makereport#std-hook-pytest_runtest_makereport\n    \"\"\"\n    def iterate_exc_chain(exc: Exception):\n        \"\"\"\n        Recurses through exception chain, yielding all exceptions",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "pytest_runtest_makereport",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "def pytest_runtest_makereport(item, call):\n    \"\"\"\n    Modifies test results after-the-fact. The function name is magic, see:\n    https://docs.pytest.org/en/7.1.x/reference/reference.html?highlight=pytest_runtest_makereport#std-hook-pytest_runtest_makereport\n    \"\"\"\n    def iterate_exc_chain(exc: Exception):\n        \"\"\"\n        Recurses through exception chain, yielding all exceptions\n        \"\"\"\n        yield exc",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "deny_network_access",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "def deny_network_access(*a, **kw):\n    raise NixNetworkAccessDeniedError\nimport httpx\nimport requests\nimport socket\nimport urllib\nimport urllib3\nimport websockets\nhttpx.AsyncClient.get = deny_network_access\nhttpx.AsyncClient.head = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "httpx.AsyncClient.get",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "httpx.AsyncClient.get = deny_network_access\nhttpx.AsyncClient.head = deny_network_access\nhttpx.Request = deny_network_access\nrequests.get = deny_network_access\nrequests.head = deny_network_access\nrequests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "httpx.AsyncClient.head",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "httpx.AsyncClient.head = deny_network_access\nhttpx.Request = deny_network_access\nrequests.get = deny_network_access\nrequests.head = deny_network_access\nrequests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "httpx.Request",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "httpx.Request = deny_network_access\nrequests.get = deny_network_access\nrequests.head = deny_network_access\nrequests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "requests.get",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "requests.get = deny_network_access\nrequests.head = deny_network_access\nrequests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "requests.head",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "requests.head = deny_network_access\nrequests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "requests.post",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "requests.post = deny_network_access\nsocket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "socket.socket.connect",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "socket.socket.connect = deny_network_access\nurllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "urllib.request.Request",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "urllib.request.Request = deny_network_access\nurllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "urllib.request.urlopen",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "urllib.request.urlopen = deny_network_access\nurllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "urllib3.connection.HTTPSConnection._new_conn",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "urllib3.connection.HTTPSConnection._new_conn = deny_network_access\nwebsockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "websockets.connect",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "peekOfCode": "websockets.connect = deny_network_access",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.gradio.conftest-skip-network-errors",
        "documentation": {}
    },
    {
        "label": "input_file",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "input_file = os.environ['image']\noutput_file_path = os.environ['out']\nnum_bits = int(os.environ['num_bits'])\nmethod = os.environ['method']\nbgr = cv2.imread(input_file)\ndecoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "output_file_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "output_file_path = os.environ['out']\nnum_bits = int(os.environ['num_bits'])\nmethod = os.environ['method']\nbgr = cv2.imread(input_file)\ndecoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "num_bits",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "num_bits = int(os.environ['num_bits'])\nmethod = os.environ['method']\nbgr = cv2.imread(input_file)\ndecoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "method",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "method = os.environ['method']\nbgr = cv2.imread(input_file)\ndecoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "bgr",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "bgr = cv2.imread(input_file)\ndecoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "decoder",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "decoder = WatermarkDecoder('bytes', num_bits)\nwatermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "watermark",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "watermark = decoder.decode(bgr, method)\nmessage = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "peekOfCode": "message = watermark.decode('utf-8')\nwith open(output_file_path, 'w') as f:\n    f.write(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.decode",
        "documentation": {}
    },
    {
        "label": "input_file_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "input_file_path = os.environ['image']\noutput_dir = os.environ['out']\nmessage = os.environ['message']\nmethod = os.environ['method']\nos.mkdir(output_dir)\nbgr = cv2.imread(input_file_path)\nencoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "output_dir = os.environ['out']\nmessage = os.environ['message']\nmethod = os.environ['method']\nos.mkdir(output_dir)\nbgr = cv2.imread(input_file_path)\nencoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "message = os.environ['message']\nmethod = os.environ['method']\nos.mkdir(output_dir)\nbgr = cv2.imread(input_file_path)\nencoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "method",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "method = os.environ['method']\nos.mkdir(output_dir)\nbgr = cv2.imread(input_file_path)\nencoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "bgr",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "bgr = cv2.imread(input_file_path)\nencoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "encoder",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "encoder = WatermarkEncoder()\nencoder.set_watermark('bytes', message.encode('utf-8'))\nbgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "bgr_encoded",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "bgr_encoded = encoder.encode(bgr, method)\noutput_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "output_file",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "peekOfCode": "output_file = os.path.join(output_dir, 'test_wm.png')\ncv2.imwrite(output_file, bgr_encoded)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.invisible-watermark.tests.python.encode",
        "documentation": {}
    },
    {
        "label": "en_core_web_sm",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "def en_core_web_sm():\n    return spacy.load(\"en_core_web_sm\")\n@pytest.fixture\ndef doc_en_core_web_sm(en_core_web_sm):\n    return en_core_web_sm(en_text)\ndef test_entities(doc_en_core_web_sm):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_sm.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "doc_en_core_web_sm",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "def doc_en_core_web_sm(en_core_web_sm):\n    return en_core_web_sm(en_text)\ndef test_entities(doc_en_core_web_sm):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_sm.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),\n        ('Google', 'ORG'),\n        ('2007', 'DATE'),\n        ('American', 'NORP'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_entities",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "def test_entities(doc_en_core_web_sm):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_sm.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),\n        ('Google', 'ORG'),\n        ('2007', 'DATE'),\n        ('American', 'NORP'),\n        ('Thrun', 'PERSON'),\n        ('Recode', 'ORG'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_nouns",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "def test_nouns(doc_en_core_web_sm):\n    assert [\n        chunk.text for chunk in doc_en_core_web_sm.noun_chunks] == [\n        'Sebastian Thrun',\n        'self-driving cars',\n        'Google',\n        'few people',\n        'the company',\n        'him',\n        'I',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_verbs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "def test_verbs(doc_en_core_web_sm):\n    assert [\n        token.lemma_ for token in doc_en_core_web_sm if token.pos_ == \"VERB\"] == [\n        'start',\n        'work',\n        'drive',\n        'take',\n        'tell',\n        'shake',\n        'turn',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "en_text",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "peekOfCode": "en_text = (\n    \"When Sebastian Thrun started working on self-driving cars at \"\n    \"Google in 2007, few people outside of the company took him \"\n    \"seriously. I can tell you very senior CEOs of major American \"\n    \"car companies would shake my hand and turn away because I wasnt \"\n    \"worth talking to, said Thrun, in an interview with Recode earlier \"\n    \"this week.\")\n@pytest.fixture\ndef en_core_web_sm():\n    return spacy.load(\"en_core_web_sm\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "en_core_web_trf",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "def en_core_web_trf():\n    return spacy.load(\"en_core_web_trf\")\n@pytest.fixture\ndef doc_en_core_web_trf(en_core_web_trf):\n    return en_core_web_trf(en_text)\ndef test_entities(doc_en_core_web_trf):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_trf.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "doc_en_core_web_trf",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "def doc_en_core_web_trf(en_core_web_trf):\n    return en_core_web_trf(en_text)\ndef test_entities(doc_en_core_web_trf):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_trf.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),\n        ('Google', 'ORG'),\n        ('2007', 'DATE'),\n        ('American', 'NORP'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_entities",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "def test_entities(doc_en_core_web_trf):\n    entities = list(map(lambda e: (e.text, e.label_),\n                        doc_en_core_web_trf.ents))\n    assert entities == [\n        ('Sebastian Thrun', 'PERSON'),\n        ('Google', 'ORG'),\n        ('2007', 'DATE'),\n        ('American', 'NORP'),\n        ('Thrun', 'PERSON'),\n        ('Recode', 'ORG'),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_nouns",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "def test_nouns(doc_en_core_web_trf):\n    assert [\n        chunk.text for chunk in doc_en_core_web_trf.noun_chunks] == [\n        'Sebastian Thrun',\n        'self-driving cars',\n        'Google',\n        'few people',\n        'the company',\n        'him',\n        'I',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "test_verbs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "def test_verbs(doc_en_core_web_trf):\n    assert [\n        token.lemma_ for token in doc_en_core_web_trf if token.pos_ == \"VERB\"] == [\n        'start',\n        'work',\n        'drive',\n        'take',\n        'tell',\n        'shake',\n        'turn',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "en_text",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "peekOfCode": "en_text = (\n    \"When Sebastian Thrun started working on self-driving cars at \"\n    \"Google in 2007, few people outside of the company took him \"\n    \"seriously. I can tell you very senior CEOs of major American \"\n    \"car companies would shake my hand and turn away because I wasnt \"\n    \"worth talking to, said Thrun, in an interview with Recode earlier \"\n    \"this week.\")\n@pytest.fixture\ndef en_core_web_trf():\n    return spacy.load(\"en_core_web_trf\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.python-modules.spacy-transformers.annotation-test.annotate",
        "documentation": {}
    },
    {
        "label": "http_archive",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "def http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "def http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,\n            \"sha256\": kw['sha256'][archive_name],\n            \"urls\": kw['urls'][archive_name]\n        })",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "git_repository",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "def git_repository(**kw):\n    print(json.dumps(kw, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nexec(sys.stdin.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }\ndef has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "has_urls",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "def has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])\ndef has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "has_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "def has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\nwith open(sys.argv[1], \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_archives",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "http_archives = []\n# just the kw args are the dict { name, sha256, urls  }\ndef http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "d = { el['name']: el for el in http_archives }\ndef has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])\ndef has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "bad_archives",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "peekOfCode": "bad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\nwith open(sys.argv[1], \"w\") as f:\n    print(json.dumps(d, sort_keys=True, indent=4), file=f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_5.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_archive",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "def http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "def http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,\n            \"sha256\": kw['sha256'][archive_name],\n            \"urls\": kw['urls'][archive_name]\n        })",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "git_repository",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "def git_repository(**kw):\n    print(json.dumps(kw, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nexec(sys.stdin.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }\ndef has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "has_urls",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "def has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])\ndef has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "has_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "def has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\nwith open(sys.argv[1], \"w\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_archives",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "http_archives = []\n# just the kw args are the dict { name, sha256, urls  }\ndef http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef _distdir_tar(**kw):\n    for archive_name in kw['archives']:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "d = { el['name']: el for el in http_archives }\ndef has_urls(el):\n    return ('url' in el and el['url']) or ('urls' in el and el['urls'])\ndef has_sha256(el):\n    return 'sha256' in el and el['sha256']\nbad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "bad_archives",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "peekOfCode": "bad_archives = list(filter(lambda el: not has_urls(el) or not has_sha256(el), d.values()))\nif bad_archives:\n    print('Following bazel dependencies are missing url or sha256', file=sys.stderr)\n    print('Check bazel sources for master or non-checksummed dependencies', file=sys.stderr)\n    for el in bad_archives:\n        print(json.dumps(el, sort_keys=True, indent=4), file=sys.stderr)\n    sys.exit(1)\nwith open(sys.argv[1], \"w\") as f:\n    print(json.dumps(d, sort_keys=True, indent=4), file=f)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.bazel_6.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_archive",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,\n            \"sha256\": kw['sha256'][archive_name],\n            \"urls\": kw['urls'][archive_name]\n        })",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "distdir_tar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def distdir_tar(**kw):\n    for archive_name in kw['archives']:\n        http_archives.append({\n            \"name\": archive_name,\n            \"sha256\": kw['sha256'][archive_name],\n            \"urls\": kw['urls'][archive_name]\n        })\n# stubs for symbols we are not interested in\n# might need to be expanded if new bazel releases add symbols to the workspace\ndef workspace(name): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "workspace",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def workspace(name): pass\ndef load(*args): pass\ndef bind(**kw): pass\ndef list_source_repository(**kw): pass\ndef new_local_repository(**kw): pass\ndef local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "load",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def load(*args): pass\ndef bind(**kw): pass\ndef list_source_repository(**kw): pass\ndef new_local_repository(**kw): pass\ndef local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "bind",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def bind(**kw): pass\ndef list_source_repository(**kw): pass\ndef new_local_repository(**kw): pass\ndef local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "list_source_repository",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def list_source_repository(**kw): pass\ndef new_local_repository(**kw): pass\ndef local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "new_local_repository",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def new_local_repository(**kw): pass\ndef local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "local_repository",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def local_repository(**kw): pass\nDOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "stardoc_repositories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "skydoc_repositories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "rules_sass_dependencies",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "node_repositories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "sass_repositories",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "register_execution_platforms",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "rbe_autoconfig",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "rules_pkg_dependencies",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "winsdk_configure",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def winsdk_configure(*args, **kw): pass\ndef register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "register_local_rc_exe_toolchains",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def register_local_rc_exe_toolchains(*args, **kw): pass\ndef register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "register_toolchains",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def register_toolchains(*args, **kw): pass\ndef debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())\n# transform to a dict with the names as keys",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "debian_deps",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def debian_deps(): pass\ndef grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "grpc_deps",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def grpc_deps(): pass\ndef grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }\nprint(json.dumps(d, sort_keys=True, indent=4))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "grpc_extra_deps",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def grpc_extra_deps(): pass\ndef bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }\nprint(json.dumps(d, sort_keys=True, indent=4))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "bazel_skylib_workspace",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "def bazel_skylib_workspace(): pass\n# execute the WORKSPACE like it was python code in this module,\n# using all the function stubs from above.\nwith open(sys.argv[1]) as f:\n    exec(f.read())\n# transform to a dict with the names as keys\nd = { el['name']: el for el in http_archives }\nprint(json.dumps(d, sort_keys=True, indent=4))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "http_archives",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "http_archives = []\n# just the kw args are the dict { name, sha256, urls  }\ndef http_archive(**kw):\n    http_archives.append(kw)\n# like http_file\ndef http_file(**kw):\n    http_archives.append(kw)\n# this is inverted from http_archive/http_file and bundles multiple archives\ndef distdir_tar(**kw):\n    for archive_name in kw['archives']:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "DOC_VERSIONS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "DOC_VERSIONS = []\ndef stardoc_repositories(**kw): pass\ndef skydoc_repositories(**kw): pass\ndef rules_sass_dependencies(**kw): pass\ndef node_repositories(**kw): pass\ndef sass_repositories(**kw): pass\ndef register_execution_platforms(*args): pass\ndef rbe_autoconfig(*args, **kw): pass\ndef rules_pkg_dependencies(*args, **kw): pass\ndef winsdk_configure(*args, **kw): pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "peekOfCode": "d = { el['name']: el for el in http_archives }\nprint(json.dumps(d, sort_keys=True, indent=4))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.build-managers.bazel.update-srcDeps",
        "documentation": {}
    },
    {
        "label": "Repo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "class Repo:\n    fetcher: str\n    args: dict\n    def __init__(self) -> None:\n        self.deps: dict = {}\n        self.hash = \"sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n    def get_deps(self, repo_vars: dict, path: str) -> None:\n        print(\n            \"evaluating \" + json.dumps(self, default=vars, sort_keys=True),\n            file=sys.stderr,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "GitRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "class GitRepo(Repo):\n    def __init__(self, url: str, rev: str) -> None:\n        super().__init__()\n        self.fetcher = \"fetchgit\"\n        self.args = {\n            \"url\": url,\n            \"rev\": rev,\n        }\nclass GitHubRepo(Repo):\n    def __init__(self, owner: str, repo: str, rev: str) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "GitHubRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "class GitHubRepo(Repo):\n    def __init__(self, owner: str, repo: str, rev: str) -> None:\n        super().__init__()\n        self.fetcher = \"fetchFromGitHub\"\n        self.args = {\n            \"owner\": owner,\n            \"repo\": repo,\n            \"rev\": rev,\n        }\n    def get_file(self, filepath: str) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "GitilesRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "class GitilesRepo(Repo):\n    def __init__(self, url: str, rev: str) -> None:\n        super().__init__()\n        self.fetcher = \"fetchFromGitiles\"\n        # self.fetcher = 'fetchgit'\n        self.args = {\n            \"url\": url,\n            \"rev\": rev,\n            # \"fetchSubmodules\": \"false\",\n        }",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "ElectronBinRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "class ElectronBinRepo(GitHubRepo):\n    def __init__(self, owner: str, repo: str, rev: str) -> None:\n        super().__init__(owner, repo, rev)\n        self.systems = {\n            \"i686-linux\": \"linux-ia32\",\n            \"x86_64-linux\": \"linux-x64\",\n            \"armv7l-linux\": \"linux-armv7l\",\n            \"aarch64-linux\": \"linux-arm64\",\n            \"x86_64-darwin\": \"darwin-x64\",\n            \"aarch64-darwin\": \"darwin-arm64\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "supported_version_range",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def supported_version_range() -> range:\n    \"\"\"Returns a range of electron releases that have not reached end-of-life yet\"\"\"\n    releases_json = json.loads(\n        urlopen(\"https://endoflife.date/api/electron.json\").read()\n    )\n    supported_releases = [\n        int(x[\"cycle\"])\n        for x in releases_json\n        if x[\"eol\"] == False\n        or datetime.strptime(x[\"eol\"], \"%Y-%m-%d\") > datetime.today()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_repo_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_repo_hash(fetcher: str, args: dict) -> str:\n    cmd = [\"nix-universal-prefetch\", fetcher]\n    for arg_name, arg in args.items():\n        cmd.append(f\"--{arg_name}\")\n        cmd.append(arg)\n    print(\" \".join(cmd), file=sys.stderr)\n    out = subprocess.check_output(cmd)\n    return out.decode(\"utf-8\").strip()\n@memory.cache\ndef _get_yarn_hash(path: str) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_yarn_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_yarn_hash(repo: Repo, yarn_lock_path: str = \"yarn.lock\") -> str:\n    return _get_yarn_hash(repo.get_file(yarn_lock_path))\n@memory.cache\ndef _get_npm_hash(filename: str) -> str:\n    print(f\"prefetch-npm-deps\", file=sys.stderr)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        with open(tmp_dir + \"/package-lock.json\", \"w\") as f:\n            f.write(filename)\n        return (\n            subprocess.check_output(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_npm_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_npm_hash(repo: Repo, package_lock_path: str = \"package-lock.json\") -> str:\n    return _get_npm_hash(repo.get_file(package_lock_path))\ndef repo_from_dep(dep: dict) -> Optional[Repo]:\n    if \"url\" in dep:\n        url, rev = gclient_utils.SplitUrlRevision(dep[\"url\"])\n        search_object = re.search(r\"https://github.com/(.+)/(.+?)(\\.git)?$\", url)\n        if search_object:\n            return GitHubRepo(search_object.group(1), search_object.group(2), rev)\n        if re.match(r\"https://.+.googlesource.com\", url):\n            return GitilesRepo(url, rev)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "repo_from_dep",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def repo_from_dep(dep: dict) -> Optional[Repo]:\n    if \"url\" in dep:\n        url, rev = gclient_utils.SplitUrlRevision(dep[\"url\"])\n        search_object = re.search(r\"https://github.com/(.+)/(.+?)(\\.git)?$\", url)\n        if search_object:\n            return GitHubRepo(search_object.group(1), search_object.group(2), rev)\n        if re.match(r\"https://.+.googlesource.com\", url):\n            return GitilesRepo(url, rev)\n        return GitRepo(url, rev)\n    else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_gn_source",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_gn_source(repo: Repo) -> dict:\n    gn_pattern = r\"'gn_version': 'git_revision:([0-9a-f]{40})'\"\n    gn_commit = re.search(gn_pattern, repo.get_file(\"DEPS\")).group(1)\n    gn_prefetch: bytes = subprocess.check_output(\n        [\n            \"nix-prefetch-git\",\n            \"--quiet\",\n            \"https://gn.googlesource.com/gn\",\n            \"--rev\",\n            gn_commit,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_latest_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_latest_version(major_version: str) -> Tuple[str, str]:\n    \"\"\"Returns the latest version for a given major version\"\"\"\n    electron_releases: dict = json.loads(\n        urlopen(\"https://releases.electronjs.org/releases.json\").read()\n    )\n    major_version_releases = filter(\n        lambda item: item[\"version\"].startswith(f\"{major_version}.\"), electron_releases\n    )\n    m = max(major_version_releases, key=lambda item: item[\"date\"])\n    rev = f\"v{m['version']}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_electron_bin_info",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_electron_bin_info(major_version: str) -> Tuple[str, str, ElectronBinRepo]:\n    m, rev = get_latest_version(major_version)\n    electron_repo: ElectronBinRepo = ElectronBinRepo(\"electron\", \"electron\", rev)\n    return (major_version, m, electron_repo)\ndef get_electron_info(major_version: str) -> Tuple[str, str, GitHubRepo]:\n    m, rev = get_latest_version(major_version)\n    electron_repo: GitHubRepo = GitHubRepo(\"electron\", \"electron\", rev)\n    electron_repo.get_deps(\n        {\n            f\"checkout_{platform}\": platform == \"linux\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_electron_info",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_electron_info(major_version: str) -> Tuple[str, str, GitHubRepo]:\n    m, rev = get_latest_version(major_version)\n    electron_repo: GitHubRepo = GitHubRepo(\"electron\", \"electron\", rev)\n    electron_repo.get_deps(\n        {\n            f\"checkout_{platform}\": platform == \"linux\"\n            for platform in [\"ios\", \"chromeos\", \"android\", \"mac\", \"win\", \"linux\"]\n        },\n        \"src/electron\",\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "get_update",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def get_update(repo: Tuple[str, str, Repo]) -> Tuple[str, dict]:\n    (major_version, m, electron_repo) = repo\n    tasks = electron_repo.prefetch_all()\n    a = lambda: ((\"electron_yarn_hash\", get_yarn_hash(electron_repo)))\n    tasks.append(delayed(a)())\n    a = lambda: (\n        (\n            \"chromium_npm_hash\",\n            get_npm_hash(\n                electron_repo.deps[\"src\"], \"third_party/node/package-lock.json\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "load_info_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def load_info_json(path: str) -> dict:\n    \"\"\"Load the contents of a JSON file\n    Args:\n        path: The path to the JSON file\n    Returns: An empty dict if the path does not exist, otherwise the contents of the JSON file.\n    \"\"\"\n    try:\n        with open(path, \"r\") as f:\n            return json.loads(f.read())\n    except:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "save_info_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def save_info_json(path: str, content: dict) -> None:\n    \"\"\"Saves the given info to a JSON file\n    Args:\n        path: The path where the info should be saved\n        content: The content to be saved as JSON.\n    \"\"\"\n    with open(path, \"w\") as f:\n        f.write(json.dumps(content, indent=JSON_INDENT, default=vars, sort_keys=True))\n        f.write(\"\\n\")\ndef update_bin(major_version: str, commit: bool) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "update_bin",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def update_bin(major_version: str, commit: bool) -> None:\n    \"\"\"Update a given electron-bin release\n    Args:\n        major_version: The major version number, e.g. '27'\n        commit: Whether the updater should commit the result\n    \"\"\"\n    package_name = f\"electron_{major_version}-bin\"\n    print(f\"Updating {package_name}\")\n    electron_bin_info = get_electron_bin_info(major_version)\n    (_major_version, _version, repo) = electron_bin_info",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "update_source",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def update_source(major_version: str, commit: bool) -> None:\n    \"\"\"Update a given electron-source release\n    Args:\n        major_version: The major version number, e.g. '27'\n        commit: Whether the updater should commit the result\n    \"\"\"\n    package_name = f\"electron-source.electron_{major_version}\"\n    print(f\"Updating electron-source.electron_{major_version}\")\n    old_info = load_info_json(SOURCE_INFO_JSON)\n    old_version = (",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "non_eol_releases",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def non_eol_releases(releases: Iterable[int]) -> Iterable[int]:\n    \"\"\"Returns a list of releases that have not reached end-of-life yet.\"\"\"\n    return tuple(filter(lambda x: x in supported_version_range(), releases))\ndef update_all_source(commit: bool) -> None:\n    \"\"\"Update all eletron-source releases at once\n    Args:\n        commit: Whether to commit the result\n    \"\"\"\n    old_info = load_info_json(SOURCE_INFO_JSON)\n    filtered_releases = non_eol_releases(tuple(map(lambda x: int(x), old_info.keys())))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "update_all_source",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def update_all_source(commit: bool) -> None:\n    \"\"\"Update all eletron-source releases at once\n    Args:\n        commit: Whether to commit the result\n    \"\"\"\n    old_info = load_info_json(SOURCE_INFO_JSON)\n    filtered_releases = non_eol_releases(tuple(map(lambda x: int(x), old_info.keys())))\n    # This might take some time\n    repos = Parallel(n_jobs=2, require=\"sharedmem\")(\n        delayed(get_electron_info)(major_version) for major_version in filtered_releases",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "parse_cve_numbers",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def parse_cve_numbers(tag_name: str) -> Iterable[str]:\n    \"\"\"Returns mentioned CVE numbers from a given release tag\"\"\"\n    cve_pattern = r\"CVE-\\d{4}-\\d+\"\n    url = f\"https://api.github.com/repos/electron/electron/releases/tags/{tag_name}\"\n    headers = {\n        \"Accept\": \"application/vnd.github+json\",\n        \"X-GitHub-Api-Version\": \"2022-11-28\",\n    }\n    request = urllib.request.Request(url=url, headers=headers)\n    release_note = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "commit_result",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def commit_result(\n    package_name: str, old_version: Optional[str], new_version: str, path: str\n) -> None:\n    \"\"\"Creates a git commit with a short description of the change\n    Args:\n        package_name: The package name, e.g. `electron-source.electron-{major_version}`\n            or `electron_{major_version}-bin`\n        old_version: Version number before the update.\n            Can be left empty when initializing a new release.\n        new_version: Version number after the update.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def cli() -> None:\n    \"\"\"A script for updating electron-bin and electron-source hashes\"\"\"\n    pass\n@cli.command(\n    \"eval\", help=\"Print the necessary sources to fetch for a given major release\"\n)\n@click.option(\"--version\", help=\"The major version, e.g. '23'\")\ndef eval(version):\n    (_, _, repo) = electron_repo = get_electron_info(version)\n    tree = repo.flatten(\"src/electron\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "eval",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def eval(version):\n    (_, _, repo) = electron_repo = get_electron_info(version)\n    tree = repo.flatten(\"src/electron\")\n    print(json.dumps(tree, indent=JSON_INDENT, default=vars, sort_keys=True))\n@cli.command(\"update\", help=\"Update a single major release\")\n@click.option(\"-v\", \"--version\", help=\"The major version, e.g. '23'\")\n@click.option(\n    \"-b\",\n    \"--bin-only\",\n    is_flag=True,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "update",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def update(version: str, bin_only: bool, source_only: bool, commit: bool) -> None:\n    assert isinstance(version, str) and len(version) > 0, \"version must be non-empty\"\n    if bin_only and source_only:\n        print(\n            \"Error: Omit --bin-only and --source-only if you want to update both source and binary packages.\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n    elif bin_only:\n        update_bin(version, commit)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "update_all",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "def update_all(bin_only: bool, source_only: bool, commit: bool) -> None:\n    # Filter out releases that have reached end-of-life\n    filtered_bin_info = dict(\n        filter(\n            lambda entry: int(entry[0]) in supported_version_range(),\n            load_info_json(BINARY_INFO_JSON).items(),\n        )\n    )\n    if bin_only and source_only:\n        print(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "depot_tools_checkout",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "depot_tools_checkout = tempfile.TemporaryDirectory()\nsubprocess.check_call(\n    [\n        \"nix-prefetch-git\",\n        \"--builder\",\n        \"--quiet\",\n        \"--url\",\n        \"https://chromium.googlesource.com/chromium/tools/depot_tools\",\n        \"--out\",\n        depot_tools_checkout.name,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "SOURCE_INFO_JSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "SOURCE_INFO_JSON = \"info.json\"\n# Relatice path to the electron-bin info.json\nBINARY_INFO_JSON = \"binary/info.json\"\n# Number of spaces used for each indentation level\nJSON_INDENT = 4\nos.chdir(os.path.dirname(__file__))\nmemory: Memory = Memory(\"cache\", verbose=0)\nlogger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass Repo:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "BINARY_INFO_JSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "BINARY_INFO_JSON = \"binary/info.json\"\n# Number of spaces used for each indentation level\nJSON_INDENT = 4\nos.chdir(os.path.dirname(__file__))\nmemory: Memory = Memory(\"cache\", verbose=0)\nlogger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass Repo:\n    fetcher: str\n    args: dict",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "JSON_INDENT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "JSON_INDENT = 4\nos.chdir(os.path.dirname(__file__))\nmemory: Memory = Memory(\"cache\", verbose=0)\nlogger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass Repo:\n    fetcher: str\n    args: dict\n    def __init__(self) -> None:\n        self.deps: dict = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclick_log.basic_config(logger)\nclass Repo:\n    fetcher: str\n    args: dict\n    def __init__(self) -> None:\n        self.deps: dict = {}\n        self.hash = \"sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n    def get_deps(self, repo_vars: dict, path: str) -> None:\n        print(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.electron.update",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def log(msg: str) -> None:\n    print(msg, file=sys.stderr)\ndef atomically_write(file_path: str, content: bytes) -> None:\n    \"\"\"atomically write the content into `file_path`\"\"\"\n    with NamedTemporaryFile(\n        # write to the parent dir, so that its guaranteed to be on the same filesystem\n        dir=os.path.dirname(file_path),\n        delete=False\n    ) as tmp:\n        try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "atomically_write",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def atomically_write(file_path: str, content: bytes) -> None:\n    \"\"\"atomically write the content into `file_path`\"\"\"\n    with NamedTemporaryFile(\n        # write to the parent dir, so that its guaranteed to be on the same filesystem\n        dir=os.path.dirname(file_path),\n        delete=False\n    ) as tmp:\n        try:\n            tmp.write(content)\n            os.rename(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "curl_github_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def curl_github_args(token: str | None, url: str) -> Args:\n    \"\"\"Query the github API via curl\"\"\"\n    yield bins[\"curl\"]\n    if not debug:\n        yield \"--silent\"\n    # follow redirects\n    yield \"--location\"\n    if token:\n        yield \"-H\"\n        yield f\"Authorization: token {token}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "curl_result",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def curl_result(output: bytes) -> Any | Literal[\"not found\"]:\n    \"\"\"Parse the curl result of the github API\"\"\"\n    res: Any = json.loads(output)\n    match res:\n        case dict(res):\n            message: str = res.get(\"message\", \"\")\n            if \"rate limit\" in message:\n                sys.exit(\"Rate limited by the Github API\")\n            if \"Not Found\" in message:\n                return \"not found\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_git_args",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def nix_prefetch_git_args(url: str, version_rev: str) -> Args:\n    \"\"\"Prefetch a git repository\"\"\"\n    yield bins[\"nix-prefetch-git\"]\n    if not debug:\n        yield \"--quiet\"\n    yield \"--no-deepClone\"\n    yield \"--url\"\n    yield url\n    yield \"--rev\"\n    yield version_rev",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "run_cmd",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def run_cmd(args: Args) -> bytes:\n    all = list(args)\n    if debug:\n        log(str(all))\n    return sub.check_output(all)\nDir = str\ndef fetchRepo() -> None:\n    \"\"\"fetch the given repo and write its nix-prefetch output to the corresponding grammar json file\"\"\"\n    match jsonArg:\n        case {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "fetchRepo",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def fetchRepo() -> None:\n    \"\"\"fetch the given repo and write its nix-prefetch output to the corresponding grammar json file\"\"\"\n    match jsonArg:\n        case {\n            \"orga\": orga,\n            \"repo\": repo,\n            \"outputDir\": outputDir,\n            \"nixRepoAttrName\": nixRepoAttrName,\n        }:\n            token: str | None = os.environ.get(\"GITHUB_TOKEN\", None)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "fetchOrgaLatestRepos",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def fetchOrgaLatestRepos(orga: str) -> set[str]:\n    \"\"\"fetch the latest (100) repos from the given github organization\"\"\"\n    token: str | None = os.environ.get(\"GITHUB_TOKEN\", None)\n    out = run_cmd(\n        curl_github_args(\n            token,\n            url=f\"https://api.github.com/orgs/{quote(orga)}/repos?per_page=100\"\n        )\n    )\n    match curl_result(out):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "checkTreeSitterRepos",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def checkTreeSitterRepos(latest_github_repos: set[str]) -> None:\n    \"\"\"Make sure we know about all tree sitter repos on the tree sitter orga.\"\"\"\n    known: set[str] = set(args[\"knownTreeSitterOrgGrammarRepos\"])\n    ignored: set[str] = set(args[\"ignoredTreeSitterOrgRepos\"])\n    unknown = latest_github_repos - (known | ignored)\n    if unknown:\n        sys.exit(f\"These repositories are neither known nor ignored:\\n{unknown}\")\nGrammar = TypedDict(\n    \"Grammar\",\n    {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "printAllGrammarsNixFile",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def printAllGrammarsNixFile() -> None:\n    \"\"\"Print a .nix file that imports all grammars.\"\"\"\n    allGrammars: list[dict[str, Grammar]] = jsonArg[\"allGrammars\"]\n    outputDir: Dir = jsonArg[\"outputDir\"]\n    def file() -> Iterator[str]:\n        yield \"{ lib }:\"\n        yield \"{\"\n        for grammar in allGrammars:\n            n = grammar[\"nixRepoAttrName\"]\n            yield f\"  {n} = lib.importJSON ./{n}.json;\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "fetchAndCheckTreeSitterRepos",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "def fetchAndCheckTreeSitterRepos() -> None:\n    log(\"fetching list of grammars\")\n    latest_repos = fetchOrgaLatestRepos(orga=\"tree-sitter\")\n    log(\"checking the tree-sitter repo list against the grammars we know\")\n    checkTreeSitterRepos(latest_repos)\nmatch mode:\n    case \"fetch-repo\":\n        fetchRepo()\n    case \"fetch-and-check-tree-sitter-repos\":\n        fetchAndCheckTreeSitterRepos()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "Bin",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "Bin = str\nargs: dict[str, Any] = json.loads(os.environ[\"ARGS\"])\nbins: dict[str, Bin] = args[\"binaries\"]\nmode: str = sys.argv[1]\njsonArg: dict = json.loads(sys.argv[2])\nArgs = Iterator[str]\ndef log(msg: str) -> None:\n    print(msg, file=sys.stderr)\ndef atomically_write(file_path: str, content: bytes) -> None:\n    \"\"\"atomically write the content into `file_path`\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "Args",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "Args = Iterator[str]\ndef log(msg: str) -> None:\n    print(msg, file=sys.stderr)\ndef atomically_write(file_path: str, content: bytes) -> None:\n    \"\"\"atomically write the content into `file_path`\"\"\"\n    with NamedTemporaryFile(\n        # write to the parent dir, so that its guaranteed to be on the same filesystem\n        dir=os.path.dirname(file_path),\n        delete=False\n    ) as tmp:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "Dir",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "Dir = str\ndef fetchRepo() -> None:\n    \"\"\"fetch the given repo and write its nix-prefetch output to the corresponding grammar json file\"\"\"\n    match jsonArg:\n        case {\n            \"orga\": orga,\n            \"repo\": repo,\n            \"outputDir\": outputDir,\n            \"nixRepoAttrName\": nixRepoAttrName,\n        }:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "Grammar",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "peekOfCode": "Grammar = TypedDict(\n    \"Grammar\",\n    {\n        \"nixRepoAttrName\": str,\n        \"orga\": str,\n        \"repo\": str,\n        \"branch\": Optional[str]\n    }\n)\ndef printAllGrammarsNixFile() -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.development.tools.parsing.tree-sitter.update_impl",
        "documentation": {}
    },
    {
        "label": "System",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "class System:\n    nix_name: str\n    url_name: str\n    tar_name: str\n@dataclass\nclass ReleaseType:\n    name: str\n    needs_auth: bool = False\n@dataclass\nclass ReleaseChannel:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "ReleaseType",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "class ReleaseType:\n    name: str\n    needs_auth: bool = False\n@dataclass\nclass ReleaseChannel:\n    name: str\nFactorioVersionsJSON = Dict[str, Dict[str, str]]\nOurVersionJSON = Dict[str, Dict[str, Dict[str, Dict[str, str]]]]\nSYSTEMS = [\n    System(nix_name=\"x86_64-linux\", url_name=\"linux64\", tar_name=\"x64\"),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "ReleaseChannel",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "class ReleaseChannel:\n    name: str\nFactorioVersionsJSON = Dict[str, Dict[str, str]]\nOurVersionJSON = Dict[str, Dict[str, Dict[str, Dict[str, str]]]]\nSYSTEMS = [\n    System(nix_name=\"x86_64-linux\", url_name=\"linux64\", tar_name=\"x64\"),\n]\nRELEASE_TYPES = [\n    ReleaseType(\"alpha\", needs_auth=True),\n    ReleaseType(\"demo\"),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "find_versions_json",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def find_versions_json() -> str:\n    if FLAGS.out:\n        return FLAGS.out\n    try_paths = [\"pkgs/games/factorio/versions.json\", \"versions.json\"]\n    for path in try_paths:\n        if os.path.exists(path):\n            return path\n    raise Exception(\"Couldn't figure out where to write versions.json; try specifying --out\")\ndef fetch_versions() -> FactorioVersionsJSON:\n    return json.loads(requests.get(\"https://factorio.com/api/latest-releases\").text)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "fetch_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def fetch_versions() -> FactorioVersionsJSON:\n    return json.loads(requests.get(\"https://factorio.com/api/latest-releases\").text)\ndef generate_our_versions(factorio_versions: FactorioVersionsJSON) -> OurVersionJSON:\n    rec_dd = lambda: defaultdict(rec_dd)\n    output = rec_dd()\n    # Deal with times where there's no experimental version\n    for rc in RELEASE_CHANNELS:\n        if not factorio_versions[rc.name]:\n            factorio_versions[rc.name] = factorio_versions['stable']\n    for system in SYSTEMS:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "generate_our_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def generate_our_versions(factorio_versions: FactorioVersionsJSON) -> OurVersionJSON:\n    rec_dd = lambda: defaultdict(rec_dd)\n    output = rec_dd()\n    # Deal with times where there's no experimental version\n    for rc in RELEASE_CHANNELS:\n        if not factorio_versions[rc.name]:\n            factorio_versions[rc.name] = factorio_versions['stable']\n    for system in SYSTEMS:\n        for release_type in RELEASE_TYPES:\n            for release_channel in RELEASE_CHANNELS:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "iter_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def iter_version(versions: OurVersionJSON, it: Callable[[str, str, str, Dict[str, str]], Dict[str, str]]) -> OurVersionJSON:\n    versions = copy.deepcopy(versions)\n    for system_name, system in versions.items():\n        for release_type_name, release_type in system.items():\n            for release_channel_name, release in release_type.items():\n                release_type[release_channel_name] = it(system_name, release_type_name, release_channel_name, dict(release))\n    return versions\ndef merge_versions(old: OurVersionJSON, new: OurVersionJSON) -> OurVersionJSON:\n    \"\"\"Copies already-known hashes from version.json to avoid having to re-fetch.\"\"\"\n    def _merge_version(system_name: str, release_type_name: str, release_channel_name: str, release: Dict[str, str]) -> Dict[str, str]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "merge_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def merge_versions(old: OurVersionJSON, new: OurVersionJSON) -> OurVersionJSON:\n    \"\"\"Copies already-known hashes from version.json to avoid having to re-fetch.\"\"\"\n    def _merge_version(system_name: str, release_type_name: str, release_channel_name: str, release: Dict[str, str]) -> Dict[str, str]:\n        old_system = old.get(system_name, {})\n        old_release_type = old_system.get(release_type_name, {})\n        old_release = old_release_type.get(release_channel_name, {})\n        if FLAGS.release_type and release_type_name not in FLAGS.release_type:\n            logging.info(\"%s/%s/%s: not in --release_type, not updating\", system_name, release_type_name, release_channel_name)\n            return old_release\n        if FLAGS.release_channel and release_channel_name not in FLAGS.release_channel:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def nix_prefetch_url(name: str, url: str, algo: str = 'sha256') -> str:\n    cmd = ['nix-prefetch-url', '--type', algo, '--name', name, url]\n    logging.info('running %s', cmd)\n    out = subprocess.check_output(cmd)\n    return out.decode('utf-8').strip()\ndef fill_in_hash(versions: OurVersionJSON) -> OurVersionJSON:\n    \"\"\"Fill in sha256 hashes for anything missing them.\"\"\"\n    urls_to_hash = {}\n    def _fill_in_hash(system_name: str, release_type_name: str, release_channel_name: str, release: Dict[str, str]) -> Dict[str, str]:\n        if \"sha256\" in release:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "fill_in_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def fill_in_hash(versions: OurVersionJSON) -> OurVersionJSON:\n    \"\"\"Fill in sha256 hashes for anything missing them.\"\"\"\n    urls_to_hash = {}\n    def _fill_in_hash(system_name: str, release_type_name: str, release_channel_name: str, release: Dict[str, str]) -> Dict[str, str]:\n        if \"sha256\" in release:\n            logging.info(\"%s/%s/%s: skipping fetch, sha256 already present\", system_name, release_type_name, release_channel_name)\n            return release\n        url = release[\"url\"]\n        if url in urls_to_hash:\n            logging.info(\"%s/%s/%s: found url %s in cache\", system_name, release_type_name, release_channel_name, url)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "def main(argv):\n    factorio_versions = fetch_versions()\n    new_our_versions = generate_our_versions(factorio_versions)\n    old_our_versions = None\n    our_versions_path = find_versions_json()\n    if our_versions_path:\n        logging.info('Loading old versions.json from %s', our_versions_path)\n        with open(our_versions_path, 'r') as f:\n            old_our_versions = json.load(f)\n    if old_our_versions:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "FACTORIO_API",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "FACTORIO_API = \"https://factorio.com/api/latest-releases\"\nFLAGS = flags.FLAGS\nflags.DEFINE_string('username', '', 'Factorio username for retrieving binaries.')\nflags.DEFINE_string('token', '', 'Factorio token for retrieving binaries.')\nflags.DEFINE_string('out', '', 'Output path for versions.json.')\nflags.DEFINE_list('release_type', '', 'If non-empty, a comma-separated list of release types to update (e.g. alpha).')\nflags.DEFINE_list('release_channel', '', 'If non-empty, a comma-separated list of release channels to update (e.g. experimental).')\n@dataclass\nclass System:\n    nix_name: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "FLAGS = flags.FLAGS\nflags.DEFINE_string('username', '', 'Factorio username for retrieving binaries.')\nflags.DEFINE_string('token', '', 'Factorio token for retrieving binaries.')\nflags.DEFINE_string('out', '', 'Output path for versions.json.')\nflags.DEFINE_list('release_type', '', 'If non-empty, a comma-separated list of release types to update (e.g. alpha).')\nflags.DEFINE_list('release_channel', '', 'If non-empty, a comma-separated list of release channels to update (e.g. experimental).')\n@dataclass\nclass System:\n    nix_name: str\n    url_name: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "FactorioVersionsJSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "FactorioVersionsJSON = Dict[str, Dict[str, str]]\nOurVersionJSON = Dict[str, Dict[str, Dict[str, Dict[str, str]]]]\nSYSTEMS = [\n    System(nix_name=\"x86_64-linux\", url_name=\"linux64\", tar_name=\"x64\"),\n]\nRELEASE_TYPES = [\n    ReleaseType(\"alpha\", needs_auth=True),\n    ReleaseType(\"demo\"),\n    ReleaseType(\"headless\"),\n]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "OurVersionJSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "OurVersionJSON = Dict[str, Dict[str, Dict[str, Dict[str, str]]]]\nSYSTEMS = [\n    System(nix_name=\"x86_64-linux\", url_name=\"linux64\", tar_name=\"x64\"),\n]\nRELEASE_TYPES = [\n    ReleaseType(\"alpha\", needs_auth=True),\n    ReleaseType(\"demo\"),\n    ReleaseType(\"headless\"),\n]\nRELEASE_CHANNELS = [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "SYSTEMS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "SYSTEMS = [\n    System(nix_name=\"x86_64-linux\", url_name=\"linux64\", tar_name=\"x64\"),\n]\nRELEASE_TYPES = [\n    ReleaseType(\"alpha\", needs_auth=True),\n    ReleaseType(\"demo\"),\n    ReleaseType(\"headless\"),\n]\nRELEASE_CHANNELS = [\n    ReleaseChannel(\"experimental\"),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "RELEASE_TYPES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "RELEASE_TYPES = [\n    ReleaseType(\"alpha\", needs_auth=True),\n    ReleaseType(\"demo\"),\n    ReleaseType(\"headless\"),\n]\nRELEASE_CHANNELS = [\n    ReleaseChannel(\"experimental\"),\n    ReleaseChannel(\"stable\"),\n]\ndef find_versions_json() -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "RELEASE_CHANNELS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "peekOfCode": "RELEASE_CHANNELS = [\n    ReleaseChannel(\"experimental\"),\n    ReleaseChannel(\"stable\"),\n]\ndef find_versions_json() -> str:\n    if FLAGS.out:\n        return FLAGS.out\n    try_paths = [\"pkgs/games/factorio/versions.json\", \"versions.json\"]\n    for path in try_paths:\n        if os.path.exists(path):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.factorio.update",
        "documentation": {}
    },
    {
        "label": "Download",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "class Download(DataClassJsonMixin):\n    sha1: str\n    size: int\n    url: str\n@dataclass\nclass Version(DataClassJsonMixin):\n    id: str\n    type: str\n    url: str\n    time: datetime = field(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "Version",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "class Version(DataClassJsonMixin):\n    id: str\n    type: str\n    url: str\n    time: datetime = field(\n        metadata=config(\n            encoder=datetime.isoformat,\n            decoder=datetime.fromisoformat,\n            mm_field=fields.DateTime(format=\"iso\"),\n        )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "get_versions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "def get_versions() -> List[Version]:\n    \"\"\"Return a list of Version objects for all available versions.\"\"\"\n    response = requests.get(\n        \"https://launchermeta.mojang.com/mc/game/version_manifest.json\"\n    )\n    response.raise_for_status()\n    data = response.json()\n    return [Version.from_dict(version) for version in data[\"versions\"]]\ndef get_major_release(version_id: str) -> str:\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "get_major_release",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "def get_major_release(version_id: str) -> str:\n    \"\"\"\n    Return the major release for a version. The major release for 1.17 and\n    1.17.1 is 1.17.\n    \"\"\"\n    if not len(version_id.split(\".\")) >= 2:\n        raise ValueError(f\"version not in expected format: '{version_id}'\")\n    return \".\".join(version_id.split(\".\")[:2])\ndef group_major_releases(releases: List[Version]) -> Dict[str, List[Version]]:\n    \"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "group_major_releases",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "def group_major_releases(releases: List[Version]) -> Dict[str, List[Version]]:\n    \"\"\"\n    Return a dictionary containing each version grouped by each major release.\n    The key \"1.17\" contains a list with two Version objects, one for \"1.17\"\n    and another for \"1.17.1\".\n    \"\"\"\n    groups: Dict[str, List[Version]] = {}\n    for release in releases:\n        major_release = get_major_release(release.id)\n        if major_release not in groups:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "get_latest_major_releases",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "def get_latest_major_releases(releases: List[Version]) -> Dict[str, Version]:\n    \"\"\"\n    Return a dictionary containing the latest version for each major release.\n    The latest major release for 1.16 is 1.16.5, so the key \"1.16\" contains a\n    Version object for 1.16.5.\n    \"\"\"\n    return {\n        major_release: max(\n            (release for release in releases if get_major_release(release.id) == major_release),\n            key=lambda x: tuple(map(int, x.id.split('.'))),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "generate",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "peekOfCode": "def generate() -> Dict[str, Dict[str, str]]:\n    \"\"\"\n    Return a dictionary containing the latest url, sha1 and version for each major\n    release.\n    \"\"\"\n    versions = get_versions()\n    releases = list(\n        filter(lambda version: version.type == \"release\", versions)\n    )  # remove snapshots and betas\n    latest_major_releases = get_latest_major_releases(releases)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.minecraft-servers.update",
        "documentation": {}
    },
    {
        "label": "Version",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "peekOfCode": "class Version:\n    def __init__(self, name: str):\n        self.name: str = name\n        self.hash: str | None = None\n        self.build_number: int | None = None\n    @property\n    def full_name(self):\n        v_name = f\"{self.name}-{self.build_number}\"\n        # this will probably never happen because the download of a build with NoneType in URL would fail\n        if not self.name or not self.build_number:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "documentation": {}
    },
    {
        "label": "VersionManager",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "peekOfCode": "class VersionManager:\n    def __init__(self, base_url: str = \"https://api.papermc.io/v2/projects/paper\"):\n        self.versions: list[Version] = []\n        self.base_url: str = base_url\n    def fetch_versions(self, not_before_minor_version: int = 18):\n        \"\"\"\n        Fetch all versions after given minor release\n        \"\"\"\n        response = requests.get(self.base_url)\n        try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.games.papermc.update",
        "documentation": {}
    },
    {
        "label": "request_supported_refs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "def request_supported_refs() -> list[str]:\n    # Looks pretty shady but I think this should work with every version of the page in the last 20 years\n    r = re.compile(\"^h\\d$\", re.IGNORECASE)\n    soup = bs4.BeautifulSoup(\n        urllib.request.urlopen(\"https://www.freebsd.org/security\"), features=\"lxml\"\n    )\n    header = soup.find(\n        lambda tag: r.match(tag.name) is not None\n        and tag.text.lower() == \"supported freebsd releases\"\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "query_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "def query_version(repo: git.Repo) -> dict[str, typing.Any]:\n    # This only works on FreeBSD 13 and later\n    text = (\n        subprocess.check_output(\n            [\"bash\", os.path.join(repo.working_dir, \"sys\", \"conf\", \"newvers.sh\"), \"-v\"]\n        )\n        .decode(\"utf-8\")\n        .strip()\n    )\n    fields = dict()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "handle_commit",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "def handle_commit(\n    repo: git.Repo,\n    rev: git.objects.commit.Commit,\n    ref_name: str,\n    ref_type: str,\n    supported_refs: list[str],\n    old_versions: dict[str, typing.Any],\n) -> dict[str, typing.Any]:\n    if old_versions.get(ref_name, {}).get(\"rev\", None) == rev.hexsha:\n        print(f\"{ref_name}: revision still {rev.hexsha}, skipping\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "def main() -> None:\n    # Normally uses /run/user/*, which is on a tmpfs and too small\n    temp_dir = tempfile.TemporaryDirectory(dir=\"/tmp\")\n    print(f\"Selected temporary directory {temp_dir.name}\")\n    if len(sys.argv) >= 2:\n        orig_repo = git.Repo(sys.argv[1])\n        print(f\"Fetching updates on {orig_repo.git_dir}\")\n        orig_repo.remote(\"origin\").fetch()\n    else:\n        print(\"Cloning source repo\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "_QUERY_VERSION_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "_QUERY_VERSION_PATTERN = re.compile('^([A-Z]+)=\"(.+)\"$')\n_RELEASE_PATCH_PATTERN = re.compile('^RELEASE-p([0-9]+)$')\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nMIN_VERSION = packaging.version.Version(\"13.0.0\")\nMAIN_BRANCH = \"main\"\nTAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "_RELEASE_PATCH_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "_RELEASE_PATCH_PATTERN = re.compile('^RELEASE-p([0-9]+)$')\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nMIN_VERSION = packaging.version.Version(\"13.0.0\")\nMAIN_BRANCH = \"main\"\nTAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\nMIN_VERSION = packaging.version.Version(\"13.0.0\")\nMAIN_BRANCH = \"main\"\nTAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "MIN_VERSION",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "MIN_VERSION = packaging.version.Version(\"13.0.0\")\nMAIN_BRANCH = \"main\"\nTAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,\n)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "MAIN_BRANCH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "MAIN_BRANCH = \"main\"\nTAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,\n)\ndef request_supported_refs() -> list[str]:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "TAG_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "TAG_PATTERN = re.compile(\n    f\"^release/({packaging.version.VERSION_PATTERN})$\", re.IGNORECASE | re.VERBOSE\n)\nREMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,\n)\ndef request_supported_refs() -> list[str]:\n    # Looks pretty shady but I think this should work with every version of the page in the last 20 years",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "REMOTE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "REMOTE = \"origin\"\nBRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,\n)\ndef request_supported_refs() -> list[str]:\n    # Looks pretty shady but I think this should work with every version of the page in the last 20 years\n    r = re.compile(\"^h\\d$\", re.IGNORECASE)\n    soup = bs4.BeautifulSoup(\n        urllib.request.urlopen(\"https://www.freebsd.org/security\"), features=\"lxml\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "BRANCH_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "peekOfCode": "BRANCH_PATTERN = re.compile(\n    f\"^{REMOTE}/((stable|releng)/({packaging.version.VERSION_PATTERN}))$\",\n    re.IGNORECASE | re.VERBOSE,\n)\ndef request_supported_refs() -> list[str]:\n    # Looks pretty shady but I think this should work with every version of the page in the last 20 years\n    r = re.compile(\"^h\\d$\", re.IGNORECASE)\n    soup = bs4.BeautifulSoup(\n        urllib.request.urlopen(\"https://www.freebsd.org/security\"), features=\"lxml\"\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.bsd.freebsd.update",
        "documentation": {}
    },
    {
        "label": "eprint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "def eprint(*args):\n    print(*args, file=sys.stderr)\ndef name_from_ident(ident):\n    return ident.get(\"swift\", ident.get(\"clang\"))\ndef scan_sdk(sdk):\n    # Find frameworks by scanning the SDK frameworks directory.\n    frameworks = [\n        framework.removesuffix(\".framework\")\n        for framework in os.listdir(f\"{sdk}/System/Library/Frameworks\")\n        if not framework.startswith(\"_\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "name_from_ident",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "def name_from_ident(ident):\n    return ident.get(\"swift\", ident.get(\"clang\"))\ndef scan_sdk(sdk):\n    # Find frameworks by scanning the SDK frameworks directory.\n    frameworks = [\n        framework.removesuffix(\".framework\")\n        for framework in os.listdir(f\"{sdk}/System/Library/Frameworks\")\n        if not framework.startswith(\"_\")\n    ]\n    frameworks.sort()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "scan_sdk",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "def scan_sdk(sdk):\n    # Find frameworks by scanning the SDK frameworks directory.\n    frameworks = [\n        framework.removesuffix(\".framework\")\n        for framework in os.listdir(f\"{sdk}/System/Library/Frameworks\")\n        if not framework.startswith(\"_\")\n    ]\n    frameworks.sort()\n    # Determine the longest name for padding output.\n    width = len(max(frameworks, key=len))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "ALLOWED_LIBS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "ALLOWED_LIBS = [\"simd\"]\nHEADER = \"\"\"\\\n# This file is generated by gen-frameworks.nix.\n# Do not edit, put overrides in apple_sdk.nix instead.\n{ libs, frameworks }: with libs; with frameworks;\n{\n\"\"\"\nFOOTER = \"\"\"\\\n}\n\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "HEADER = \"\"\"\\\n# This file is generated by gen-frameworks.nix.\n# Do not edit, put overrides in apple_sdk.nix instead.\n{ libs, frameworks }: with libs; with frameworks;\n{\n\"\"\"\nFOOTER = \"\"\"\\\n}\n\"\"\"\ndef eprint(*args):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "FOOTER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "peekOfCode": "FOOTER = \"\"\"\\\n}\n\"\"\"\ndef eprint(*args):\n    print(*args, file=sys.stderr)\ndef name_from_ident(ident):\n    return ident.get(\"swift\", ident.get(\"clang\"))\ndef scan_sdk(sdk):\n    # Find frameworks by scanning the SDK frameworks directory.\n    frameworks = [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.darwin.gen-frameworks",
        "documentation": {}
    },
    {
        "label": "NixOSPathNamespace",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "peekOfCode": "class NixOSPathNamespace(FedoraPathNamespace):\n    SBIN_IPA_JOIN = \"@out@/bin/ipa-join\"\n    IPA_GETCERT = \"@out@/bin/ipa-getcert\"\n    IPA_RMKEYTAB = \"@out@/bin/ipa-rmkeytab\"\n    IPA_GETKEYTAB = \"@out@/bin/ipa-getkeytab\"\n    NSUPDATE = \"@bind@/bin/nsupdate\"\n    BIN_CURL = \"@curl@/bin/curl\"\n    KINIT = \"@kerberos@/bin/kinit\"\n    KDESTROY = \"@kerberos@/bin/kdestroy\"\npaths = NixOSPathNamespace()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "documentation": {}
    },
    {
        "label": "paths",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "peekOfCode": "paths = NixOSPathNamespace()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.freeipa.paths",
        "documentation": {}
    },
    {
        "label": "ReleaseInfo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "class ReleaseInfo:\n    version: Version\n    release: GitRelease\nHERE = Path(__file__).resolve().parent\nNIXPKGS_KERNEL_PATH = HERE.parent\nNIXPKGS_PATH = HERE.parents[4]\nHARDENED_GITHUB_REPO = \"anthraxx/linux-hardened\"\nHARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "read_min_kernel_branch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def read_min_kernel_branch() -> List[str]:\n    with open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as f:\n        return list(parse_version(sorted(json.load(f).keys())[0]).release)\n@dataclass\nclass ReleaseInfo:\n    version: Version\n    release: GitRelease\nHERE = Path(__file__).resolve().parent\nNIXPKGS_KERNEL_PATH = HERE.parent\nNIXPKGS_PATH = HERE.parents[4]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            encoding=\"utf-8\",\n        )\n    except subprocess.CalledProcessError as err:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def nix_prefetch_url(url: str) -> Tuple[str, Path]:\n    output = run(\"nix-prefetch-url\", \"--print-path\", url).stdout\n    sha256, path = output.strip().split(\"\\n\")\n    return sha256, Path(path)\ndef verify_openpgp_signature(\n    *, name: str, trusted_key: Path, sig_path: Path, data_path: Path,\n) -> bool:\n    with TemporaryDirectory(suffix=\".nixpkgs-gnupg-home\") as gnupg_home_str:\n        gnupg_home = Path(gnupg_home_str)\n        run(\"gpg\", \"--homedir\", gnupg_home, \"--import\", trusted_key)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "verify_openpgp_signature",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def verify_openpgp_signature(\n    *, name: str, trusted_key: Path, sig_path: Path, data_path: Path,\n) -> bool:\n    with TemporaryDirectory(suffix=\".nixpkgs-gnupg-home\") as gnupg_home_str:\n        gnupg_home = Path(gnupg_home_str)\n        run(\"gpg\", \"--homedir\", gnupg_home, \"--import\", trusted_key)\n        keyring = gnupg_home / \"pubring.kbx\"\n        try:\n            subprocess.run(\n                (\"gpgv\", \"--keyring\", keyring, sig_path, data_path),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "fetch_patch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def fetch_patch(*, name: str, release_info: ReleaseInfo) -> Optional[Patch]:\n    release = release_info.release\n    extra = f'-{release_info.version[-1]}'\n    def find_asset(filename: str) -> str:\n        try:\n            it: Iterator[str] = (\n                asset.browser_download_url\n                for asset in release.get_assets()\n                if asset.name == filename\n            )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "parse_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def parse_version(version_str: str) -> Version:\n    version: Version = []\n    for component in re.split('\\.|\\-', version_str):\n        try:\n            version.append(int(component))\n        except ValueError:\n            version.append(component)\n    return version\ndef version_string(version: Version) -> str:\n    return \".\".join(str(component) for component in version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "version_string",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def version_string(version: Version) -> str:\n    return \".\".join(str(component) for component in version)\ndef major_kernel_version_key(kernel_version: Version) -> str:\n    return version_string(kernel_version[:-1])\ndef commit_patches(*, kernel_key: str, message: str) -> None:\n    new_patches_path = HARDENED_PATCHES_PATH.with_suffix(\".new\")\n    with open(new_patches_path, \"w\") as new_patches_file:\n        json.dump(patches, new_patches_file, indent=4, sort_keys=True)\n        new_patches_file.write(\"\\n\")\n    os.rename(new_patches_path, HARDENED_PATCHES_PATH)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "major_kernel_version_key",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def major_kernel_version_key(kernel_version: Version) -> str:\n    return version_string(kernel_version[:-1])\ndef commit_patches(*, kernel_key: str, message: str) -> None:\n    new_patches_path = HARDENED_PATCHES_PATH.with_suffix(\".new\")\n    with open(new_patches_path, \"w\") as new_patches_file:\n        json.dump(patches, new_patches_file, indent=4, sort_keys=True)\n        new_patches_file.write(\"\\n\")\n    os.rename(new_patches_path, HARDENED_PATCHES_PATH)\n    message = f\"linux/hardened/patches/{kernel_key}: {message}\"\n    print(message)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "commit_patches",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "def commit_patches(*, kernel_key: str, message: str) -> None:\n    new_patches_path = HARDENED_PATCHES_PATH.with_suffix(\".new\")\n    with open(new_patches_path, \"w\") as new_patches_file:\n        json.dump(patches, new_patches_file, indent=4, sort_keys=True)\n        new_patches_file.write(\"\\n\")\n    os.rename(new_patches_path, HARDENED_PATCHES_PATH)\n    message = f\"linux/hardened/patches/{kernel_key}: {message}\"\n    print(message)\n    if os.environ.get(\"COMMIT\"):\n        run(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "VersionComponent",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "VersionComponent = Union[int, str]\nVersion = List[VersionComponent]\nPatchData = TypedDict(\"PatchData\", {\"name\": str, \"url\": str, \"sha256\": str, \"extra\": str})\nPatch = TypedDict(\"Patch\", {\n    \"patch\": PatchData,\n    \"version\": str,\n    \"sha256\": str,\n})\ndef read_min_kernel_branch() -> List[str]:\n    with open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as f:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "Version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "Version = List[VersionComponent]\nPatchData = TypedDict(\"PatchData\", {\"name\": str, \"url\": str, \"sha256\": str, \"extra\": str})\nPatch = TypedDict(\"Patch\", {\n    \"patch\": PatchData,\n    \"version\": str,\n    \"sha256\": str,\n})\ndef read_min_kernel_branch() -> List[str]:\n    with open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as f:\n        return list(parse_version(sorted(json.load(f).keys())[0]).release)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "PatchData",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "PatchData = TypedDict(\"PatchData\", {\"name\": str, \"url\": str, \"sha256\": str, \"extra\": str})\nPatch = TypedDict(\"Patch\", {\n    \"patch\": PatchData,\n    \"version\": str,\n    \"sha256\": str,\n})\ndef read_min_kernel_branch() -> List[str]:\n    with open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as f:\n        return list(parse_version(sorted(json.load(f).keys())[0]).release)\n@dataclass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "Patch",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "Patch = TypedDict(\"Patch\", {\n    \"patch\": PatchData,\n    \"version\": str,\n    \"sha256\": str,\n})\ndef read_min_kernel_branch() -> List[str]:\n    with open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as f:\n        return list(parse_version(sorted(json.load(f).keys())[0]).release)\n@dataclass\nclass ReleaseInfo:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "HERE = Path(__file__).resolve().parent\nNIXPKGS_KERNEL_PATH = HERE.parent\nNIXPKGS_PATH = HERE.parents[4]\nHARDENED_GITHUB_REPO = \"anthraxx/linux-hardened\"\nHARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_KERNEL_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "NIXPKGS_KERNEL_PATH = HERE.parent\nNIXPKGS_PATH = HERE.parents[4]\nHARDENED_GITHUB_REPO = \"anthraxx/linux-hardened\"\nHARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "NIXPKGS_PATH = HERE.parents[4]\nHARDENED_GITHUB_REPO = \"anthraxx/linux-hardened\"\nHARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,\n            check=True,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "HARDENED_GITHUB_REPO",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "HARDENED_GITHUB_REPO = \"anthraxx/linux-hardened\"\nHARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,\n            check=True,\n            stdout=subprocess.PIPE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "HARDENED_TRUSTED_KEY",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "HARDENED_TRUSTED_KEY = HERE / \"anthraxx.asc\"\nHARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "HARDENED_PATCHES_PATH",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "HARDENED_PATCHES_PATH = HERE / \"patches.json\"\nMIN_KERNEL_VERSION: Version = read_min_kernel_branch()\ndef run(*args: Union[str, Path]) -> subprocess.CompletedProcess[bytes]:\n    try:\n        return subprocess.run(\n            args,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            encoding=\"utf-8\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "kernel_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "kernel_versions = {}\nwith open(NIXPKGS_KERNEL_PATH / \"kernels-org.json\") as kernel_versions_json:\n    kernel_versions = json.load(kernel_versions_json)\n    for kernel_branch_str in kernel_versions:\n        if kernel_branch_str == \"testing\": continue\n        kernel_branch = [int(i) for i in kernel_branch_str.split(\".\")]\n        if kernel_branch < MIN_KERNEL_VERSION: continue\n        kernel_version = [int(i) for i in kernel_versions[kernel_branch_str][\"version\"].split(\".\")]\n        kernel_versions[kernel_branch_str] = kernel_version\n# Remove patches for unpackaged kernel versions.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "g",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "g = Github(os.environ.get(\"GITHUB_TOKEN\"))\nrepo = g.get_repo(HARDENED_GITHUB_REPO)\nfailures = False\n# Match each kernel version with the best patch version.\nreleases = {}\ni = 0\nfor release in repo.get_releases():\n    # Dirty workaround to make sure that we don't run into issues because\n    # GitHub's API only allows fetching the last 1000 releases.\n    # It's not reliable to exit earlier because not every kernel minor may",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "repo",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "repo = g.get_repo(HARDENED_GITHUB_REPO)\nfailures = False\n# Match each kernel version with the best patch version.\nreleases = {}\ni = 0\nfor release in repo.get_releases():\n    # Dirty workaround to make sure that we don't run into issues because\n    # GitHub's API only allows fetching the last 1000 releases.\n    # It's not reliable to exit earlier because not every kernel minor may\n    # have hardened patches, hence the naive search below.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "failures",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "failures = False\n# Match each kernel version with the best patch version.\nreleases = {}\ni = 0\nfor release in repo.get_releases():\n    # Dirty workaround to make sure that we don't run into issues because\n    # GitHub's API only allows fetching the last 1000 releases.\n    # It's not reliable to exit earlier because not every kernel minor may\n    # have hardened patches, hence the naive search below.\n    i += 1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "releases",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "releases = {}\ni = 0\nfor release in repo.get_releases():\n    # Dirty workaround to make sure that we don't run into issues because\n    # GitHub's API only allows fetching the last 1000 releases.\n    # It's not reliable to exit earlier because not every kernel minor may\n    # have hardened patches, hence the naive search below.\n    i += 1\n    if i > 500:\n        break",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "i",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "i = 0\nfor release in repo.get_releases():\n    # Dirty workaround to make sure that we don't run into issues because\n    # GitHub's API only allows fetching the last 1000 releases.\n    # It's not reliable to exit earlier because not every kernel minor may\n    # have hardened patches, hence the naive search below.\n    i += 1\n    if i > 500:\n        break\n    version = parse_version(release.tag_name)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "missing_kernel_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "peekOfCode": "missing_kernel_versions = kernel_versions.keys() - patches.keys()\nif missing_kernel_versions:\n    print(\n        f\"warning: no patches for kernel versions \"\n        + \", \".join(missing_kernel_versions),\n        file=sys.stderr,\n    )\nif failures:\n    sys.exit(1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.hardened.update",
        "documentation": {}
    },
    {
        "label": "KernelNature",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "class KernelNature(Enum):\n    MAINLINE = 1\n    STABLE = 2\n    LONGTERM = 3\n@dataclass\nclass KernelRelease:\n    nature: KernelNature\n    version: str\n    branch: str\n    date: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "KernelRelease",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "class KernelRelease:\n    nature: KernelNature\n    version: str\n    branch: str\n    date: str\n    link: str\n    eol: bool = False\ndef parse_release(release: Tag) -> KernelRelease | None:\n    columns: list[Tag] = list(release.find_all(\"td\"))\n    try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "parse_release",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def parse_release(release: Tag) -> KernelRelease | None:\n    columns: list[Tag] = list(release.find_all(\"td\"))\n    try:\n        nature = KernelNature[columns[0].get_text().rstrip(\":\").upper()]\n    except KeyError:\n        return None\n    version = columns[1].get_text().rstrip(\" [EOL]\")\n    date = columns[2].get_text()\n    link = columns[3].find(\"a\")\n    if link is not None and isinstance(link, Tag):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "get_branch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def get_branch(version: str):\n    # This is a testing kernel.\n    if \"rc\" in version:\n        return \"testing\"\n    else:\n        major, minor, *_ = version.split(\".\")\n        return f\"{major}.{minor}\"\ndef get_hash(kernel: KernelRelease):\n    if kernel.branch == \"testing\":\n        args = [\"--unpack\"]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def get_hash(kernel: KernelRelease):\n    if kernel.branch == \"testing\":\n        args = [\"--unpack\"]\n    else:\n        args = []\n    hash = (\n        subprocess.check_output([\"nix-prefetch-url\", kernel.link] + args)\n        .decode()\n        .strip()\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "get_oldest_branch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def get_oldest_branch() -> Version:\n    with open(VERSIONS_FILE) as f:\n        return parse_version(sorted(json.load(f).keys())[0])\ndef predates_oldest_branch(oldest: Version, to_compare: str) -> bool:\n    if to_compare == \"testing\":\n        return False\n    return parse_version(to_compare) < oldest\ndef commit(message):\n    return subprocess.check_call([\"git\", \"commit\", \"-m\", message, VERSIONS_FILE])\ndef main():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "predates_oldest_branch",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def predates_oldest_branch(oldest: Version, to_compare: str) -> bool:\n    if to_compare == \"testing\":\n        return False\n    return parse_version(to_compare) < oldest\ndef commit(message):\n    return subprocess.check_call([\"git\", \"commit\", \"-m\", message, VERSIONS_FILE])\ndef main():\n    kernel_org = urllib.request.urlopen(\"https://kernel.org/\")\n    soup = BeautifulSoup(kernel_org.read().decode(), \"lxml\")\n    release_table = soup.find(id=\"releases\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "commit",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def commit(message):\n    return subprocess.check_call([\"git\", \"commit\", \"-m\", message, VERSIONS_FILE])\ndef main():\n    kernel_org = urllib.request.urlopen(\"https://kernel.org/\")\n    soup = BeautifulSoup(kernel_org.read().decode(), \"lxml\")\n    release_table = soup.find(id=\"releases\")\n    if not release_table or isinstance(release_table, NavigableString):\n        print(release_table, file=sys.stderr)\n        print(\"Failed to find the release table on https://kernel.org\", file=sys.stderr)\n        sys.exit(1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "def main():\n    kernel_org = urllib.request.urlopen(\"https://kernel.org/\")\n    soup = BeautifulSoup(kernel_org.read().decode(), \"lxml\")\n    release_table = soup.find(id=\"releases\")\n    if not release_table or isinstance(release_table, NavigableString):\n        print(release_table, file=sys.stderr)\n        print(\"Failed to find the release table on https://kernel.org\", file=sys.stderr)\n        sys.exit(1)\n    releases = release_table.find_all(\"tr\")\n    parsed_releases = filter(None, [parse_release(release) for release in releases])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nROOT = HERE.parent.parent.parent.parent\nVERSIONS_FILE = HERE / \"kernels-org.json\"\nclass KernelNature(Enum):\n    MAINLINE = 1\n    STABLE = 2\n    LONGTERM = 3\n@dataclass\nclass KernelRelease:\n    nature: KernelNature",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "ROOT = HERE.parent.parent.parent.parent\nVERSIONS_FILE = HERE / \"kernels-org.json\"\nclass KernelNature(Enum):\n    MAINLINE = 1\n    STABLE = 2\n    LONGTERM = 3\n@dataclass\nclass KernelRelease:\n    nature: KernelNature\n    version: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "VERSIONS_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "peekOfCode": "VERSIONS_FILE = HERE / \"kernels-org.json\"\nclass KernelNature(Enum):\n    MAINLINE = 1\n    STABLE = 2\n    LONGTERM = 3\n@dataclass\nclass KernelRelease:\n    nature: KernelNature\n    version: str\n    branch: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-mainline",
        "documentation": {}
    },
    {
        "label": "panic",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def panic(exc):\n    raise Exception(exc)\nDIR = os.path.dirname(os.path.abspath(__file__))\nHEADERS = {'Accept': 'application/vnd.github.v3+json'}\ndef github_api_request(endpoint):\n    base_url = 'https://api.github.com/'\n    request = Request(base_url + endpoint, headers=HEADERS)\n    with urlopen(request) as http_response:\n        return json.loads(http_response.read().decode('utf-8'))\ndef get_commit_date(repo, sha):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "github_api_request",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def github_api_request(endpoint):\n    base_url = 'https://api.github.com/'\n    request = Request(base_url + endpoint, headers=HEADERS)\n    with urlopen(request) as http_response:\n        return json.loads(http_response.read().decode('utf-8'))\ndef get_commit_date(repo, sha):\n    url = f'https://api.github.com/repos/{repo}/commits/{sha}'\n    request = Request(url, headers=HEADERS)\n    with urlopen(request) as http_response:\n        commit = json.loads(http_response.read().decode())",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "get_commit_date",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def get_commit_date(repo, sha):\n    url = f'https://api.github.com/repos/{repo}/commits/{sha}'\n    request = Request(url, headers=HEADERS)\n    with urlopen(request) as http_response:\n        commit = json.loads(http_response.read().decode())\n        date = commit['commit']['committer']['date'].rstrip('Z')\n        date = datetime.fromisoformat(date).date().isoformat()\n        return 'unstable-' + date\ndef nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision (incl. submodules) of the given repository URL.\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_git",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def nix_prefetch_git(url, rev):\n    \"\"\"Prefetches the requested Git revision (incl. submodules) of the given repository URL.\"\"\"\n    print(f'nix-prefetch-git {url} {rev}')\n    out = subprocess.check_output([\n        'nix-prefetch-git', '--quiet',\n        '--url', url,\n        '--rev', rev,\n        '--fetch-submodules'])\n    return json.loads(out)['sha256']\ndef nix_prefetch_url(url, unpack=False):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def nix_prefetch_url(url, unpack=False):\n    \"\"\"Prefetches the content of the given URL.\"\"\"\n    print(f'nix-prefetch-url {url}')\n    options = ['--type', 'sha256']\n    if unpack:\n        options += ['--unpack']\n    out = subprocess.check_output(['nix-prefetch-url'] + options + [url])\n    return out.decode('utf-8').rstrip()\ndef update_file(relpath, variant, version, suffix, sha256):\n    file_path = os.path.join(DIR, relpath)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "update_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def update_file(relpath, variant, version, suffix, sha256):\n    file_path = os.path.join(DIR, relpath)\n    with fileinput.FileInput(file_path, inplace=True) as f:\n        for line in f:\n            result = line\n            result = re.sub(\n                fr'^    version = \".+\"; #{variant}',\n                f'    version = \"{version}\"; #{variant}',\n                result)\n            result = re.sub(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "def read_file(relpath, variant):\n    file_path = os.path.join(DIR, relpath)\n    re_version = re.compile(fr'^\\s*version = \"(.+)\"; #{variant}')\n    re_suffix = re.compile(fr'^\\s*suffix = \"(.+)\"; #{variant}')\n    version = None\n    suffix = None\n    with fileinput.FileInput(file_path, mode='r') as f:\n        for line in f:\n            version_match = re_version.match(line)\n            if version_match:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "DIR = os.path.dirname(os.path.abspath(__file__))\nHEADERS = {'Accept': 'application/vnd.github.v3+json'}\ndef github_api_request(endpoint):\n    base_url = 'https://api.github.com/'\n    request = Request(base_url + endpoint, headers=HEADERS)\n    with urlopen(request) as http_response:\n        return json.loads(http_response.read().decode('utf-8'))\ndef get_commit_date(repo, sha):\n    url = f'https://api.github.com/repos/{repo}/commits/{sha}'\n    request = Request(url, headers=HEADERS)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "HEADERS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "peekOfCode": "HEADERS = {'Accept': 'application/vnd.github.v3+json'}\ndef github_api_request(endpoint):\n    base_url = 'https://api.github.com/'\n    request = Request(base_url + endpoint, headers=HEADERS)\n    with urlopen(request) as http_response:\n        return json.loads(http_response.read().decode('utf-8'))\ndef get_commit_date(repo, sha):\n    url = f'https://api.github.com/repos/{repo}/commits/{sha}'\n    request = Request(url, headers=HEADERS)\n    with urlopen(request) as http_response:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.os-specific.linux.kernel.update-zen",
        "documentation": {}
    },
    {
        "label": "get_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_version():\n    with open(os.path.dirname(sys.argv[0]) + \"/default.nix\") as fh:\n        # A version consists of digits, dots, and possibly a \"b\" (for beta)\n        m = re.search('version = \"([\\\\d\\\\.b]+)\";', fh.read())\n        return m.group(1)\ndef get_file_from_github(version: str, path: str):\n    with urlopen(\n        f\"https://raw.githubusercontent.com/apache/airflow/{version}/{path}\"\n    ) as response:\n        return yaml.safe_load(response)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "get_file_from_github",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_file_from_github(version: str, path: str):\n    with urlopen(\n        f\"https://raw.githubusercontent.com/apache/airflow/{version}/{path}\"\n    ) as response:\n        return yaml.safe_load(response)\ndef repository_root() -> Path:\n    return Path(os.path.dirname(sys.argv[0])) / \"../../..\"\ndef dump_packages() -> Dict[str, Dict[str, str]]:\n    # Store a JSON dump of Nixpkgs' python3Packages\n    output = subprocess.check_output(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "repository_root",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def repository_root() -> Path:\n    return Path(os.path.dirname(sys.argv[0])) / \"../../..\"\ndef dump_packages() -> Dict[str, Dict[str, str]]:\n    # Store a JSON dump of Nixpkgs' python3Packages\n    output = subprocess.check_output(\n        [\n            \"nix-env\",\n            \"-f\",\n            repository_root(),\n            \"-qa\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "dump_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def dump_packages() -> Dict[str, Dict[str, str]]:\n    # Store a JSON dump of Nixpkgs' python3Packages\n    output = subprocess.check_output(\n        [\n            \"nix-env\",\n            \"-f\",\n            repository_root(),\n            \"-qa\",\n            \"-A\",\n            PKG_SET,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "remove_version_constraint",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def remove_version_constraint(req: str) -> str:\n    return re.sub(r\"[=><~].*$\", \"\", req)\ndef name_to_attr_path(req: str, packages: Dict[str, Dict[str, str]]) -> Optional[str]:\n    if req in PKG_PREFERENCES:\n        return f\"{PKG_SET}.{PKG_PREFERENCES[req]}\"\n    attr_paths = []\n    names = [req]\n    # E.g. python-mpd2 is actually called python3.6-mpd2\n    # instead of python-3.6-python-mpd2 inside Nixpkgs\n    if req.startswith(\"python-\") or req.startswith(\"python_\"):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "name_to_attr_path",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def name_to_attr_path(req: str, packages: Dict[str, Dict[str, str]]) -> Optional[str]:\n    if req in PKG_PREFERENCES:\n        return f\"{PKG_SET}.{PKG_PREFERENCES[req]}\"\n    attr_paths = []\n    names = [req]\n    # E.g. python-mpd2 is actually called python3.6-mpd2\n    # instead of python-3.6-python-mpd2 inside Nixpkgs\n    if req.startswith(\"python-\") or req.startswith(\"python_\"):\n        names.append(req[len(\"python-\") :])\n    for name in names:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "provider_reqs_to_attr_paths",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def provider_reqs_to_attr_paths(reqs: List, packages: Dict) -> List:\n    no_version_reqs = map(remove_version_constraint, reqs)\n    filtered_reqs = [\n        req for req in no_version_reqs if not re.match(r\"^apache-airflow\", req)\n    ]\n    attr_paths = []\n    for req in filtered_reqs:\n        attr_path = name_to_attr_path(req, packages)\n        if attr_path is not None:\n            # Add attribute path without \"python3Packages.\" prefix",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "get_cross_provider_reqs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_cross_provider_reqs(\n    provider: str, provider_reqs: Dict, cross_provider_deps: Dict, seen: List = None\n) -> Set:\n    # Unfortunately there are circular cross-provider dependencies, so keep a\n    # list of ones we've seen already\n    seen = seen or []\n    reqs = set(provider_reqs[provider])\n    if len(cross_provider_deps[provider]) > 0:\n        reqs.update(\n            chain.from_iterable(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "get_provider_reqs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_provider_reqs(version: str, packages: Dict) -> Dict:\n    provider_dependencies = get_file_from_github(\n        version, \"generated/provider_dependencies.json\"\n    )\n    provider_reqs = {}\n    cross_provider_deps = {}\n    for provider, provider_data in provider_dependencies.items():\n        provider_reqs[provider] = list(\n            provider_reqs_to_attr_paths(provider_data[\"deps\"], packages)\n        ) + EXTRA_REQS.get(provider, [])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "get_provider_yaml",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_provider_yaml(version: str, provider: str) -> Dict:\n    provider_dir = provider.replace(\".\", \"/\")\n    path = f\"airflow/providers/{provider_dir}/provider.yaml\"\n    try:\n        return get_file_from_github(version, path)\n    except HTTPError:\n        logging.warning(\"Couldn't get provider yaml for %s\", provider)\n        return {}\ndef get_provider_imports(version: str, providers) -> Dict:\n    provider_imports = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "get_provider_imports",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def get_provider_imports(version: str, providers) -> Dict:\n    provider_imports = {}\n    for provider in providers:\n        provider_yaml = get_provider_yaml(version, provider)\n        imports: List[str] = []\n        if \"hooks\" in provider_yaml:\n            imports.extend(\n                chain.from_iterable(\n                    hook[\"python-modules\"] for hook in provider_yaml[\"hooks\"]\n                )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "to_nix_expr",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def to_nix_expr(provider_reqs: Dict, provider_imports: Dict, fh: TextIO) -> None:\n    fh.write(\"# Warning: generated by update-providers.py, do not update manually\\n\")\n    fh.write(\"{\\n\")\n    for provider, reqs in provider_reqs.items():\n        provider_name = provider.replace(\".\", \"_\")\n        fh.write(f\"  {provider_name} = {{\\n\")\n        fh.write(\n            \"    deps = [ \" + \" \".join(sorted(f'\"{req}\"' for req in reqs)) + \" ];\\n\"\n        )\n        fh.write(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "def main() -> None:\n    logging.basicConfig(level=logging.INFO)\n    version = get_version()\n    packages = dump_packages()\n    logging.info(\"Generating providers.nix for version %s\", version)\n    provider_reqs = get_provider_reqs(version, packages)\n    provider_imports = get_provider_imports(version, provider_reqs.keys())\n    with open(\"providers.nix\", \"w\") as fh:\n        to_nix_expr(provider_reqs, provider_imports, fh)\nif __name__ == \"__main__\":",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "PKG_SET",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "PKG_SET = \"apache-airflow.pythonPackages\"\n# If some requirements are matched by multiple or no Python packages, the\n# following can be used to choose the correct one\nPKG_PREFERENCES = {\n    \"dnspython\": \"dnspython\",\n    \"elasticsearch-dsl\": \"elasticsearch-dsl\",\n    \"google-api-python-client\": \"google-api-python-client\",\n    \"protobuf\": \"protobuf\",\n    \"psycopg2-binary\": \"psycopg2\",\n    \"requests_toolbelt\": \"requests-toolbelt\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "PKG_PREFERENCES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "PKG_PREFERENCES = {\n    \"dnspython\": \"dnspython\",\n    \"elasticsearch-dsl\": \"elasticsearch-dsl\",\n    \"google-api-python-client\": \"google-api-python-client\",\n    \"protobuf\": \"protobuf\",\n    \"psycopg2-binary\": \"psycopg2\",\n    \"requests_toolbelt\": \"requests-toolbelt\",\n}\n# Requirements missing from the airflow provider metadata\nEXTRA_REQS = {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "EXTRA_REQS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "peekOfCode": "EXTRA_REQS = {\n    \"sftp\": [\"pysftp\"],\n}\ndef get_version():\n    with open(os.path.dirname(sys.argv[0]) + \"/default.nix\") as fh:\n        # A version consists of digits, dots, and possibly a \"b\" (for beta)\n        m = re.search('version = \"([\\\\d\\\\.b]+)\";', fh.read())\n        return m.group(1)\ndef get_file_from_github(version: str, path: str):\n    with urlopen(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.apache-airflow.update-providers",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "URL = \"https://downloads.asterisk.org/pub/telephony/asterisk/\"\npage = requests.get(URL)\nchangelog = re.compile(\"^ChangeLog-\\d+\\.\\d+\\.\\d+\\.md$\")\nchangelogs = [a.get_text() for a in BeautifulSoup(page.text, 'html.parser').find_all('a') if changelog.match(a.get_text())]\nmajor_versions = {}\nfor changelog in changelogs:\n    v = version.parse(changelog.removeprefix(\"ChangeLog-\").removesuffix(\".md\"))\n    major_versions.setdefault(v.major, []).append(v)\nout = {}\nfor mv in major_versions.keys():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "page",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "page = requests.get(URL)\nchangelog = re.compile(\"^ChangeLog-\\d+\\.\\d+\\.\\d+\\.md$\")\nchangelogs = [a.get_text() for a in BeautifulSoup(page.text, 'html.parser').find_all('a') if changelog.match(a.get_text())]\nmajor_versions = {}\nfor changelog in changelogs:\n    v = version.parse(changelog.removeprefix(\"ChangeLog-\").removesuffix(\".md\"))\n    major_versions.setdefault(v.major, []).append(v)\nout = {}\nfor mv in major_versions.keys():\n    v = max(major_versions[mv])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "changelog",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "changelog = re.compile(\"^ChangeLog-\\d+\\.\\d+\\.\\d+\\.md$\")\nchangelogs = [a.get_text() for a in BeautifulSoup(page.text, 'html.parser').find_all('a') if changelog.match(a.get_text())]\nmajor_versions = {}\nfor changelog in changelogs:\n    v = version.parse(changelog.removeprefix(\"ChangeLog-\").removesuffix(\".md\"))\n    major_versions.setdefault(v.major, []).append(v)\nout = {}\nfor mv in major_versions.keys():\n    v = max(major_versions[mv])\n    sha = requests.get(f\"{URL}/asterisk-{v}.sha256\").text.split()[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "changelogs",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "changelogs = [a.get_text() for a in BeautifulSoup(page.text, 'html.parser').find_all('a') if changelog.match(a.get_text())]\nmajor_versions = {}\nfor changelog in changelogs:\n    v = version.parse(changelog.removeprefix(\"ChangeLog-\").removesuffix(\".md\"))\n    major_versions.setdefault(v.major, []).append(v)\nout = {}\nfor mv in major_versions.keys():\n    v = max(major_versions[mv])\n    sha = requests.get(f\"{URL}/asterisk-{v}.sha256\").text.split()[0]\n    out[\"asterisk_\" + str(mv)] = {",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "major_versions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "major_versions = {}\nfor changelog in changelogs:\n    v = version.parse(changelog.removeprefix(\"ChangeLog-\").removesuffix(\".md\"))\n    major_versions.setdefault(v.major, []).append(v)\nout = {}\nfor mv in major_versions.keys():\n    v = max(major_versions[mv])\n    sha = requests.get(f\"{URL}/asterisk-{v}.sha256\").text.split()[0]\n    out[\"asterisk_\" + str(mv)] = {\n        \"version\": str(v),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "out = {}\nfor mv in major_versions.keys():\n    v = max(major_versions[mv])\n    sha = requests.get(f\"{URL}/asterisk-{v}.sha256\").text.split()[0]\n    out[\"asterisk_\" + str(mv)] = {\n        \"version\": str(v),\n        \"sha256\": sha\n    }\nversions_path = Path(sys.argv[0]).parent / \"versions.json\"\ntry:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "versions_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "peekOfCode": "versions_path = Path(sys.argv[0]).parent / \"versions.json\"\ntry:\n    with open(versions_path, \"r\") as in_file:\n        in_data = json.loads(in_file.read())\n        for v in in_data.keys():\n            print(v + \":\", in_data[v][\"version\"], \"->\", out[v][\"version\"])\nexcept:\n    # nice to have for the PR, not a requirement\n    pass\nwith open(versions_path, \"w\") as out_file:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.asterisk.update",
        "documentation": {}
    },
    {
        "label": "WiktionaryLatestVersionParser",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "peekOfCode": "class WiktionaryLatestVersionParser(HTMLParser):\n    def __init__(self, current_version, *args, **kwargs):\n        self.latest_version = current_version\n        super().__init__(*args, **kwargs)\n    def handle_starttag(self, tag, attrs):\n        if tag != 'a':\n            return\n        href = dict(attrs)['href'][0:-1]\n        if href == 'latest':\n            return",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_url",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "peekOfCode": "def nix_prefetch_url(url, algo='sha256'):\n    \"\"\"Prefetches the content of the given URL.\"\"\"\n    print(f'nix-prefetch-url {url}')\n    out = subprocess.check_output(['nix-prefetch-url', '--type', algo, url])\n    return out.rstrip()\ncurrent_version = subprocess.check_output([\n    'nix', 'eval', '--raw',\n    '-f', dirname(abspath(__file__)) + '/../../../..',\n    'dictdDBs.wiktionary.version',\n])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "documentation": {}
    },
    {
        "label": "current_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "peekOfCode": "current_version = subprocess.check_output([\n    'nix', 'eval', '--raw',\n    '-f', dirname(abspath(__file__)) + '/../../../..',\n    'dictdDBs.wiktionary.version',\n])\nparser = WiktionaryLatestVersionParser(current_version)\nwith urlopen('https://dumps.wikimedia.org/enwiktionary/') as resp:\n    parser.feed(resp.read())\nprint(parser.latest_version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "peekOfCode": "parser = WiktionaryLatestVersionParser(current_version)\nwith urlopen('https://dumps.wikimedia.org/enwiktionary/') as resp:\n    parser.feed(resp.read())\nprint(parser.latest_version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.latest_version",
        "documentation": {}
    },
    {
        "label": "Text",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class Text:\n    def __init__(self, s):\n        self.s = s\n    def process(self):\n        return s\nclass TemplateCall:\n    def __init__(self):\n        pass\n    def process(self):\n        pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "TemplateCall",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class TemplateCall:\n    def __init__(self):\n        pass\n    def process(self):\n        pass\nclass Template:\n    def __init__(self):\n        self.parts = []\n    def append(self, part):\n        self.parts.append(part)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Template",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class Template:\n    def __init__(self):\n        self.parts = []\n    def append(self, part):\n        self.parts.append(part)\n    def process(self):\n        return ''.join(x.process() for x in self.parts)\nclass Whitespace:\n    def __init__(self, s):\n        self.s = s",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Whitespace",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class Whitespace:\n    def __init__(self, s):\n        self.s = s\nclass OpenDouble: pass\nclass OpenTriple: pass\nclass CloseDouble: pass\nclass CloseTriple: pass\nclass Equals:\n    def __str__(self):\n        return \"=\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "OpenDouble",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class OpenDouble: pass\nclass OpenTriple: pass\nclass CloseDouble: pass\nclass CloseTriple: pass\nclass Equals:\n    def __str__(self):\n        return \"=\"\nclass Delimiter:\n    def __init__(self, c):\n        self.c = c",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "OpenTriple",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class OpenTriple: pass\nclass CloseDouble: pass\nclass CloseTriple: pass\nclass Equals:\n    def __str__(self):\n        return \"=\"\nclass Delimiter:\n    def __init__(self, c):\n        self.c = c\n    def __str__(self):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "CloseDouble",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class CloseDouble: pass\nclass CloseTriple: pass\nclass Equals:\n    def __str__(self):\n        return \"=\"\nclass Delimiter:\n    def __init__(self, c):\n        self.c = c\n    def __str__(self):\n        return self.c",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "CloseTriple",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class CloseTriple: pass\nclass Equals:\n    def __str__(self):\n        return \"=\"\nclass Delimiter:\n    def __init__(self, c):\n        self.c = c\n    def __str__(self):\n        return self.c\ndef Tokenise(s):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Equals",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class Equals:\n    def __str__(self):\n        return \"=\"\nclass Delimiter:\n    def __init__(self, c):\n        self.c = c\n    def __str__(self):\n        return self.c\ndef Tokenise(s):\n    s = str(s)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Delimiter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class Delimiter:\n    def __init__(self, c):\n        self.c = c\n    def __str__(self):\n        return self.c\ndef Tokenise(s):\n    s = str(s)\n    stack = []\n    last = 0\n    i = 0",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "WikiSection",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class WikiSection:\n    def __init__(self, heading, body):\n        self.heading = heading\n        self.body = body\n        #self.lines = re.split(\"\\n+\", body.strip())\n        #if len(self.lines) == 1 and len(self.lines[0]) == 0:\n        #    self.lines = []\n        self.children = []\n    def __str__(self):\n        return \"<%s:%i:%s>\" % (self.heading, len(self.body or \"\"), ','.join([str(x) for x in self.children]))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "WikiHandler",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class WikiHandler(xml.sax.ContentHandler):\n    def __init__(self):\n        self.element = None\n        self.page = None\n        self.text = \"\"\n        self.long = {}\n    def startElement(self, name, attrs):\n        #print \"start\", name, attrs\n        self.element = name\n    def endElement(self, name):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "TemplateHandler",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class TemplateHandler(WikiHandler):\n    def checkPage(self, page):\n        return page.startswith(\"Template:\")\n    def doPage(self, page, text):\n        Templates[page[page.find(':')+1:].lower()] = text\nclass WordHandler(WikiHandler):\n    def checkPage(self, page):\n        return ':' not in page\n    def doPage(self, page, text):\n        m = re.match(r\"#redirect\\s*\\[\\[(.*?)\\]\\]\", text, re.IGNORECASE)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "WordHandler",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "class WordHandler(WikiHandler):\n    def checkPage(self, page):\n        return ':' not in page\n    def doPage(self, page, text):\n        m = re.match(r\"#redirect\\s*\\[\\[(.*?)\\]\\]\", text, re.IGNORECASE)\n        if m:\n            out.write(\"  See <%s>\" % page)\n            return\n        doc = parse(page, text)\n        out.write(formatBrief(page, doc))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Tokenise",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def Tokenise(s):\n    s = str(s)\n    stack = []\n    last = 0\n    i = 0\n    while i < len(s):\n        if s[i] == '{' and i+1 < len(s) and s[i+1] == '{':\n            if i > last:\n                yield s[last:i]\n            if i+2 < len(s) and s[i+2] == '{':",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "processSub",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def processSub(templates, tokens, args):\n    t = next(tokens)\n    if not isinstance(t, str):\n        raise SyntaxError\n    name = t\n    t = next(tokens)\n    default = None\n    if isinstance(t, Delimiter) and t.c == '|':\n        default = \"\"\n        while True:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "processTemplateCall",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def processTemplateCall(templates, tokens, args):\n    template = tokens.next().strip().lower()\n    args = {}\n    a = 1\n    t = next(tokens)\n    while True:\n        if isinstance(t, Delimiter):\n            name = str(a)\n            arg = \"\"\n            while True:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "process",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def process(templates, s, args = {}):\n    s = re.compile(r\"<!--.*?-->\", re.DOTALL).sub(\"\", s)\n    s = re.compile(r\"<noinclude>.*?</noinclude>\", re.DOTALL).sub(\"\", s)\n    assert \"<onlyinclude>\" not in s\n    #s = re.sub(r\"(.*?)<onlyinclude>(.*?)</onlyinclude>(.*)\", r\"\\1\", s)\n    s = re.compile(r\"<includeonly>(.*?)</includeonly>\", re.DOTALL).sub(r\"\\1\", s)\n    r = \"\"\n    #print list(Tokenise(s))\n    tokens = Tokenise(s)\n    try:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def test():\n    templates = {\n        'lb': \"{{\",\n        'name-example': \"I am a template example, my first name is '''{{{firstName}}}''' and my last name is '''{{{lastName}}}'''. You can reference my page at [[{{{lastName}}}, {{{firstName}}}]].\",\n        't': \"start-{{{1|pqr}}}-end\",\n        't0': \"start-{{{1}}}-end\",\n        't1': \"start{{{1}}}end<noinclude>moo</noinclude>\",\n        't2a1': \"{{t2demo|a|{{{1}}}}}\",\n        't2a2': \"{{t2demo|a|2={{{1}}}}}\",\n        't2demo': \"start-{{{1}}}-middle-{{{2}}}-end\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def encode(s):\n    r = e(s)\n    assert r[1] == len(s)\n    return r[0]\ndef dowikilink(m):\n    a = m.group(1).split(\"|\")\n    if len(a) > 1:\n        link = a[1]\n    else:\n        link = a[0]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "dowikilink",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def dowikilink(m):\n    a = m.group(1).split(\"|\")\n    if len(a) > 1:\n        link = a[1]\n    else:\n        link = a[0]\n    if ':' in link:\n        link = \"\"\n    return link\nseentemplates = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "dotemplate",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def dotemplate(m):\n    aa = m.group(1).split(\"|\")\n    args = {}\n    n = 0\n    for a in aa:\n        am = re.match(r\"(.*?)(=(.*))?\", a)\n        if am:\n            args[am.group(1)] = am.group(3)\n        else:\n            n += 1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "doparserfunction",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def doparserfunction(m):\n    a = m.group(2).split(\"|\")\n    if m.group(1) == \"ifeq\":\n        if a[0] == a[1]:\n            return a[2]\n        elif len(a) >= 4:\n            return a[3]\n    return \"\"\ndef dewiki(body, indent = 0):\n    # process in this order:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "dewiki",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def dewiki(body, indent = 0):\n    # process in this order:\n    #   {{{ }}}\n    #   <> <>\n    #   [[ ]]\n    #   {{ }}\n    #   ''' '''\n    #   '' ''\n    #body = wikimediatemplate.process(Templates, body)\n    body = re.sub(r\"\\[\\[(.*?)\\]\\]\", dowikilink, body)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def parse(word, text):\n    headings = list(re.finditer(\"^(=+)\\s*(.*?)\\s*=+\\n\", text, re.MULTILINE))\n    #print [x.group(1) for x in headings]\n    doc = WikiSection(word, \"\")\n    stack = [doc]\n    for i, m in enumerate(headings):\n        depth = len(m.group(1))\n        if depth < len(stack):\n            stack = stack[:depth]\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "formatFull",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def formatFull(word, doc):\n    def f(depth, section):\n        if section.heading:\n            r = \"  \"*(depth-1) + section.heading + \"\\n\\n\"\n        else:\n            r = \"\"\n        if section.body:\n            r += dewiki(section.body, depth+1)+\"\\n\"\n        #r += \"\".join(\"  \"*depth + x + \"\\n\" for x in dewiki(section.body))\n        #if len(section.lines) > 0:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "formatNormal",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def formatNormal(word, doc):\n    def f(depth, posdepth, section):\n        r = \"\"\n        if depth == posdepth:\n            if not section.heading or section.heading.startswith(\"Etymology\"):\n                posdepth += 1\n            elif section.heading in Parts:\n                #p = Parts[section.heading]\n                #if p:\n                #    r += \"  \"*(depth-1) + word + \" (\" + p + \")\\n\\n\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "formatBrief",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "def formatBrief(word, doc):\n    def f(depth, posdepth, section):\n        if depth == posdepth:\n            h = section.heading\n            if not section.heading or section.heading.startswith(\"Etymology\"):\n                posdepth += 1\n            elif section.heading in Parts:\n                #h = Parts[section.heading]\n                #if h:\n                #    h = \"%s (%s)\" % (word, h)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Parts",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "Parts = {\n    # Standard POS headers\n    'noun': \"n.\",\n    'Noun': \"n.\",\n    'Noun 1': \"n.\",\n    'Noun 2': \"n.\",\n    'Verb': \"v.\",\n    'Adjective': \"adj.\",\n    'Adverb': \"adv.\",\n    'Pronoun': \"pron.\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "PartsUsed",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "PartsUsed = {}\nfor p in list(Parts.keys()):\n    PartsUsed[p] = 0\ndef encode(s):\n    r = e(s)\n    assert r[1] == len(s)\n    return r[0]\ndef dowikilink(m):\n    a = m.group(1).split(\"|\")\n    if len(a) > 1:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "seentemplates",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "seentemplates = {}\ndef dotemplate(m):\n    aa = m.group(1).split(\"|\")\n    args = {}\n    n = 0\n    for a in aa:\n        am = re.match(r\"(.*?)(=(.*))?\", a)\n        if am:\n            args[am.group(1)] = am.group(3)\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "fn",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "fn = sys.argv[1]\ninfo = \"\"\"   This file was converted from the original database on:\n             %s\n   The original data is available from:\n             http://en.wiktionary.org\n   The version from which this file was generated was:\n             %s\n  Wiktionary is available under the GNU Free Documentation License.\n\"\"\" % (time.ctime(), os.path.basename(fn))\nerrors = open(\"mkdict.err\", \"w\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "info",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "info = \"\"\"   This file was converted from the original database on:\n             %s\n   The original data is available from:\n             http://en.wiktionary.org\n   The version from which this file was generated was:\n             %s\n  Wiktionary is available under the GNU Free Documentation License.\n\"\"\" % (time.ctime(), os.path.basename(fn))\nerrors = open(\"mkdict.err\", \"w\")\nTemplates = {}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "errors",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "errors = open(\"mkdict.err\", \"w\")\nTemplates = {}\nf = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nxml.sax.parse(f, TemplateHandler())\nf.close()\nf = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nout = os.popen(\"dictfmt -p wiktionary-en --locale en_US.UTF-8 --columns 0 -u http://en.wiktionary.org\", \"w\")\nout.write(\"%%h English Wiktionary\\n%s\" % info)\nxml.sax.parse(f, WordHandler())\nf.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "Templates",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "Templates = {}\nf = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nxml.sax.parse(f, TemplateHandler())\nf.close()\nf = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nout = os.popen(\"dictfmt -p wiktionary-en --locale en_US.UTF-8 --columns 0 -u http://en.wiktionary.org\", \"w\")\nout.write(\"%%h English Wiktionary\\n%s\" % info)\nxml.sax.parse(f, WordHandler())\nf.close()\nout.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "f = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nxml.sax.parse(f, TemplateHandler())\nf.close()\nf = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nout = os.popen(\"dictfmt -p wiktionary-en --locale en_US.UTF-8 --columns 0 -u http://en.wiktionary.org\", \"w\")\nout.write(\"%%h English Wiktionary\\n%s\" % info)\nxml.sax.parse(f, WordHandler())\nf.close()\nout.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "f = os.popen(\"bunzip2 -c %s\" % fn, \"r\")\nout = os.popen(\"dictfmt -p wiktionary-en --locale en_US.UTF-8 --columns 0 -u http://en.wiktionary.org\", \"w\")\nout.write(\"%%h English Wiktionary\\n%s\" % info)\nxml.sax.parse(f, WordHandler())\nf.close()\nout.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "peekOfCode": "out = os.popen(\"dictfmt -p wiktionary-en --locale en_US.UTF-8 --columns 0 -u http://en.wiktionary.org\", \"w\")\nout.write(\"%%h English Wiktionary\\n%s\" % info)\nxml.sax.parse(f, WordHandler())\nf.close()\nout.close()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wiktionary.wiktionary2dict",
        "documentation": {}
    },
    {
        "label": "WordIndex",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "class WordIndex:\n   def __init__(self, lemma, category, ptrs, synsets, tagsense_count):\n      self.lemma = lemma\n      self.category = category\n      self.ptrs = ptrs\n      self.synsets = synsets\n      self.tagsense_count = tagsense_count\n   @classmethod\n   def build_from_line(cls, line_data, synset_map):\n      line_split = line_data.split()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "WordIndexDictFormatter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "class WordIndexDictFormatter(WordIndex):\n   category_map_rev = {\n      CAT_NOUN: 'n',\n      CAT_VERB: 'v',\n      CAT_ADJECTIVE: 'adj',\n      CAT_ADVERB: 'adv'\n   }\n   linesep = '\\n'\n   LINE_WIDTH_MAX = 68\n   prefix_fmtf_line_first = '%5s 1: '",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "Synset",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "class Synset:\n   def __init__(self, offset, ss_type, words, ptrs, gloss, frames=()):\n      self.offset = offset\n      self.type = ss_type\n      self.words = words\n      self.ptrs = ptrs\n      self.gloss = gloss\n      self.frames = frames\n      self.comments = []\n   @classmethod",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "WordnetDict",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "class WordnetDict:\n   db_info_fmt = '''This file was converted from the original database on:\n          %(conversion_datetime)s\nThe original data is available from:\n     %(wn_url)s\nThe original data was distributed with the notice shown below. No\nadditional restrictions are claimed.  Please redistribute this changed\nversion under the same conditions and restriction that apply to the\noriginal version.\\n\\n\n%(wn_license)s'''",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "CAT_ADJECTIVE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "CAT_ADJECTIVE = 0\nCAT_ADVERB = 1\nCAT_NOUN = 2\nCAT_VERB = 3\ncategory_map = {\n   'n': CAT_NOUN,\n   'v': CAT_VERB,\n   'a': CAT_ADJECTIVE,\n   's': CAT_ADJECTIVE,\n   'r': CAT_ADVERB",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "CAT_ADVERB",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "CAT_ADVERB = 1\nCAT_NOUN = 2\nCAT_VERB = 3\ncategory_map = {\n   'n': CAT_NOUN,\n   'v': CAT_VERB,\n   'a': CAT_ADJECTIVE,\n   's': CAT_ADJECTIVE,\n   'r': CAT_ADVERB\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "CAT_NOUN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "CAT_NOUN = 2\nCAT_VERB = 3\ncategory_map = {\n   'n': CAT_NOUN,\n   'v': CAT_VERB,\n   'a': CAT_ADJECTIVE,\n   's': CAT_ADJECTIVE,\n   'r': CAT_ADVERB\n}\nclass WordIndex:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "CAT_VERB",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "CAT_VERB = 3\ncategory_map = {\n   'n': CAT_NOUN,\n   'v': CAT_VERB,\n   'a': CAT_ADJECTIVE,\n   's': CAT_ADJECTIVE,\n   'r': CAT_ADVERB\n}\nclass WordIndex:\n   def __init__(self, lemma, category, ptrs, synsets, tagsense_count):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "category_map",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "peekOfCode": "category_map = {\n   'n': CAT_NOUN,\n   'v': CAT_VERB,\n   'a': CAT_ADJECTIVE,\n   's': CAT_ADJECTIVE,\n   'r': CAT_ADVERB\n}\nclass WordIndex:\n   def __init__(self, lemma, category, ptrs, synsets, tagsense_count):\n      self.lemma = lemma",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.dict.wordnet_structures",
        "documentation": {}
    },
    {
        "label": "error",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "peekOfCode": "def error(msg: str) -> None:\n    print(f\"  - {msg}\", file=sys.stderr)\n    return False\ndef check_requirement(req: str):\n    # https://packaging.pypa.io/en/stable/requirements.html\n    requirement = Requirement(req)\n    try:\n        version = importlib_metadata.distribution(requirement.name).version\n    except importlib_metadata.PackageNotFoundError:\n        return error(f\"{requirement.name}{requirement.specifier} not present\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "documentation": {}
    },
    {
        "label": "check_requirement",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "peekOfCode": "def check_requirement(req: str):\n    # https://packaging.pypa.io/en/stable/requirements.html\n    requirement = Requirement(req)\n    try:\n        version = importlib_metadata.distribution(requirement.name).version\n    except importlib_metadata.PackageNotFoundError:\n        return error(f\"{requirement.name}{requirement.specifier} not present\")\n    # https://packaging.pypa.io/en/stable/specifiers.html\n    if version not in requirement.specifier:\n        return error(",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "documentation": {}
    },
    {
        "label": "check_manifest",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "peekOfCode": "def check_manifest(manifest_file: str):\n    with open(manifest_file) as fd:\n        manifest = json.load(fd)\n    ok = True\n    derivation_domain = os.environ.get(\"domain\")\n    manifest_domain = manifest[\"domain\"]\n    if derivation_domain != manifest_domain:\n        ok = False\n        error(\n            f\"Derivation attribute domain ({derivation_domain}) must match manifest domain ({manifest_domain})\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.build-custom-component.check_manifest",
        "documentation": {}
    },
    {
        "label": "run_sync",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def run_sync(cmd: List[str]) -> None:\n    print(f\"$ {' '.join(cmd)}\")\n    process = subprocess.run(cmd)\n    if process.returncode != 0:\n        sys.exit(1)\ndef get_version() -> str:\n    with open(os.path.dirname(sys.argv[0]) + \"/default.nix\") as f:\n        # A version consists of digits, dots, and possibly a \"b\" (for beta)\n        if match := re.search('hassVersion = \"([\\\\d\\\\.b]+)\";', f.read()):\n            return match.group(1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "get_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def get_version() -> str:\n    with open(os.path.dirname(sys.argv[0]) + \"/default.nix\") as f:\n        # A version consists of digits, dots, and possibly a \"b\" (for beta)\n        if match := re.search('hassVersion = \"([\\\\d\\\\.b]+)\";', f.read()):\n            return match.group(1)\n        raise RuntimeError(\"hassVersion not in default.nix\")\ndef parse_components(version: str = \"master\"):\n    components = {}\n    components_with_tests = []\n    with tempfile.TemporaryDirectory() as tmp:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "parse_components",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def parse_components(version: str = \"master\"):\n    components = {}\n    components_with_tests = []\n    with tempfile.TemporaryDirectory() as tmp:\n        with urlopen(\n            f\"https://github.com/home-assistant/home-assistant/archive/{version}.tar.gz\"\n        ) as response:\n            tarfile.open(fileobj=BytesIO(response.read())).extractall(tmp)\n        # Use part of a script from the Home Assistant codebase\n        core_path = os.path.join(tmp, f\"core-{version}\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "get_reqs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def get_reqs(components: Dict[str, Dict[str, Any]], component: str, processed: Set[str]) -> Set[str]:\n    requirements = set(components[component].get(\"requirements\", []))\n    deps = components[component].get(\"dependencies\", [])\n    deps.extend(components[component].get(\"after_dependencies\", []))\n    processed.add(component)\n    for dependency in deps:\n        if dependency not in processed:\n            requirements.update(get_reqs(components, dependency, processed))\n    return requirements\ndef repository_root() -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "repository_root",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def repository_root() -> str:\n    return os.path.abspath(sys.argv[0] + \"/../../../..\")\n# For a package attribute and and an extra, check if the package exposes it via passthru.optional-dependencies\ndef has_extra(package: str, extra: str):\n    cmd = [\n        \"nix-instantiate\",\n        repository_root(),\n        \"-A\",\n        f\"{package}.optional-dependencies.{extra}\",\n    ]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "has_extra",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def has_extra(package: str, extra: str):\n    cmd = [\n        \"nix-instantiate\",\n        repository_root(),\n        \"-A\",\n        f\"{package}.optional-dependencies.{extra}\",\n    ]\n    try:\n        subprocess.run(\n            cmd,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "dump_packages",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def dump_packages() -> Dict[str, Dict[str, str]]:\n    # Store a JSON dump of Nixpkgs' python3Packages\n    output = subprocess.check_output(\n        [\n            \"nix-env\",\n            \"-f\",\n            repository_root(),\n            \"-qa\",\n            \"-A\",\n            PKG_SET,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "name_to_attr_path",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def name_to_attr_path(req: str, packages: Dict[str, Dict[str, str]]) -> Optional[str]:\n    if req in PKG_PREFERENCES:\n        return f\"{PKG_SET}.{PKG_PREFERENCES[req]}\"\n    attr_paths = []\n    names = [req]\n    # E.g. python-mpd2 is actually called python3.6-mpd2\n    # instead of python-3.6-python-mpd2 inside Nixpkgs\n    if req.startswith(\"python-\") or req.startswith(\"python_\"):\n        names.append(req[len(\"python-\") :])\n    for name in names:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "get_pkg_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def get_pkg_version(attr_path: str, packages: Dict[str, Dict[str, str]]) -> Optional[str]:\n    pkg = packages.get(attr_path, None)\n    if not pkg:\n        return None\n    return pkg[\"version\"]\ndef main() -> None:\n    packages = dump_packages()\n    version = get_version()\n    print(\"Generating component-packages.nix for version {}\".format(version))\n    components, components_with_tests = parse_components(version=version)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "def main() -> None:\n    packages = dump_packages()\n    version = get_version()\n    print(\"Generating component-packages.nix for version {}\".format(version))\n    components, components_with_tests = parse_components(version=version)\n    build_inputs = {}\n    outdated = {}\n    for component in sorted(components.keys()):\n        attr_paths = []\n        extra_attrs = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "COMPONENT_PREFIX",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "COMPONENT_PREFIX = \"homeassistant.components\"\nPKG_SET = \"home-assistant.python.pkgs\"\n# If some requirements are matched by multiple or no Python packages, the\n# following can be used to choose the correct one\nPKG_PREFERENCES = {\n    \"fiblary3\": \"fiblary3-fork\",  # https://github.com/home-assistant/core/issues/66466\n    \"HAP-python\": \"hap-python\",\n    \"ollama-hass\": \"ollama\",\n    \"slackclient\": \"slack-sdk\",\n    \"SQLAlchemy\": \"sqlalchemy\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "PKG_SET",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "PKG_SET = \"home-assistant.python.pkgs\"\n# If some requirements are matched by multiple or no Python packages, the\n# following can be used to choose the correct one\nPKG_PREFERENCES = {\n    \"fiblary3\": \"fiblary3-fork\",  # https://github.com/home-assistant/core/issues/66466\n    \"HAP-python\": \"hap-python\",\n    \"ollama-hass\": \"ollama\",\n    \"slackclient\": \"slack-sdk\",\n    \"SQLAlchemy\": \"sqlalchemy\",\n    \"tensorflow\": \"tensorflow\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "PKG_PREFERENCES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "PKG_PREFERENCES = {\n    \"fiblary3\": \"fiblary3-fork\",  # https://github.com/home-assistant/core/issues/66466\n    \"HAP-python\": \"hap-python\",\n    \"ollama-hass\": \"ollama\",\n    \"slackclient\": \"slack-sdk\",\n    \"SQLAlchemy\": \"sqlalchemy\",\n    \"tensorflow\": \"tensorflow\",\n    \"yt-dlp\": \"yt-dlp\",\n}\n# Some dependencies are loaded dynamically at runtime, and are not",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "EXTRA_COMPONENT_DEPS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "EXTRA_COMPONENT_DEPS = {\n    \"conversation\": [\n        \"intent\"\n    ],\n    \"default_config\": [\n        \"backup\",\n    ],\n}\n# Sometimes we have unstable versions for libraries that are not\n# well-maintained. This allows us to mark our weird version as newer",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "OUR_VERSION_IS_NEWER_THAN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "peekOfCode": "OUR_VERSION_IS_NEWER_THAN = {\n    \"blinkstick\": \"1.2.0\",\n    \"gps3\": \"0.33.3\",\n    \"pybluez\": \"0.22\",\n}\ndef run_sync(cmd: List[str]) -> None:\n    print(f\"$ {' '.join(cmd)}\")\n    process = subprocess.run(cmd)\n    if process.returncode != 0:\n        sys.exit(1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update-component-packages",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "peekOfCode": "class File:\n    def __init__(self, path: str):\n        self.path = os.path.join(ROOT, path)\n    def __enter__(self):\n        with open(self.path, \"r\") as handle:\n            self.text = handle.read()\n        return self\n    def get_exact_match(self, attr: str, value: str):\n        matches = re.findall(\n            rf'{re.escape(attr)}\\s+=\\s+\\\"?{re.escape(value)}\\\"?',",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "documentation": {}
    },
    {
        "label": "Nurl",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "peekOfCode": "class Nurl:\n    @classmethod\n    async def prefetch(cls, url: str, version: str, *extra_args: str) -> str:\n        cmd = [\n            \"nurl\",\n            \"--hash\",\n            url,\n            version,\n        ]\n        cmd.extend(extra_args)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "documentation": {}
    },
    {
        "label": "Nix",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "peekOfCode": "class Nix:\n    base_cmd: Final = [\n        \"nix\",\n        \"--show-trace\",\n        \"--extra-experimental-features\", \"nix-command\"\n    ]\n    @classmethod\n    async def _run(cls, args: List[str]) -> Optional[str]:\n        return await check_async(cls.base_cmd + args)\n    @classmethod",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "documentation": {}
    },
    {
        "label": "HomeAssistant",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "peekOfCode": "class HomeAssistant:\n    def __init__(self, session: ClientSession):\n        self._session = session\n    async def get_latest_core_version(\n        self,\n        owner: str = \"home-assistant\",\n        repo: str = \"core\"\n    ) -> str:\n        async with self._session.get(\n            f\"https://api.github.com/repos/{owner}/{repo}/releases/latest\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "documentation": {}
    },
    {
        "label": "run_sync",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "peekOfCode": "def run_sync(cmd: List[str]) -> None:\n    print(f\"$ {' '.join(cmd)}\")\n    process = run(cmd)\n    if process.returncode != 0:\n        sys.exit(1)\nasync def check_async(cmd: List[str]) -> str:\n    print(f\"$ {' '.join(cmd)}\")\n    process = await asyncio.create_subprocess_exec(\n        *cmd,\n        stdout=asyncio.subprocess.PIPE,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.home-assistant.update",
        "documentation": {}
    },
    {
        "label": "DiscourseVersion",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "class DiscourseVersion:\n    \"\"\"Represents a Discourse style version number and git tag.\n    This takes either a tag or version string as input and\n    extrapolates the other. Sorting is implemented to work as expected\n    in regard to A.B.C.betaD version numbers - 2.0.0.beta1 is\n    considered lower than 2.0.0.\n    \"\"\"\n    tag: str = \"\"\n    version: str = \"\"\n    split_version: Iterable[Union[None, int, str]] = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "DiscourseRepo",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "class DiscourseRepo:\n    version_regex = re.compile(r'^v\\d+\\.\\d+\\.\\d+(\\.beta\\d+)?$')\n    _latest_commit_sha = None\n    def __init__(self, owner: str = 'discourse', repo: str = 'discourse'):\n        self.owner = owner\n        self.repo = repo\n    @property\n    def versions(self) -> Iterable[str]:\n        r = requests.get(f'https://api.github.com/repos/{self.owner}/{self.repo}/git/refs/tags').json()\n        tags = [x['ref'].replace('refs/tags/', '') for x in r]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "def cli():\n    pass\n@cli.command()\n@click.argument('rev', default='latest')\n@click.option('--reverse/--no-reverse', default=False, help='Print diffs from REV to current.')\ndef print_diffs(rev, reverse):\n    \"\"\"Print out diffs for files used as templates for the NixOS module.\n    The current package version found in the nixpkgs worktree the\n    script is run from will be used to download the \"from\" file and\n    REV used to download the \"to\" file for the diff, unless the",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "print_diffs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "def print_diffs(rev, reverse):\n    \"\"\"Print out diffs for files used as templates for the NixOS module.\n    The current package version found in the nixpkgs worktree the\n    script is run from will be used to download the \"from\" file and\n    REV used to download the \"to\" file for the diff, unless the\n    '--reverse' flag is specified.\n    REV should be the git rev to find changes in ('vX.Y.Z') or\n    'latest'; defaults to 'latest'.\n    \"\"\"\n    if rev == 'latest':",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "update",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "def update(rev):\n    \"\"\"Update gem files and version.\n    REV: the git rev to update to ('vX.Y.Z[.betaA]') or\n    'latest'; defaults to 'latest'.\n    \"\"\"\n    repo = DiscourseRepo()\n    if rev == 'latest':\n        version = repo.versions[0]\n    else:\n        version = DiscourseVersion(rev)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "update_mail_receiver",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "def update_mail_receiver(rev):\n    \"\"\"Update discourse-mail-receiver.\n    REV: the git rev to update to ('vX.Y.Z') or 'latest'; defaults to\n    'latest'.\n    \"\"\"\n    repo = DiscourseRepo(repo=\"mail-receiver\")\n    if rev == 'latest':\n        version = repo.versions[0]\n    else:\n        version = DiscourseVersion(rev)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "update_plugins",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "def update_plugins():\n    \"\"\"Update plugins to their latest revision.\"\"\"\n    plugins = [\n        {'name': 'discourse-assign'},\n        {'name': 'discourse-bbcode-color'},\n        {'name': 'discourse-calendar'},\n        {'name': 'discourse-canned-replies'},\n        {'name': 'discourse-chat-integration'},\n        {'name': 'discourse-checklist'},\n        {'name': 'discourse-data-explorer'},",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@total_ordering\nclass DiscourseVersion:\n    \"\"\"Represents a Discourse style version number and git tag.\n    This takes either a tag or version string as input and\n    extrapolates the other. Sorting is implemented to work as expected\n    in regard to A.B.C.betaD version numbers - 2.0.0.beta1 is\n    considered lower than 2.0.0.\n    \"\"\"\n    tag: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.discourse.update",
        "documentation": {}
    },
    {
        "label": "Pin",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "class Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"\n    serverCargoHash: str = \"\"\n    uiHash: str = \"\"\n    uiYarnDepsHash: str = \"\"\n    filename: Optional[str] = None\n    def write(self) -> None:\n        if not self.filename:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "github_get",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def github_get(path: str) -> Dict:\n    \"\"\"Send a GET request to GitHub, optionally adding GITHUB_TOKEN auth header\"\"\"\n    url = f\"https://api.github.com/{path.lstrip('/')}\"\n    print(f\"Retrieving {url}\")\n    req = Request(url)\n    if \"GITHUB_TOKEN\" in os.environ:\n        req.add_header(\"authorization\", f\"Bearer {os.environ['GITHUB_TOKEN']}\")\n    with urlopen(req) as resp:\n        return json.loads(resp.read())\ndef get_latest_release(owner: str, repo: str) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "get_latest_release",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def get_latest_release(owner: str, repo: str) -> str:\n    return github_get(f\"/repos/{owner}/{repo}/releases/latest\")[\"tag_name\"]\ndef prefetch_github(owner: str, repo: str, rev: str) -> str:\n    \"\"\"Prefetch GitHub rev and return SRI hash\"\"\"\n    print(f\"Prefetching {owner}/{repo}({rev})\")\n    proc = subprocess.run(\n        [\"nix-prefetch-github\", owner, repo, \"--rev\", rev, \"--fetch-submodules\"],\n        check=True,\n        stdout=subprocess.PIPE,\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "prefetch_github",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def prefetch_github(owner: str, repo: str, rev: str) -> str:\n    \"\"\"Prefetch GitHub rev and return SRI hash\"\"\"\n    print(f\"Prefetching {owner}/{repo}({rev})\")\n    proc = subprocess.run(\n        [\"nix-prefetch-github\", owner, repo, \"--rev\", rev, \"--fetch-submodules\"],\n        check=True,\n        stdout=subprocess.PIPE,\n    )\n    return json.loads(proc.stdout)[\"hash\"]\ndef get_latest_tag(owner: str, repo: str, prerelease: bool = False) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "get_latest_tag",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def get_latest_tag(owner: str, repo: str, prerelease: bool = False) -> str:\n    \"\"\"Get the latest tag from a GitHub Repo\"\"\"\n    tags: List[str] = []\n    # As the GitHub API doesn't have any notion of \"latest\" for tags we need to\n    # collect all of them and sort so we can figure out the latest one.\n    i = 0\n    while i <= 100:  # Prevent infinite looping\n        i += 1\n        resp = github_get(f\"/repos/{owner}/{repo}/tags?page={i}\")\n        if not resp:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "get_fod_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def get_fod_hash(attr: str) -> str:\n    \"\"\"\n    Get fixed output hash for attribute.\n    This depends on a fixed output derivation with an empty hash.\n    \"\"\"\n    print(f\"Getting fixed output hash for {attr}\")\n    proc = subprocess.run([\"nix-build\", NIXPKGS, \"-A\", attr], stderr=subprocess.PIPE)\n    if proc.returncode != 1:\n        raise ValueError(\"Expected nix-build to fail\")\n    # Iterate list in reverse order so we get the \"got:\" line early",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "make_server_pin",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def make_server_pin(pin: Pin, attr: str) -> None:\n    pin.serverHash = prefetch_github(OWNER, SERVER_REPO, pin.serverVersion)\n    pin.write()\n    pin.serverCargoHash = get_fod_hash(attr)\n    pin.write()\ndef make_ui_pin(pin: Pin, package_json: str, attr: str) -> None:\n    # Save a copy of package.json\n    print(\"Getting package.json\")\n    with urlopen(\n        f\"https://raw.githubusercontent.com/{OWNER}/{UI_REPO}/{pin.uiVersion}/package.json\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "make_ui_pin",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "def make_ui_pin(pin: Pin, package_json: str, attr: str) -> None:\n    # Save a copy of package.json\n    print(\"Getting package.json\")\n    with urlopen(\n        f\"https://raw.githubusercontent.com/{OWNER}/{UI_REPO}/{pin.uiVersion}/package.json\"\n    ) as resp:\n        with open(os.path.join(SCRIPT_DIR, package_json), \"wb\") as fd:\n            fd.write(resp.read())\n    pin.uiHash = prefetch_github(OWNER, UI_REPO, pin.uiVersion)\n    pin.write()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "SCRIPT_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\nNIXPKGS = os.path.abspath(os.path.join(SCRIPT_DIR, \"../../../../\"))\nOWNER = \"LemmyNet\"\nUI_REPO = \"lemmy-ui\"\nSERVER_REPO = \"lemmy\"\n@dataclasses.dataclass\nclass Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "NIXPKGS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "NIXPKGS = os.path.abspath(os.path.join(SCRIPT_DIR, \"../../../../\"))\nOWNER = \"LemmyNet\"\nUI_REPO = \"lemmy-ui\"\nSERVER_REPO = \"lemmy\"\n@dataclasses.dataclass\nclass Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"\n    serverCargoHash: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "OWNER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "OWNER = \"LemmyNet\"\nUI_REPO = \"lemmy-ui\"\nSERVER_REPO = \"lemmy\"\n@dataclasses.dataclass\nclass Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"\n    serverCargoHash: str = \"\"\n    uiHash: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "UI_REPO",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "UI_REPO = \"lemmy-ui\"\nSERVER_REPO = \"lemmy\"\n@dataclasses.dataclass\nclass Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"\n    serverCargoHash: str = \"\"\n    uiHash: str = \"\"\n    uiYarnDepsHash: str = \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "SERVER_REPO",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "peekOfCode": "SERVER_REPO = \"lemmy\"\n@dataclasses.dataclass\nclass Pin:\n    serverVersion: str\n    uiVersion: str\n    serverHash: str = \"\"\n    serverCargoHash: str = \"\"\n    uiHash: str = \"\"\n    uiYarnDepsHash: str = \"\"\n    filename: Optional[str] = None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.web-apps.lemmy.update",
        "documentation": {}
    },
    {
        "label": "mirror",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "mirror = \"mirror://xorg/\"\nallversions = {}\nprint(\"Downloading latest version info...\")\n# xorg packages\nfor component in [\n    \"individual/app\",\n    \"individual/data\",\n    \"individual/data/xkeyboard-config\",\n    \"individual/doc\",\n    \"individual/driver\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "allversions",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "allversions = {}\nprint(\"Downloading latest version info...\")\n# xorg packages\nfor component in [\n    \"individual/app\",\n    \"individual/data\",\n    \"individual/data/xkeyboard-config\",\n    \"individual/doc\",\n    \"individual/driver\",\n    \"individual/font\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "lurl",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "lurl = \"https://invisible-mirror.net/archives/luit/\"\nr = requests.get(lurl)\nsoup = BeautifulSoup(r.text, \"html.parser\")\nfor a in soup.find_all(\"a\"):\n    href = a[\"href\"]\n    if not href.endswith(\".tgz\"):\n        continue\n    pname, rem = href.rsplit(\"-\", 1)\n    ver, _ = rem.rsplit(\".\", 1)\n    entry = allversions.setdefault(f\"{lurl}{pname}\", ([], {}))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "r",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "r = requests.get(lurl)\nsoup = BeautifulSoup(r.text, \"html.parser\")\nfor a in soup.find_all(\"a\"):\n    href = a[\"href\"]\n    if not href.endswith(\".tgz\"):\n        continue\n    pname, rem = href.rsplit(\"-\", 1)\n    ver, _ = rem.rsplit(\".\", 1)\n    entry = allversions.setdefault(f\"{lurl}{pname}\", ([], {}))\n    entry[0].append(version.parse(ver))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "soup",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "soup = BeautifulSoup(r.text, \"html.parser\")\nfor a in soup.find_all(\"a\"):\n    href = a[\"href\"]\n    if not href.endswith(\".tgz\"):\n        continue\n    pname, rem = href.rsplit(\"-\", 1)\n    ver, _ = rem.rsplit(\".\", 1)\n    entry = allversions.setdefault(f\"{lurl}{pname}\", ([], {}))\n    entry[0].append(version.parse(ver))\n    entry[1][ver] = f\"{lurl}{href}\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "updated_tarballs",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "updated_tarballs = []\nchanges = {}\nchanges_text = []\nfor line in lines_tarballs:\n    line = line.rstrip(\"\\n\")\n    if any(line.startswith(frag) for frag in [mirror, lurl]):\n        pname, rem = line.rsplit(\"-\", 1)\n        if line.startswith(mirror):\n            ver, _, _ = rem.rsplit(\".\", 2)\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "changes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "changes = {}\nchanges_text = []\nfor line in lines_tarballs:\n    line = line.rstrip(\"\\n\")\n    if any(line.startswith(frag) for frag in [mirror, lurl]):\n        pname, rem = line.rsplit(\"-\", 1)\n        if line.startswith(mirror):\n            ver, _, _ = rem.rsplit(\".\", 2)\n        else:\n            ver, _ = rem.rsplit(\".\", 1)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "changes_text",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "peekOfCode": "changes_text = []\nfor line in lines_tarballs:\n    line = line.rstrip(\"\\n\")\n    if any(line.startswith(frag) for frag in [mirror, lurl]):\n        pname, rem = line.rsplit(\"-\", 1)\n        if line.startswith(mirror):\n            ver, _, _ = rem.rsplit(\".\", 2)\n        else:\n            ver, _ = rem.rsplit(\".\", 1)\n        if pname not in allversions:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.servers.x11.xorg.update",
        "documentation": {}
    },
    {
        "label": "aa_setvar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "peekOfCode": "def aa_setvar(v):\n    def _aa_setvar():\n        transform._mark_set = False\n        global aa; aa = v\n    return _aa_setvar\ndef aa_ifvar():\n    def _aa_ifvar():\n        transform._mark_set = False\n        global aa\n        if aa: aa = False; return K(\"esc\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "documentation": {}
    },
    {
        "label": "aa_ifvar",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "peekOfCode": "def aa_ifvar():\n    def _aa_ifvar():\n        transform._mark_set = False\n        global aa\n        if aa: aa = False; return K(\"esc\")\n        return K(\"enter\")\n    return _aa_ifvar\ndef aa_flipmark():\n    def _aa_flipmark():\n        transform._mark_set = not transform._mark_set;",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "documentation": {}
    },
    {
        "label": "aa_flipmark",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "peekOfCode": "def aa_flipmark():\n    def _aa_flipmark():\n        transform._mark_set = not transform._mark_set;\n    return _aa_flipmark\ndefine_keymap(re.compile(\"Google-chrome|Chromium-browser|firefox\"), {\n    K(\"C-b\"): with_mark(K(\"left\")),\n    K(\"C-f\"): with_mark(K(\"right\")),\n    K(\"C-p\"): with_mark(K(\"up\")),\n    K(\"C-n\"): with_mark(K(\"down\")),\n    K(\"M-b\"): with_mark(K(\"C-left\")),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "documentation": {}
    },
    {
        "label": "aa",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "peekOfCode": "aa = False\ndef aa_setvar(v):\n    def _aa_setvar():\n        transform._mark_set = False\n        global aa; aa = v\n    return _aa_setvar\ndef aa_ifvar():\n    def _aa_ifvar():\n        transform._mark_set = False\n        global aa",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.X11.xkeysnail.browser-emacs-bindings",
        "documentation": {}
    },
    {
        "label": "nix_prefetch_sha256",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "def nix_prefetch_sha256(name):\n    return subprocess.run(['nix-prefetch-url', '--type', 'sha256', 'https://optifine.net/download?f=' + name], capture_output=True, text=True).stdout.strip()\n# fetch download page\nsess = requests.session()\npage = sess.get('https://optifine.net/downloads')\ntree = html.fromstring(page.content)\n# parse and extract main jar file names\nhref = tree.xpath('//tr[@class=\"downloadLine downloadLineMain\"]/td[@class=\"colMirror\"]/a/@href')\nexpr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "sess",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "sess = requests.session()\npage = sess.get('https://optifine.net/downloads')\ntree = html.fromstring(page.content)\n# parse and extract main jar file names\nhref = tree.xpath('//tr[@class=\"downloadLine downloadLineMain\"]/td[@class=\"colMirror\"]/a/@href')\nexpr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "page",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "page = sess.get('https://optifine.net/downloads')\ntree = html.fromstring(page.content)\n# parse and extract main jar file names\nhref = tree.xpath('//tr[@class=\"downloadLine downloadLineMain\"]/td[@class=\"colMirror\"]/a/@href')\nexpr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "tree",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "tree = html.fromstring(page.content)\n# parse and extract main jar file names\nhref = tree.xpath('//tr[@class=\"downloadLine downloadLineMain\"]/td[@class=\"colMirror\"]/a/@href')\nexpr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')\n    version = r.group(2) + r.group(3)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "href",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "href = tree.xpath('//tr[@class=\"downloadLine downloadLineMain\"]/td[@class=\"colMirror\"]/a/@href')\nexpr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')\n    version = r.group(2) + r.group(3)\n    catalogue[index] = {\n        \"version\": version,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "expr",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "expr = re.compile('(OptiFine_)([0-9.]*)(.*)\\.jar')\nresult = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')\n    version = r.group(2) + r.group(3)\n    catalogue[index] = {\n        \"version\": version,\n        \"sha256\": nix_prefetch_sha256(r.group(0))",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "result = [ expr.search(x) for x in href ]\n# format name, version and hash for each file\ncatalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')\n    version = r.group(2) + r.group(3)\n    catalogue[index] = {\n        \"version\": version,\n        \"sha256\": nix_prefetch_sha256(r.group(0))\n    }",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "catalogue",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "catalogue = {}\nfor i, r in enumerate(result):\n    index = r.group(1).lower() + r.group(2).replace('.', '_')\n    version = r.group(2) + r.group(3)\n    catalogue[index] = {\n        \"version\": version,\n        \"sha256\": nix_prefetch_sha256(r.group(0))\n    }\n# latest version should be the first entry\nif len(catalogue) > 0:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "d = os.path.dirname(os.path.abspath(__file__))\nwith open(os.path.join(d, 'versions.json'), 'r') as f:\n    prev = json.load(f)\n# `maintainers/scripts/update.py` will extract stdout to write commit message\n# embed the commit message in json and print it\nchanges = [ { 'commitMessage': 'optifinePackages: update versions\\n\\n' } ]\n# build a longest common subsequence, natural sorted by keys\nfor key, value in sorted({**prev, **catalogue}.items(), key=lambda item: [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', item[0])]):\n    if key not in prev:\n        changes[0]['commitMessage'] += 'optifinePackages.{}: init at {}\\n'.format(key, value['version'])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "changes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "peekOfCode": "changes = [ { 'commitMessage': 'optifinePackages: update versions\\n\\n' } ]\n# build a longest common subsequence, natural sorted by keys\nfor key, value in sorted({**prev, **catalogue}.items(), key=lambda item: [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', item[0])]):\n    if key not in prev:\n        changes[0]['commitMessage'] += 'optifinePackages.{}: init at {}\\n'.format(key, value['version'])\n    elif value['version'] != prev[key]['version']:\n        changes[0]['commitMessage'] += 'optifinePackages.{}: {} -> {}\\n'.format(key, prev[key]['version'], value['version'])\n# print the changes in stdout\nprint(json.dumps(changes))\n# write catalogue to file",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.games.minecraft.optifine.update",
        "documentation": {}
    },
    {
        "label": "get_github_hash",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "peekOfCode": "def get_github_hash(owner, repo, revision):\n    result = subprocess.run(\n        [\"nix-prefetch-github\", owner, repo, \"--json\", \"--rev\", revision],\n        check=True,\n        capture_output=True,\n        text=True,\n    )\n    j = json.loads(result.stdout)\n    # Remove False values\n    return {k: v for k, v in j.items() if v}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "peekOfCode": "def main():\n    pkgs = fetch_sources.PACKAGES\n    pkgs.sort(key = lambda pkg: pkg.baseDir)\n    existing_sources = {}\n    # Fetch hashes from existing sources file\n    with open(\"sources.nix\") as f:\n        existing_file = f.read()\n    source_re = re.compile(\"(?P<name>[^ ]+) = fetchFromGitHub[^\\n]*\\n\"\n        \"[^\\n]+\\n\" # owner\n        \"[^\\n]+\\n\" # repo",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.graphics.vulkan-cts.vk-cts-sources",
        "documentation": {}
    },
    {
        "label": "get_latest_tag",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "peekOfCode": "def get_latest_tag(repo, owner=OWNER):\n    r = requests.get('https://api.github.com/repos/{}/{}/tags'.format(owner,repo))\n    return r.json()[0].get(\"name\")\ndef main():\n    for repo in REPOS:\n        rev = get_latest_tag(repo)\n        if repo == \"fcitx5-qt\":\n            subprocess.run([\"nix-update\", \"--commit\", \"--version\", rev, \"libsForQt5.{}\".format(repo)])\n        else:\n            subprocess.run([\"nix-update\", \"--commit\", \"--version\", rev, repo])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "peekOfCode": "def main():\n    for repo in REPOS:\n        rev = get_latest_tag(repo)\n        if repo == \"fcitx5-qt\":\n            subprocess.run([\"nix-update\", \"--commit\", \"--version\", rev, \"libsForQt5.{}\".format(repo)])\n        else:\n            subprocess.run([\"nix-update\", \"--commit\", \"--version\", rev, repo])\nif __name__ == \"__main__\":\n    main ()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "documentation": {}
    },
    {
        "label": "REPOS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "peekOfCode": "REPOS = [\n        \"libime\",\n        \"xcb-imdkit\",\n        \"fcitx5\",\n        \"fcitx5-anthy\",\n        \"fcitx5-chewing\",\n        \"fcitx5-chinese-addons\",\n        \"fcitx5-configtool\",\n        \"fcitx5-gtk\",\n        \"fcitx5-hangul\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "documentation": {}
    },
    {
        "label": "OWNER",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "peekOfCode": "OWNER = \"fcitx\"\ndef get_latest_tag(repo, owner=OWNER):\n    r = requests.get('https://api.github.com/repos/{}/{}/tags'.format(owner,repo))\n    return r.json()[0].get(\"name\")\ndef main():\n    for repo in REPOS:\n        rev = get_latest_tag(repo)\n        if repo == \"fcitx5-qt\":\n            subprocess.run([\"nix-update\", \"--commit\", \"--version\", rev, \"libsForQt5.{}\".format(repo)])\n        else:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.inputmethods.fcitx5.update",
        "documentation": {}
    },
    {
        "label": "process_repo",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "def process_repo(path: str, official: bool):\n    global PLUGINS\n    with open(path, 'rt') as f:\n        data = yaml.load(f)\n    name, repourl, license, desc = data['name'], data['repo'], data['license'], data['description']\n    origurl = repourl\n    if '/' in name or ' ' in name:\n        name = os.path.split(path)[-1].removesuffix('.yaml')\n    name = name.replace('_', '-').lower()\n    if name in PLUGINS.keys():",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "next_incomp",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "def next_incomp(ver_s: str) -> str:\n    ver = ver_s.split('.')\n    zero = False\n    for i in range(len(ver)):\n        try:\n            seg = int(ver[i])\n        except ValueError:\n            if zero:\n                ver = ver[:i]\n                break",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "poetry_to_pep",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "def poetry_to_pep(ver_req: str) -> List[str]:\n    if '*' in ver_req:\n        raise NotImplementedError('Wildcard poetry versions not implemented!')\n    if ver_req.startswith('^'):\n        return ['>=' + ver_req[1:], '<' + next_incomp(ver_req[1:])]\n    if ver_req.startswith('~'):\n        return ['~=' + ver_req[1:]]\n    return [ver_req]\ndef main():\n    cache_path = os.path.join(TMP, 'maubot-plugins')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "def main():\n    cache_path = os.path.join(TMP, 'maubot-plugins')\n    if not os.path.exists(cache_path):\n        os.makedirs(cache_path)\n        git.Repo.clone_from('https://github.com/maubot/plugins.maubot.xyz', os.path.join(cache_path, '_repo'))\n    else:\n        pass\n    repodir = os.path.join(cache_path, '_repo')\n    for suffix, official in (('official', True), ('thirdparty', False)):\n        directory = os.path.join(repodir, 'data', 'plugins', suffix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "HOSTNAMES",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "HOSTNAMES = {\n    'git.skeg1.se': 'gitlab',\n    'edugit.org': 'gitlab',\n    'codeberg.org': 'gitea',\n}\nPLUGINS: Dict[str, dict] = {}\nyaml = ruamel.yaml.YAML(typ='safe')\nTMP = os.environ.get('TEMPDIR', '/tmp')\ndef process_repo(path: str, official: bool):\n    global PLUGINS",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "yaml = ruamel.yaml.YAML(typ='safe')\nTMP = os.environ.get('TEMPDIR', '/tmp')\ndef process_repo(path: str, official: bool):\n    global PLUGINS\n    with open(path, 'rt') as f:\n        data = yaml.load(f)\n    name, repourl, license, desc = data['name'], data['repo'], data['license'], data['description']\n    origurl = repourl\n    if '/' in name or ' ' in name:\n        name = os.path.split(path)[-1].removesuffix('.yaml')",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "TMP",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "peekOfCode": "TMP = os.environ.get('TEMPDIR', '/tmp')\ndef process_repo(path: str, official: bool):\n    global PLUGINS\n    with open(path, 'rt') as f:\n        data = yaml.load(f)\n    name, repourl, license, desc = data['name'], data['repo'], data['license'], data['description']\n    origurl = repourl\n    if '/' in name or ' ' in name:\n        name = os.path.split(path)[-1].removesuffix('.yaml')\n    name = name.replace('_', '-').lower()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.networking.maubot.plugins.update",
        "documentation": {}
    },
    {
        "label": "List",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "peekOfCode": "class List:\n    head: str\n@dataclass()\nclass Par:\n    sep: str\n    block_delim: str\n    continuing: bool = False\nclass AsciiDocRenderer(Renderer):\n    __output__ = \"asciidoc\"\n    _parstack: list[Par]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "documentation": {}
    },
    {
        "label": "Par",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "peekOfCode": "class Par:\n    sep: str\n    block_delim: str\n    continuing: bool = False\nclass AsciiDocRenderer(Renderer):\n    __output__ = \"asciidoc\"\n    _parstack: list[Par]\n    _list_stack: list[List]\n    _attrspans: list[str]\n    def __init__(self, manpage_urls: Mapping[str, str]):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "documentation": {}
    },
    {
        "label": "AsciiDocRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "peekOfCode": "class AsciiDocRenderer(Renderer):\n    __output__ = \"asciidoc\"\n    _parstack: list[Par]\n    _list_stack: list[List]\n    _attrspans: list[str]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        super().__init__(manpage_urls)\n        self._parstack = [ Par(\"\\n\\n\", \"====\") ]\n        self._list_stack = []\n        self._attrspans = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "documentation": {}
    },
    {
        "label": "asciidoc_escape",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "peekOfCode": "def asciidoc_escape(s: str) -> str:\n    s = s.translate(_asciidoc_escapes)\n    # :: is deflist item, ;; is has a replacement but no idea why\n    return s.replace(\"::\", \"{two-colons}\").replace(\";;\", \"{two-semicolons}\")\n@dataclass(kw_only=True)\nclass List:\n    head: str\n@dataclass()\nclass Par:\n    sep: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "documentation": {}
    },
    {
        "label": "_asciidoc_escapes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "peekOfCode": "_asciidoc_escapes = {\n    # escape all dots, just in case one is pasted at SOL\n    ord('.'): \"{zwsp}.\",\n    # may be replaced by typographic variants\n    ord(\"'\"): \"{apos}\",\n    ord('\"'): \"{quot}\",\n    # passthrough character\n    ord('+'): \"{plus}\",\n    # table marker\n    ord('|'): \"{vbar}\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.asciidoc",
        "documentation": {}
    },
    {
        "label": "List",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "peekOfCode": "class List:\n    next_idx: Optional[int] = None\n    compact: bool\n    first_item_seen: bool = False\n@dataclass\nclass Par:\n    indent: str\n    continuing: bool = False\nclass CommonMarkRenderer(Renderer):\n    __output__ = \"commonmark\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "documentation": {}
    },
    {
        "label": "Par",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "peekOfCode": "class Par:\n    indent: str\n    continuing: bool = False\nclass CommonMarkRenderer(Renderer):\n    __output__ = \"commonmark\"\n    _parstack: list[Par]\n    _link_stack: list[str]\n    _list_stack: list[List]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        super().__init__(manpage_urls)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "documentation": {}
    },
    {
        "label": "CommonMarkRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "peekOfCode": "class CommonMarkRenderer(Renderer):\n    __output__ = \"commonmark\"\n    _parstack: list[Par]\n    _link_stack: list[str]\n    _list_stack: list[List]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        super().__init__(manpage_urls)\n        self._parstack = [ Par(\"\") ]\n        self._link_stack = []\n        self._list_stack = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.commonmark",
        "documentation": {}
    },
    {
        "label": "UnresolvedXrefError",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "peekOfCode": "class UnresolvedXrefError(Exception):\n    pass\nclass Heading(NamedTuple):\n    container_tag: str\n    level: int\n    html_tag: str\n    # special handling for part content: whether partinfo div was already closed from\n    # elsewhere or still needs closing.\n    partintro_closed: bool\n    # tocs are generated when the heading opens, but have to be emitted into the file",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "documentation": {}
    },
    {
        "label": "Heading",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "peekOfCode": "class Heading(NamedTuple):\n    container_tag: str\n    level: int\n    html_tag: str\n    # special handling for part content: whether partinfo div was already closed from\n    # elsewhere or still needs closing.\n    partintro_closed: bool\n    # tocs are generated when the heading opens, but have to be emitted into the file\n    # after the heading titlepage (and maybe partinfo) has been closed.\n    toc_fragment: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "documentation": {}
    },
    {
        "label": "HTMLRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "peekOfCode": "class HTMLRenderer(Renderer):\n    _xref_targets: Mapping[str, XrefTarget]\n    _headings: list[Heading]\n    _attrspans: list[str]\n    _hlevel_offset: int = 0\n    _bullet_list_nesting: int = 0\n    _ordered_list_nesting: int = 0\n    def __init__(self, manpage_urls: Mapping[str, str], xref_targets: Mapping[str, XrefTarget]):\n        super().__init__(manpage_urls)\n        self._headings = []",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "documentation": {}
    },
    {
        "label": "_bullet_list_styles",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "peekOfCode": "_bullet_list_styles = [ 'disc', 'circle', 'square' ]\n_ordered_list_styles = [ '1', 'a', 'i', 'A', 'I' ]\nclass HTMLRenderer(Renderer):\n    _xref_targets: Mapping[str, XrefTarget]\n    _headings: list[Heading]\n    _attrspans: list[str]\n    _hlevel_offset: int = 0\n    _bullet_list_nesting: int = 0\n    _ordered_list_nesting: int = 0\n    def __init__(self, manpage_urls: Mapping[str, str], xref_targets: Mapping[str, XrefTarget]):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "documentation": {}
    },
    {
        "label": "_ordered_list_styles",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "peekOfCode": "_ordered_list_styles = [ '1', 'a', 'i', 'A', 'I' ]\nclass HTMLRenderer(Renderer):\n    _xref_targets: Mapping[str, XrefTarget]\n    _headings: list[Heading]\n    _attrspans: list[str]\n    _hlevel_offset: int = 0\n    _bullet_list_nesting: int = 0\n    _ordered_list_nesting: int = 0\n    def __init__(self, manpage_urls: Mapping[str, str], xref_targets: Mapping[str, XrefTarget]):\n        super().__init__(manpage_urls)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.html",
        "documentation": {}
    },
    {
        "label": "List",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "class List:\n    width: int\n    next_idx: Optional[int] = None\n    compact: bool\n    first_item_seen: bool = False\n# this renderer assumed that it produces a set of lines as output, and that those lines will\n# be pasted as-is into a larger output. no prefixing or suffixing is allowed for correctness.\n#\n# NOTE that we output exclusively physical markup. this is because we have to use the older\n# mandoc(7) format instead of the newer mdoc(7) format due to limitations in groff: while",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "ManpageRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "class ManpageRenderer(Renderer):\n    # whether to emit mdoc .Ql equivalents for inline code or just the contents. this is\n    # mainly used by the options manpage converter to not emit extra quotes in defaults\n    # and examples where it's already clear from context that the following text is code.\n    inline_code_is_quoted: bool = True\n    link_footnotes: Optional[list[str]] = None\n    _href_targets: dict[str, str]\n    _link_stack: list[str]\n    _do_parbreak_stack: list[bool]\n    _list_stack: list[List]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "man_escape",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "def man_escape(s: str) -> str:\n    s = s.translate(_roff_escapes)\n    return _roff_unicode.sub(lambda m: f\"\\\\[u{ord(m[0]):04X}]\", s)\n# remove leading and trailing spaces from links and condense multiple consecutive spaces\n# into a single space for presentation parity with html. this is currently easiest with\n# regex postprocessing and some marker characters. since we don't want to drop spaces\n# from code blocks we will have to specially protect *inline* code (luckily not block code)\n# so normalization can turn the spaces inside it into regular spaces again.\n_normalize_space_re = re.compile(r'''\\u0000 < *| *>\\u0000 |(?<= ) +''')\ndef _normalize_space(s: str) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "_roff_unicode",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "_roff_unicode = re.compile(r'''[^\\n !#$%&()*+,\\-./0-9:;<=>?@A-Z[\\\\\\]_a-z{|}]''', re.ASCII)\n_roff_escapes = {\n    ord('\"'): \"\\\\(dq\",\n    ord(\"'\"): \"\\\\(aq\",\n    ord('-'): \"\\\\-\",\n    ord('.'): \"\\\\&.\",\n    ord('\\\\'): \"\\\\e\",\n    ord('^'): \"\\\\(ha\",\n    ord('`'): \"\\\\(ga\",\n    ord('~'): \"\\\\(ti\",",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "_roff_escapes",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "_roff_escapes = {\n    ord('\"'): \"\\\\(dq\",\n    ord(\"'\"): \"\\\\(aq\",\n    ord('-'): \"\\\\-\",\n    ord('.'): \"\\\\&.\",\n    ord('\\\\'): \"\\\\e\",\n    ord('^'): \"\\\\(ha\",\n    ord('`'): \"\\\\(ga\",\n    ord('~'): \"\\\\(ti\",\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "_normalize_space_re",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "peekOfCode": "_normalize_space_re = re.compile(r'''\\u0000 < *| *>\\u0000 |(?<= ) +''')\ndef _normalize_space(s: str) -> str:\n    return _normalize_space_re.sub(\"\", s).replace(\"\\0p\", \" \")\ndef _protect_spaces(s: str) -> str:\n    return s.replace(\" \", \"\\0p\")\n@dataclass(kw_only=True)\nclass List:\n    width: int\n    next_idx: Optional[int] = None\n    compact: bool",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manpage",
        "documentation": {}
    },
    {
        "label": "BaseConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "class BaseConverter(Converter[md.TR], Generic[md.TR]):\n    # per-converter configuration for ns:arg=value arguments to include blocks, following\n    # the include type. html converters need something like this to support chunking, or\n    # another external method like the chunktocs docbook uses (but block options seem like\n    # a much nicer of doing this).\n    INCLUDE_ARGS_NS: ClassVar[str]\n    INCLUDE_FRAGMENT_ALLOWED_ARGS: ClassVar[set[str]] = set()\n    INCLUDE_OPTIONS_ALLOWED_ARGS: ClassVar[set[str]] = set()\n    _base_paths: list[Path]\n    _current_type: list[TocEntryType]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "RendererMixin",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "class RendererMixin(Renderer):\n    _toplevel_tag: str\n    _revision: str\n    def __init__(self, toplevel_tag: str, revision: str, *args: Any, **kwargs: Any):\n        super().__init__(*args, **kwargs)\n        self._toplevel_tag = toplevel_tag\n        self._revision = revision\n        self.rules |= {\n            'included_sections': lambda *args: self._included_thing(\"section\", *args),\n            'included_chapters': lambda *args: self._included_thing(\"chapter\", *args),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "HTMLParameters",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "class HTMLParameters(NamedTuple):\n    generator: str\n    stylesheets: Sequence[str]\n    scripts: Sequence[str]\n    # number of levels in the rendered table of contents. tables are prepended to\n    # the content they apply to (entire document / document chunk / top-level section\n    # of a chapter), setting a depth of 0 omits the respective table.\n    toc_depth: int\n    chunk_toc_depth: int\n    section_toc_depth: int",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "ManualHTMLRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "class ManualHTMLRenderer(RendererMixin, HTMLRenderer):\n    _base_path: Path\n    _in_dir: Path\n    _html_params: HTMLParameters\n    def __init__(self, toplevel_tag: str, revision: str, html_params: HTMLParameters,\n                 manpage_urls: Mapping[str, str], xref_targets: dict[str, XrefTarget],\n                 in_dir: Path, base_path: Path):\n        super().__init__(toplevel_tag, revision, manpage_urls, xref_targets)\n        self._in_dir = in_dir\n        self._base_path = base_path.absolute()",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "HTMLConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "class HTMLConverter(BaseConverter[ManualHTMLRenderer]):\n    INCLUDE_ARGS_NS = \"html\"\n    INCLUDE_FRAGMENT_ALLOWED_ARGS = { 'into-file' }\n    _revision: str\n    _html_params: HTMLParameters\n    _manpage_urls: Mapping[str, str]\n    _xref_targets: dict[str, XrefTarget]\n    _redirection_targets: set[str]\n    _appendix_count: int = 0\n    def _next_appendix_id(self) -> str:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "build_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "def build_cli(p: argparse.ArgumentParser) -> None:\n    formats = p.add_subparsers(dest='format', required=True)\n    _build_cli_html(formats.add_parser('html'))\ndef run_cli(args: argparse.Namespace) -> None:\n    if args.format == 'html':\n        _run_cli_html(args)\n    else:\n        raise RuntimeError('format not hooked up', args)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "run_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "peekOfCode": "def run_cli(args: argparse.Namespace) -> None:\n    if args.format == 'html':\n        _run_cli_html(args)\n    else:\n        raise RuntimeError('format not hooked up', args)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual",
        "documentation": {}
    },
    {
        "label": "XrefTarget",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "class XrefTarget:\n    id: str\n    \"\"\"link label for `[](#local-references)`\"\"\"\n    title_html: str\n    \"\"\"toc label\"\"\"\n    toc_html: str | None\n    \"\"\"text for `<title>` tags and `title=\"...\"` attributes\"\"\"\n    title: str | None\n    \"\"\"path to file that contains the anchor\"\"\"\n    path: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "TocEntry",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "class TocEntry(Freezeable):\n    kind: TocEntryType\n    target: XrefTarget\n    parent: TocEntry | None = None\n    prev: TocEntry | None = None\n    next: TocEntry | None = None\n    children: list[TocEntry] = dc.field(default_factory=list)\n    starts_new_chunk: bool = False\n    examples: list[TocEntry] = dc.field(default_factory=list)\n    figures: list[TocEntry] = dc.field(default_factory=list)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "is_include",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "def is_include(token: Token) -> bool:\n    return token.type == \"fence\" and token.info.startswith(\"{=include=} \")\n# toplevel file must contain only the title headings and includes, anything else\n# would cause strange rendering.\ndef _check_book_structure(tokens: Sequence[Token]) -> None:\n    for token in tokens[6:]:\n        if not is_include(token):\n            assert token.map\n            raise RuntimeError(f\"unexpected content in line {token.map[0] + 1}, \"\n                               \"expected structural include\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "check_structure",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "def check_structure(kind: TocEntryType, tokens: Sequence[Token]) -> None:\n    wanted = { 'h1': 'title' }\n    wanted |= { 'h2': 'subtitle' } if kind == 'book' else {}\n    for (i, (tag, role)) in enumerate(wanted.items()):\n        if len(tokens) < 3 * (i + 1):\n            raise RuntimeError(f\"missing {role} ({tag}) heading\")\n        token = tokens[3 * i]\n        if token.type != 'heading_open' or token.tag != tag:\n            assert token.map\n            raise RuntimeError(f\"expected {role} ({tag}) heading in line {token.map[0] + 1}\", token)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "make_xml_id",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "def make_xml_id(s: str) -> str:\n    return s.translate(_xml_id_translate_table)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "FragmentType",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "FragmentType = Literal['preface', 'part', 'chapter', 'section', 'appendix']\n# in the TOC all fragments are allowed, plus the all-encompassing book.\nTocEntryType = Literal['book', 'preface', 'part', 'chapter', 'section', 'appendix', 'example', 'figure']\ndef is_include(token: Token) -> bool:\n    return token.type == \"fence\" and token.info.startswith(\"{=include=} \")\n# toplevel file must contain only the title headings and includes, anything else\n# would cause strange rendering.\ndef _check_book_structure(tokens: Sequence[Token]) -> None:\n    for token in tokens[6:]:\n        if not is_include(token):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "TocEntryType",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "TocEntryType = Literal['book', 'preface', 'part', 'chapter', 'section', 'appendix', 'example', 'figure']\ndef is_include(token: Token) -> bool:\n    return token.type == \"fence\" and token.info.startswith(\"{=include=} \")\n# toplevel file must contain only the title headings and includes, anything else\n# would cause strange rendering.\ndef _check_book_structure(tokens: Sequence[Token]) -> None:\n    for token in tokens[6:]:\n        if not is_include(token):\n            assert token.map\n            raise RuntimeError(f\"unexpected content in line {token.map[0] + 1}, \"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "_xml_id_translate_table",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "peekOfCode": "_xml_id_translate_table = {\n    ord('*'): ord('_'),\n    ord('<'): ord('_'),\n    ord(' '): ord('_'),\n    ord('>'): ord('_'),\n    ord('['): ord('_'),\n    ord(']'): ord('_'),\n    ord(':'): ord('_'),\n    ord('\"'): ord('_'),\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.manual_structure",
        "documentation": {}
    },
    {
        "label": "Renderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "class Renderer:\n    _admonitions: dict[AdmonitionKind, tuple[RenderFn, RenderFn]]\n    _admonition_stack: list[AdmonitionKind]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        self._manpage_urls = manpage_urls\n        self.rules = {\n            'text': self.text,\n            'paragraph_open': self.paragraph_open,\n            'paragraph_close': self.paragraph_close,\n            'hardbreak': self.hardbreak,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "class Converter(ABC, Generic[TR]):\n    # we explicitly disable markdown-it rendering support and use our own entirely.\n    # rendering is well separated from parsing and our renderers carry much more state than\n    # markdown-it easily acknowledges as 'good' (unless we used the untyped env args to\n    # shuttle that state around, which is very fragile)\n    class ForbiddenRenderer(markdown_it.renderer.RendererProtocol):\n        __output__ = \"none\"\n        def __init__(self, parser: Optional[markdown_it.MarkdownIt]):\n            pass\n        def render(self, tokens: Sequence[Token], options: OptionsDict,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "md_escape",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "def md_escape(s: str) -> str:\n    return s.translate(_md_escape_table)\ndef md_make_code(code: str, info: str = \"\", multiline: Optional[bool] = None) -> str:\n    # for multi-line code blocks we only have to count ` runs at the beginning\n    # of a line, but this is much easier.\n    multiline = multiline or info != \"\" or '\\n' in code\n    longest, current = (0, 0)\n    for c in code:\n        current = current + 1 if c == '`' else 0\n        longest = max(current, longest)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "md_make_code",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "def md_make_code(code: str, info: str = \"\", multiline: Optional[bool] = None) -> str:\n    # for multi-line code blocks we only have to count ` runs at the beginning\n    # of a line, but this is much easier.\n    multiline = multiline or info != \"\" or '\\n' in code\n    longest, current = (0, 0)\n    for c in code:\n        current = current + 1 if c == '`' else 0\n        longest = max(current, longest)\n    # inline literals need a space to separate ticks from content, code blocks\n    # need newlines. inline literals need one extra tick, code blocks need three.",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "_md_escape_table",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "_md_escape_table = {\n    ord('*'): '\\\\*',\n    ord('<'): '\\\\<',\n    ord('['): '\\\\[',\n    ord('`'): '\\\\`',\n    ord('.'): '\\\\.',\n    ord('#'): '\\\\#',\n    ord('&'): '\\\\&',\n    ord('\\\\'): '\\\\\\\\',\n}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "AttrBlockKind",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "AttrBlockKind = Literal['admonition', 'example', 'figure']\nAdmonitionKind = Literal[\"note\", \"caution\", \"tip\", \"important\", \"warning\"]\nclass Renderer:\n    _admonitions: dict[AdmonitionKind, tuple[RenderFn, RenderFn]]\n    _admonition_stack: list[AdmonitionKind]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        self._manpage_urls = manpage_urls\n        self.rules = {\n            'text': self.text,\n            'paragraph_open': self.paragraph_open,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "AdmonitionKind",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "AdmonitionKind = Literal[\"note\", \"caution\", \"tip\", \"important\", \"warning\"]\nclass Renderer:\n    _admonitions: dict[AdmonitionKind, tuple[RenderFn, RenderFn]]\n    _admonition_stack: list[AdmonitionKind]\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        self._manpage_urls = manpage_urls\n        self.rules = {\n            'text': self.text,\n            'paragraph_open': self.paragraph_open,\n            'paragraph_close': self.paragraph_close,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "_ATTR_SPAN_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "_ATTR_SPAN_PATTERN = re.compile(r\"\\{([^}]*)\\}\")\n# this one is for blocks with attrs. we want to use it with fullmatch() to deconstruct an info.\n_ATTR_BLOCK_PATTERN = re.compile(r\"\\s*\\{([^}]*)\\}\\s*\")\ndef _parse_attrs(s: str) -> Optional[tuple[Optional[str], list[str]]]:\n    (id, classes) = (None, [])\n    for part in s.split():\n        if part.startswith('#'):\n            if id is not None:\n                return None # just bail on multiple ids instead of trying to recover\n            id = part[1:]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "_ATTR_BLOCK_PATTERN",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "_ATTR_BLOCK_PATTERN = re.compile(r\"\\s*\\{([^}]*)\\}\\s*\")\ndef _parse_attrs(s: str) -> Optional[tuple[Optional[str], list[str]]]:\n    (id, classes) = (None, [])\n    for part in s.split():\n        if part.startswith('#'):\n            if id is not None:\n                return None # just bail on multiple ids instead of trying to recover\n            id = part[1:]\n        elif part.startswith('.'):\n            classes.append(part[1:])",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "_HEADER_ID_RE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "_HEADER_ID_RE = re.compile(r\"\\s*\\{\\s*\\#([\\w.-]+)\\s*\\}\\s*$\")\ndef _heading_ids(md: markdown_it.MarkdownIt) -> None:\n    def heading_ids(state: markdown_it.rules_core.StateCore) -> None:\n        tokens = state.tokens\n        # this is purposely simple and doesn't support classes or other kinds of attributes.\n        for (i, token) in enumerate(tokens):\n            if token.type == 'heading_open':\n                children = tokens[i + 1].children\n                assert children is not None\n                if len(children) == 0 or children[-1].type != 'text':",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "TR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "peekOfCode": "TR = TypeVar('TR', bound='Renderer')\nclass Converter(ABC, Generic[TR]):\n    # we explicitly disable markdown-it rendering support and use our own entirely.\n    # rendering is well separated from parsing and our renderers carry much more state than\n    # markdown-it easily acknowledges as 'good' (unless we used the untyped env args to\n    # shuttle that state around, which is very fragile)\n    class ForbiddenRenderer(markdown_it.renderer.RendererProtocol):\n        __output__ = \"none\"\n        def __init__(self, parser: Optional[markdown_it.MarkdownIt]):\n            pass",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.md",
        "documentation": {}
    },
    {
        "label": "BaseConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class BaseConverter(Converter[md.TR], Generic[md.TR]):\n    __option_block_separator__: str\n    _options: dict[str, RenderedOption]\n    def __init__(self, revision: str):\n        super().__init__()\n        self._options = {}\n        self._revision = revision\n    def _sorted_options(self) -> list[tuple[str, RenderedOption]]:\n        keys = list(self._options.keys())\n        keys.sort(key=lambda opt: [ (0 if p.startswith(\"enable\") else 1 if p.startswith(\"package\") else 2, p)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "OptionDocsRestrictions",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class OptionDocsRestrictions:\n    def heading_open(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        raise RuntimeError(\"md token not supported in options doc\", token)\n    def heading_close(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        raise RuntimeError(\"md token not supported in options doc\", token)\n    def attr_span_begin(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        raise RuntimeError(\"md token not supported in options doc\", token)\n    def example_open(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        raise RuntimeError(\"md token not supported in options doc\", token)\nclass OptionsManpageRenderer(OptionDocsRestrictions, ManpageRenderer):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "OptionsManpageRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class OptionsManpageRenderer(OptionDocsRestrictions, ManpageRenderer):\n    pass\nclass ManpageConverter(BaseConverter[OptionsManpageRenderer]):\n    __option_block_separator__ = \".sp\"\n    _options_by_id: dict[str, str]\n    _links_in_last_description: Optional[list[str]] = None\n    def __init__(self, revision: str,\n                 header: list[str] | None,\n                 footer: list[str] | None,\n                 *,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "ManpageConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class ManpageConverter(BaseConverter[OptionsManpageRenderer]):\n    __option_block_separator__ = \".sp\"\n    _options_by_id: dict[str, str]\n    _links_in_last_description: Optional[list[str]] = None\n    def __init__(self, revision: str,\n                 header: list[str] | None,\n                 footer: list[str] | None,\n                 *,\n                 # only for parallel rendering\n                 _options_by_id: Optional[dict[str, str]] = None):",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "OptionsCommonMarkRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class OptionsCommonMarkRenderer(OptionDocsRestrictions, CommonMarkRenderer):\n    pass\nclass CommonMarkConverter(BaseConverter[OptionsCommonMarkRenderer]):\n    __option_block_separator__ = \"\"\n    def __init__(self, manpage_urls: Mapping[str, str], revision: str):\n        super().__init__(revision)\n        self._renderer = OptionsCommonMarkRenderer(manpage_urls)\n    def _parallel_render_prepare(self) -> Any:\n        return (self._renderer._manpage_urls, self._revision)\n    @classmethod",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "CommonMarkConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class CommonMarkConverter(BaseConverter[OptionsCommonMarkRenderer]):\n    __option_block_separator__ = \"\"\n    def __init__(self, manpage_urls: Mapping[str, str], revision: str):\n        super().__init__(revision)\n        self._renderer = OptionsCommonMarkRenderer(manpage_urls)\n    def _parallel_render_prepare(self) -> Any:\n        return (self._renderer._manpage_urls, self._revision)\n    @classmethod\n    def _parallel_render_init_worker(cls, a: Any) -> CommonMarkConverter:\n        return cls(*a)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "OptionsAsciiDocRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class OptionsAsciiDocRenderer(OptionDocsRestrictions, AsciiDocRenderer):\n    pass\nclass AsciiDocConverter(BaseConverter[OptionsAsciiDocRenderer]):\n    __option_block_separator__ = \"\"\n    def __init__(self, manpage_urls: Mapping[str, str], revision: str):\n        super().__init__(revision)\n        self._renderer = OptionsAsciiDocRenderer(manpage_urls)\n    def _parallel_render_prepare(self) -> Any:\n        return (self._renderer._manpage_urls, self._revision)\n    @classmethod",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "AsciiDocConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class AsciiDocConverter(BaseConverter[OptionsAsciiDocRenderer]):\n    __option_block_separator__ = \"\"\n    def __init__(self, manpage_urls: Mapping[str, str], revision: str):\n        super().__init__(revision)\n        self._renderer = OptionsAsciiDocRenderer(manpage_urls)\n    def _parallel_render_prepare(self) -> Any:\n        return (self._renderer._manpage_urls, self._revision)\n    @classmethod\n    def _parallel_render_init_worker(cls, a: Any) -> AsciiDocConverter:\n        return cls(*a)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "OptionsHTMLRenderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class OptionsHTMLRenderer(OptionDocsRestrictions, HTMLRenderer):\n    # TODO docbook compat. must be removed together with the matching docbook handlers.\n    def ordered_list_open(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        token.meta['compact'] = False\n        return super().ordered_list_open(token, tokens, i)\n    def bullet_list_open(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        token.meta['compact'] = False\n        return super().bullet_list_open(token, tokens, i)\n    def fence(self, token: Token, tokens: Sequence[Token], i: int) -> str:\n        info = f\" {html.escape(token.info, True)}\" if token.info != \"\" else \"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "HTMLConverter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "class HTMLConverter(BaseConverter[OptionsHTMLRenderer]):\n    __option_block_separator__ = \"\"\n    def __init__(self, manpage_urls: Mapping[str, str], revision: str,\n                 varlist_id: str, id_prefix: str, xref_targets: Mapping[str, XrefTarget]):\n        super().__init__(revision)\n        self._xref_targets = xref_targets\n        self._varlist_id = varlist_id\n        self._id_prefix = id_prefix\n        self._renderer = OptionsHTMLRenderer(manpage_urls, self._xref_targets)\n    def _parallel_render_prepare(self) -> Any:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "option_is",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "def option_is(option: Option, key: str, typ: str) -> Optional[dict[str, str]]:\n    if key not in option:\n        return None\n    if type(option[key]) != dict:\n        return None\n    if option[key].get('_type') != typ: # type: ignore[union-attr]\n        return None\n    return option[key] # type: ignore[return-value]\nclass BaseConverter(Converter[md.TR], Generic[md.TR]):\n    __option_block_separator__: str",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "build_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "def build_cli(p: argparse.ArgumentParser) -> None:\n    formats = p.add_subparsers(dest='format', required=True)\n    _build_cli_manpage(formats.add_parser('manpage'))\n    _build_cli_commonmark(formats.add_parser('commonmark'))\n    _build_cli_asciidoc(formats.add_parser('asciidoc'))\ndef run_cli(args: argparse.Namespace) -> None:\n    if args.format == 'manpage':\n        _run_cli_manpage(args)\n    elif args.format == 'commonmark':\n        _run_cli_commonmark(args)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "run_cli",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "peekOfCode": "def run_cli(args: argparse.Namespace) -> None:\n    if args.format == 'manpage':\n        _run_cli_manpage(args)\n    elif args.format == 'commonmark':\n        _run_cli_commonmark(args)\n    elif args.format == 'asciidoc':\n        _run_cli_asciidoc(args)\n    else:\n        raise RuntimeError('format not hooked up', args)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.options",
        "documentation": {}
    },
    {
        "label": "map",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "peekOfCode": "def map(fn: Callable[[S, T], R], d: Iterable[T], chunk_size: int,\n        state_fn: Callable[[A], S], state_arg: A) -> list[R]:\n    \"\"\"\n    `[ fn(state, i) for i in d ]`  where `state = state_fn(state_arg)`, but using multiprocessing\n    if `pool_processes` is not `None`. when using multiprocessing is used the state function will\n    be run once in ever worker process and `multiprocessing.Pool.imap` will be used.\n    **NOTE:** neither `state_fn` nor `fn` are allowed to mutate global state! doing so will cause\n    discrepancies if `pool_processes` is not None, since each worker will have its own copy.\n    **NOTE**: all data types that potentially cross a process boundary (so, all of them) must be\n    pickle-able. this excludes lambdas, bound functions, local functions, and a number of other",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "documentation": {}
    },
    {
        "label": "R",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "peekOfCode": "R = TypeVar('R')\nS = TypeVar('S')\nT = TypeVar('T')\nA = TypeVar('A')\npool_processes: Optional[int] = None\n# this thing is impossible to type because there's so much global state involved.\n# wrapping in a class to get access to Generic[] parameters is not sufficient\n# because mypy is too weak, and unnecessarily obscures how much global state is\n# needed in each worker to make this whole brouhaha work.\n_map_worker_fn: Any = None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "documentation": {}
    },
    {
        "label": "S",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "peekOfCode": "S = TypeVar('S')\nT = TypeVar('T')\nA = TypeVar('A')\npool_processes: Optional[int] = None\n# this thing is impossible to type because there's so much global state involved.\n# wrapping in a class to get access to Generic[] parameters is not sufficient\n# because mypy is too weak, and unnecessarily obscures how much global state is\n# needed in each worker to make this whole brouhaha work.\n_map_worker_fn: Any = None\n_map_worker_state_fn: Any = None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "peekOfCode": "T = TypeVar('T')\nA = TypeVar('A')\npool_processes: Optional[int] = None\n# this thing is impossible to type because there's so much global state involved.\n# wrapping in a class to get access to Generic[] parameters is not sufficient\n# because mypy is too weak, and unnecessarily obscures how much global state is\n# needed in each worker to make this whole brouhaha work.\n_map_worker_fn: Any = None\n_map_worker_state_fn: Any = None\n_map_worker_state_arg: Any = None",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "peekOfCode": "A = TypeVar('A')\npool_processes: Optional[int] = None\n# this thing is impossible to type because there's so much global state involved.\n# wrapping in a class to get access to Generic[] parameters is not sufficient\n# because mypy is too weak, and unnecessarily obscures how much global state is\n# needed in each worker to make this whole brouhaha work.\n_map_worker_fn: Any = None\n_map_worker_state_fn: Any = None\n_map_worker_state_arg: Any = None\ndef _map_worker_init(*args: Any) -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.parallel",
        "documentation": {}
    },
    {
        "label": "RenderedOption",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "peekOfCode": "class RenderedOption(NamedTuple):\n    loc: list[str]\n    lines: list[str]\n    links: Optional[list[str]] = None\nRenderFn = Callable[[Token, Sequence[Token], int], str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "documentation": {}
    },
    {
        "label": "OptionLoc",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "peekOfCode": "OptionLoc = str | dict[str, str]\nOption = dict[str, str | dict[str, str] | list[OptionLoc]]\nclass RenderedOption(NamedTuple):\n    loc: list[str]\n    lines: list[str]\n    links: Optional[list[str]] = None\nRenderFn = Callable[[Token, Sequence[Token], int], str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "documentation": {}
    },
    {
        "label": "Option",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "peekOfCode": "Option = dict[str, str | dict[str, str] | list[OptionLoc]]\nclass RenderedOption(NamedTuple):\n    loc: list[str]\n    lines: list[str]\n    links: Optional[list[str]] = None\nRenderFn = Callable[[Token, Sequence[Token], int], str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "documentation": {}
    },
    {
        "label": "RenderFn",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "peekOfCode": "RenderFn = Callable[[Token, Sequence[Token], int], str]",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.types",
        "documentation": {}
    },
    {
        "label": "Freezeable",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.utils",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.utils",
        "peekOfCode": "class Freezeable:\n    def freeze(self) -> None:\n        cls = type(self)\n        if not (frozen := _frozen_classes.get(cls)):\n            def __setattr__(instance: Any, n: str, v: Any) -> None:\n                raise TypeError(f'{cls.__name__} is frozen')\n            frozen = type(cls.__name__, (cls,), {\n                '__setattr__': __setattr__,\n            })\n            _frozen_classes[cls] = frozen",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.nixos_render_docs.utils",
        "documentation": {}
    },
    {
        "label": "sample1",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.sample_md",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.sample_md",
        "peekOfCode": "sample1 = \"\"\"\\\n:::: {.warning}\nfoo\n::: {.note}\nnested\n:::\n::::\n[\n  multiline\n](link)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.sample_md",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.asciidoc.AsciiDocRenderer]):\n    def __init__(self, manpage_urls: dict[str, str]):\n        super().__init__()\n        self._renderer = nrd.asciidoc.AsciiDocRenderer(manpage_urls)\ndef test_lists() -> None:\n    c = Converter({})\n    # attaching to the nth ancestor list requires n newlines before the +\n    assert c._render(\"\"\"\\\n- a\n  b",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "documentation": {}
    },
    {
        "label": "test_lists",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "peekOfCode": "def test_lists() -> None:\n    c = Converter({})\n    # attaching to the nth ancestor list requires n newlines before the +\n    assert c._render(\"\"\"\\\n- a\n  b\n- c\n  - d\n    - e\n      1",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "documentation": {}
    },
    {
        "label": "test_full",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "peekOfCode": "def test_full() -> None:\n    c = Converter({ 'man(1)': 'http://example.org' })\n    assert c._render(sample1) == \"\"\"\\\n[WARNING]\n====\nfoo\n[NOTE]\n=====\nnested\n=====",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_asciidoc",
        "documentation": {}
    },
    {
        "label": "set_prefix",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "peekOfCode": "def set_prefix(token: Token, ident: str) -> None:\n    token.attrs[\"id\"] = f\"{auto_id_prefix}-{ident}\"\ndef test_auto_id_prefix_simple() -> None:\n    md = HTMLConverter(\"1.0.0\", HTMLParameters(\"\", [], [], 2, 2, 2, Path(\"\")), {})\n    src = f\"\"\"\n# title\n## subtitle\n    \"\"\"\n    tokens = Converter()._parse(src)\n    md._handle_headings(tokens, on_heading=set_prefix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "documentation": {}
    },
    {
        "label": "test_auto_id_prefix_simple",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "peekOfCode": "def test_auto_id_prefix_simple() -> None:\n    md = HTMLConverter(\"1.0.0\", HTMLParameters(\"\", [], [], 2, 2, 2, Path(\"\")), {})\n    src = f\"\"\"\n# title\n## subtitle\n    \"\"\"\n    tokens = Converter()._parse(src)\n    md._handle_headings(tokens, on_heading=set_prefix)\n    assert [\n        {**token.attrs, \"tag\": token.tag}",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "documentation": {}
    },
    {
        "label": "test_auto_id_prefix_repeated",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "peekOfCode": "def test_auto_id_prefix_repeated() -> None:\n    md = HTMLConverter(\"1.0.0\", HTMLParameters(\"\", [], [], 2, 2, 2, Path(\"\")), {})\n    src = f\"\"\"\n# title\n## subtitle\n# title2\n## subtitle2\n    \"\"\"\n    tokens = Converter()._parse(src)\n    md._handle_headings(tokens, on_heading=set_prefix)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "documentation": {}
    },
    {
        "label": "test_auto_id_prefix_maximum_nested",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "peekOfCode": "def test_auto_id_prefix_maximum_nested() -> None:\n    md = HTMLConverter(\"1.0.0\", HTMLParameters(\"\", [], [], 2, 2, 2, Path(\"\")), {})\n    src = f\"\"\"\n# h1\n## h2\n### h3\n#### h4\n##### h5\n###### h6\n## h2.2",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_auto_id_prefix",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.commonmark.CommonMarkRenderer]):\n    def __init__(self, manpage_urls: Mapping[str, str]):\n        super().__init__()\n        self._renderer = nrd.commonmark.CommonMarkRenderer(manpage_urls)\n# NOTE: in these tests we represent trailing spaces by `` and replace them with real space later,\n# since a number of editors will strip trailing whitespace on save and that would break the tests.\ndef test_indented_fence() -> None:\n    c = Converter({})\n    s = \"\"\"\\\n>  - ```foo",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "documentation": {}
    },
    {
        "label": "test_indented_fence",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "peekOfCode": "def test_indented_fence() -> None:\n    c = Converter({})\n    s = \"\"\"\\\n>  - ```foo\n>    thing\n>\n>    rest\n>    ```\\\n\"\"\".replace('', ' ')\n    assert c._render(s) == s",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "documentation": {}
    },
    {
        "label": "test_full",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "peekOfCode": "def test_full() -> None:\n    c = Converter({ 'man(1)': 'http://example.org' })\n    assert c._render(sample1) == \"\"\"\\\n**Warning:** foo\n**Note:** nested\n[\nmultiline\n](link)\n[` man(1) `](http://example.org) reference\nsome nested anchors",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "documentation": {}
    },
    {
        "label": "test_images",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "peekOfCode": "def test_images() -> None:\n    c = Converter({})\n    assert c._render(\"![*alt text*](foo \\\"title \\\\\\\"quoted\\\\\\\" text\\\")\") == (\n        \"![*alt text*](foo \\\"title \\\\\\\"quoted\\\\\\\" text\\\")\"\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_commonmark",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.html.HTMLRenderer]):\n    # actual renderer doesn't matter, we're just parsing.\n    def __init__(self, manpage_urls: dict[str, str]) -> None:\n        super().__init__()\n        self._renderer = nrd.html.HTMLRenderer(manpage_urls, {})\ndef test_heading_id_absent() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='#', info='', meta={}, block=True, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "test_heading_id_absent",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "def test_heading_id_absent() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo', markup='', info='', meta={}, block=False, hidden=False)\n              ],",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "test_heading_id_present",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "def test_heading_id_present() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo {#foo}\\n## bar { #bar}\\n### bal { #bal}  \") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={'id': 'foo'}, map=[0, 1], level=0,\n              children=None, content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo {#foo}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "test_heading_id_incomplete",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "def test_heading_id_incomplete() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo {#}\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo {#}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo {#}', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "test_heading_id_double",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "def test_heading_id_double() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo {#a} {#b}\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={'id': 'b'}, map=[0, 1], level=0,\n              children=None, content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo {#a} {#b}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo {#a}', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "test_heading_id_suffixed",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "peekOfCode": "def test_heading_id_suffixed() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo {#a} s\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0,\n              children=None, content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo {#a} s', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo {#a} s', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_headings",
        "documentation": {}
    },
    {
        "label": "Renderer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "class Renderer(nrd.html.HTMLRenderer):\n    def _pull_image(self, src: str) -> str:\n        return src\nclass Converter(nrd.md.Converter[nrd.html.HTMLRenderer]):\n    def __init__(self, manpage_urls: dict[str, str], xrefs: dict[str, nrd.manual_structure.XrefTarget]):\n        super().__init__()\n        self._renderer = Renderer(manpage_urls, xrefs)\ndef unpretty(s: str) -> str:\n    return \"\".join(map(str.strip, s.splitlines())).replace('', ' ').replace('', '\\n')\ndef test_lists_styles() -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.html.HTMLRenderer]):\n    def __init__(self, manpage_urls: dict[str, str], xrefs: dict[str, nrd.manual_structure.XrefTarget]):\n        super().__init__()\n        self._renderer = Renderer(manpage_urls, xrefs)\ndef unpretty(s: str) -> str:\n    return \"\".join(map(str.strip, s.splitlines())).replace('', ' ').replace('', '\\n')\ndef test_lists_styles() -> None:\n    # nested lists rotate through a number of list style\n    c = Converter({}, {})\n    assert c._render(\"- - - - foo\") == unpretty(\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "unpretty",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def unpretty(s: str) -> str:\n    return \"\".join(map(str.strip, s.splitlines())).replace('', ' ').replace('', '\\n')\ndef test_lists_styles() -> None:\n    # nested lists rotate through a number of list style\n    c = Converter({}, {})\n    assert c._render(\"- - - - foo\") == unpretty(\"\"\"\n      <div class=\"itemizedlist\"><ul class=\"itemizedlist compact\" style=\"list-style-type: disc;\">\n       <li class=\"listitem\">\n        <div class=\"itemizedlist\"><ul class=\"itemizedlist compact\" style=\"list-style-type: circle;\">\n         <li class=\"listitem\">",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_lists_styles",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_lists_styles() -> None:\n    # nested lists rotate through a number of list style\n    c = Converter({}, {})\n    assert c._render(\"- - - - foo\") == unpretty(\"\"\"\n      <div class=\"itemizedlist\"><ul class=\"itemizedlist compact\" style=\"list-style-type: disc;\">\n       <li class=\"listitem\">\n        <div class=\"itemizedlist\"><ul class=\"itemizedlist compact\" style=\"list-style-type: circle;\">\n         <li class=\"listitem\">\n          <div class=\"itemizedlist\"><ul class=\"itemizedlist compact\" style=\"list-style-type: square;\">\n           <li class=\"listitem\">",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_xrefs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_xrefs() -> None:\n    # nested lists rotate through a number of list style\n    c = Converter({}, {\n        'foo': nrd.manual_structure.XrefTarget('foo', '<hr/>', 'toc1', 'title1', 'index.html'),\n        'bar': nrd.manual_structure.XrefTarget('bar', '<br/>', 'toc2', 'title2', 'index.html', True),\n    })\n    assert c._render(\"[](#foo)\") == '<p><a class=\"xref\" href=\"index.html#foo\" title=\"title1\" ><hr/></a></p>'\n    assert c._render(\"[](#bar)\") == '<p><a class=\"xref\" href=\"index.html\" title=\"title2\" ><br/></a></p>'\n    with pytest.raises(nrd.html.UnresolvedXrefError) as exc:\n        c._render(\"[](#baz)\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_images",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_images() -> None:\n    c = Converter({}, {})\n    assert c._render(\"![*alt text*](foo \\\"title text\\\")\") == unpretty(\"\"\"\n      <p>\n       <div class=\"mediaobject\">\n        <img src=\"foo\" alt=\"*alt text*\" title=\"title text\" />\n       </div>\n      </p>\n    \"\"\")\ndef test_tables() -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_tables",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_tables() -> None:\n    c = Converter({}, {})\n    assert c._render(textwrap.dedent(\"\"\"\n      | d | l | m | r |\n      |---|:--|:-:|--:|\n      | a | b | c | d |\n    \"\"\")) == unpretty(\"\"\"\n      <div class=\"informaltable\">\n       <table class=\"informaltable\" border=\"1\">\n        <colgroup>",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_footnotes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_footnotes() -> None:\n    c = Converter({}, {\n        \"bar\": nrd.manual_structure.XrefTarget(\"bar\", \"\", None, None, \"\"),\n        \"bar.__back.0\": nrd.manual_structure.XrefTarget(\"bar.__back.0\", \"\", None, None, \"\"),\n        \"bar.__back.1\": nrd.manual_structure.XrefTarget(\"bar.__back.1\", \"\", None, None, \"\"),\n    })\n    assert c._render(textwrap.dedent(\"\"\"\n      foo [^bar] baz [^bar]\n      [^bar]: note\n    \"\"\")) == unpretty(\"\"\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "test_full",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "peekOfCode": "def test_full() -> None:\n    c = Converter({ 'man(1)': 'http://example.org' }, {})\n    assert c._render(sample1) == unpretty(\"\"\"\n        <div class=\"warning\">\n         <h3 class=\"title\">Warning</h3>\n         <p>foo</p>\n         <div class=\"note\">\n          <h3 class=\"title\">Note</h3>\n          <p>nested</p>\n         </div>",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_html",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.html.HTMLRenderer]):\n    # actual renderer doesn't matter, we're just parsing.\n    def __init__(self, manpage_urls: dict[str, str]) -> None:\n        super().__init__()\n        self._renderer = nrd.html.HTMLRenderer(manpage_urls, {})\n@pytest.mark.parametrize(\"ordered\", [True, False])\ndef test_list_wide(ordered: bool) -> None:\n    t, tag, m, e1, e2, i1, i2 = (\n        (\"ordered\", \"ol\", \".\", \"1.\", \"2.\", \"1\", \"2\") if ordered else (\"bullet\", \"ul\", \"-\", \"-\", \"-\", \"\", \"\")\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "documentation": {}
    },
    {
        "label": "test_list_wide",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "peekOfCode": "def test_list_wide(ordered: bool) -> None:\n    t, tag, m, e1, e2, i1, i2 = (\n        (\"ordered\", \"ol\", \".\", \"1.\", \"2.\", \"1\", \"2\") if ordered else (\"bullet\", \"ul\", \"-\", \"-\", \"-\", \"\", \"\")\n    )\n    c = Converter({})\n    meta = { 'end': int(e2[:-1]) } if ordered else {}\n    meta['compact'] = False\n    assert c._parse(f\"{e1} a\\n\\n{e2} b\") == [\n        Token(type=f'{t}_list_open', tag=tag, nesting=1, attrs={}, map=[0, 3], level=0,\n              children=None, content='', markup=m, info='', meta=meta, block=True, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "documentation": {}
    },
    {
        "label": "test_list_narrow",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "peekOfCode": "def test_list_narrow(ordered: bool) -> None:\n    t, tag, m, e1, e2, i1, i2 = (\n        (\"ordered\", \"ol\", \".\", \"1.\", \"2.\", \"1\", \"2\") if ordered else (\"bullet\", \"ul\", \"-\", \"-\", \"-\", \"\", \"\")\n    )\n    c = Converter({})\n    meta = { 'end': int(e2[:-1]) } if ordered else {}\n    meta['compact'] = True\n    assert c._parse(f\"{e1} a\\n{e2} b\") == [\n        Token(type=f'{t}_list_open', tag=tag, nesting=1, attrs={}, map=[0, 2], level=0,\n              children=None, content='', markup=m, info='', meta=meta, block=True, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_lists",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.manpage.ManpageRenderer]):\n    def __init__(self, manpage_urls: Mapping[str, str], options_by_id: dict[str, str] = {}):\n        super().__init__()\n        self._renderer = nrd.manpage.ManpageRenderer(manpage_urls, options_by_id)\ndef test_inline_code() -> None:\n    c = Converter({})\n    assert c._render(\"1  `x  a  x`  2\") == \"1 \\\\fR\\\\(oqx  a  x\\\\(cq\\\\fP 2\"\ndef test_fonts() -> None:\n    c = Converter({})\n    assert c._render(\"*a **b** c*\") == \"\\\\fIa \\\\fBb\\\\fI c\\\\fR\"",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_inline_code",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_inline_code() -> None:\n    c = Converter({})\n    assert c._render(\"1  `x  a  x`  2\") == \"1 \\\\fR\\\\(oqx  a  x\\\\(cq\\\\fP 2\"\ndef test_fonts() -> None:\n    c = Converter({})\n    assert c._render(\"*a **b** c*\") == \"\\\\fIa \\\\fBb\\\\fI c\\\\fR\"\n    assert c._render(\"*a [1 `2`](3) c*\") == \"\\\\fIa \\\\fB1 \\\\fR\\\\(oq2\\\\(cq\\\\fP\\\\fI c\\\\fR\"\ndef test_expand_link_targets() -> None:\n    c = Converter({}, { '#foo1': \"bar\", \"#foo2\": \"bar\" })\n    assert (c._render(\"[a](#foo1) [](#foo2) [b](#bar1) [](#bar2)\") ==",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_fonts",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_fonts() -> None:\n    c = Converter({})\n    assert c._render(\"*a **b** c*\") == \"\\\\fIa \\\\fBb\\\\fI c\\\\fR\"\n    assert c._render(\"*a [1 `2`](3) c*\") == \"\\\\fIa \\\\fB1 \\\\fR\\\\(oq2\\\\(cq\\\\fP\\\\fI c\\\\fR\"\ndef test_expand_link_targets() -> None:\n    c = Converter({}, { '#foo1': \"bar\", \"#foo2\": \"bar\" })\n    assert (c._render(\"[a](#foo1) [](#foo2) [b](#bar1) [](#bar2)\") ==\n            \"\\\\fBa\\\\fR \\\\fBbar\\\\fR \\\\fBb\\\\fR \\\\fB\\\\fR\")\ndef test_collect_links() -> None:\n    c = Converter({}, { '#foo': \"bar\" })",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_expand_link_targets",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_expand_link_targets() -> None:\n    c = Converter({}, { '#foo1': \"bar\", \"#foo2\": \"bar\" })\n    assert (c._render(\"[a](#foo1) [](#foo2) [b](#bar1) [](#bar2)\") ==\n            \"\\\\fBa\\\\fR \\\\fBbar\\\\fR \\\\fBb\\\\fR \\\\fB\\\\fR\")\ndef test_collect_links() -> None:\n    c = Converter({}, { '#foo': \"bar\" })\n    c._renderer.link_footnotes = []\n    assert c._render(\"[a](link1) [b](link2)\") == \"\\\\fBa\\\\fR[1]\\\\fR \\\\fBb\\\\fR[2]\\\\fR\"\n    assert c._renderer.link_footnotes == ['link1', 'link2']\ndef test_dedup_links() -> None:",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_collect_links",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_collect_links() -> None:\n    c = Converter({}, { '#foo': \"bar\" })\n    c._renderer.link_footnotes = []\n    assert c._render(\"[a](link1) [b](link2)\") == \"\\\\fBa\\\\fR[1]\\\\fR \\\\fBb\\\\fR[2]\\\\fR\"\n    assert c._renderer.link_footnotes == ['link1', 'link2']\ndef test_dedup_links() -> None:\n    c = Converter({}, { '#foo': \"bar\" })\n    c._renderer.link_footnotes = []\n    assert c._render(\"[a](link) [b](link)\") == \"\\\\fBa\\\\fR[1]\\\\fR \\\\fBb\\\\fR[1]\\\\fR\"\n    assert c._renderer.link_footnotes == ['link']",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_dedup_links",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_dedup_links() -> None:\n    c = Converter({}, { '#foo': \"bar\" })\n    c._renderer.link_footnotes = []\n    assert c._render(\"[a](link) [b](link)\") == \"\\\\fBa\\\\fR[1]\\\\fR \\\\fBb\\\\fR[1]\\\\fR\"\n    assert c._renderer.link_footnotes == ['link']\ndef test_full() -> None:\n    c = Converter({ 'man(1)': 'http://example.org' })\n    assert c._render(sample1) == \"\"\"\\\n.sp\n.RS 4",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_full",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "peekOfCode": "def test_full() -> None:\n    c = Converter({ 'man(1)': 'http://example.org' })\n    assert c._render(sample1) == \"\"\"\\\n.sp\n.RS 4\n\\\\fBWarning\\\\fP\n.br\nfoo\n.sp\n.RS 4",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_manpage",
        "documentation": {}
    },
    {
        "label": "test_option_headings",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_options",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_options",
        "peekOfCode": "def test_option_headings() -> None:\n    c = nixos_render_docs.options.HTMLConverter({}, 'local', 'vars', 'opt-', {})\n    with pytest.raises(RuntimeError) as exc:\n        c._render(\"# foo\")\n    assert exc.value.args[0] == 'md token not supported in options doc'\n    assert exc.value.args[1] == Token(\n        type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n        content='', markup='#', info='', meta={}, block=True, hidden=False\n    )",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_options",
        "documentation": {}
    },
    {
        "label": "Converter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "class Converter(nrd.md.Converter[nrd.html.HTMLRenderer]):\n    # actual renderer doesn't matter, we're just parsing.\n    def __init__(self, manpage_urls: dict[str, str]) -> None:\n        super().__init__()\n        self._renderer = nrd.html.HTMLRenderer(manpage_urls, {})\ndef test_attr_span_parsing() -> None:\n    c = Converter({})\n    assert c._parse(\"[]{#test}\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_parsing",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_parsing() -> None:\n    c = Converter({})\n    assert c._parse(\"[]{#test}\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1, content='[]{#test}',\n              markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='attr_span_begin', tag='span', nesting=1, attrs={'id': 'test'}, map=None, level=0,\n                        children=None, content='', markup='', info='', meta={}, block=False, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_formatted",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_formatted() -> None:\n    c = Converter({})\n    assert c._parse(\"a[b c `d` ***e***]{#test}f\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0,\n              children=None, content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='a[b c `d` ***e***]{#test}f', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0,\n                        children=None, content='a', markup='', info='', meta={}, block=False, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_in_heading",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_in_heading() -> None:\n    c = Converter({})\n    # inline anchors in headers are allowed, but header attributes should be preferred\n    assert c._parse(\"# foo []{#bar} baz\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo []{#bar} baz', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_on_links",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_on_links() -> None:\n    c = Converter({})\n    assert c._parse(\"[ [a](#bar) ]{#foo}\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1, content='[ [a](#bar) ]{#foo}',\n              markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='attr_span_begin', tag='span', nesting=1, attrs={'id': 'foo'}, map=None, level=0,\n                        children=None, content='', markup='', info='', meta={}, block=False, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_nested",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_nested() -> None:\n    # inline anchors may contain more anchors (even though this is a bit pointless)\n    c = Converter({})\n    assert c._parse(\"[ [a]{#bar} ]{#foo}\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='[ [a]{#bar} ]{#foo}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='attr_span_begin', tag='span', nesting=1, attrs={'id': 'foo'}, map=None, level=0,",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_attr_span_escaping",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_attr_span_escaping() -> None:\n    c = Converter({})\n    assert c._parse(\"\\\\[a]{#bar}\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='\\\\[a]{#bar}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='[a]{#bar}', markup='\\\\[', info='escape', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_inline_comment_basic",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_inline_comment_basic() -> None:\n    c = Converter({})\n    assert c._parse(\"a <!-- foo --><!----> b\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='a <!-- foo --><!----> b', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='a  b', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_inline_comment_does_not_nest_in_code",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_inline_comment_does_not_nest_in_code() -> None:\n    c = Converter({})\n    assert c._parse(\"`a<!-- b -->c`\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='`a<!-- b -->c`', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='code_inline', tag='code', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='a<!-- b -->c', markup='`', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_inline_comment_does_not_nest_elsewhere",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_inline_comment_does_not_nest_elsewhere() -> None:\n    c = Converter({})\n    assert c._parse(\"*a<!-- b -->c*\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='*a<!-- b -->c*', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='em_open', tag='em', nesting=1, attrs={}, map=None, level=0, children=None,\n                        content='', markup='*', info='', meta={}, block=False, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_inline_comment_can_be_escaped",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_inline_comment_can_be_escaped() -> None:\n    c = Converter({})\n    assert c._parse(\"a\\\\<!-- b -->c\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, attrs={}, map=[0, 1], level=0, children=None,\n              content='', markup='', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='a\\\\<!-- b -->c', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='a<!-- b -->c', markup='', info='', meta={}, block=False, hidden=False)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_block_comment",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_block_comment() -> None:\n    c = Converter({})\n    assert c._parse(\"<!-- a -->\") == []\n    assert c._parse(\"<!-- a\\n-->\") == []\n    assert c._parse(\"<!--\\na\\n-->\") == []\n    assert c._parse(\"<!--\\n\\na\\n\\n-->\") == []\n    assert c._parse(\"<!--\\n\\n```\\n\\n\\n```\\n\\n-->\") == []\ndef test_heading_attributes() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo *bar* {#hid}\") == [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_heading_attributes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_heading_attributes() -> None:\n    c = Converter({})\n    assert c._parse(\"# foo *bar* {#hid}\") == [\n        Token(type='heading_open', tag='h1', nesting=1, attrs={'id': 'hid'}, map=[0, 1], level=0,\n              children=None, content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[0, 1], level=1,\n              content='foo *bar* {#hid}', markup='', info='', meta={}, block=True, hidden=False,\n              children=[\n                  Token(type='text', tag='', nesting=0, attrs={}, map=None, level=0, children=None,\n                        content='foo ', markup='', info='', meta={}, block=False, hidden=False),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_admonitions",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_admonitions() -> None:\n    c = Converter({})\n    assert c._parse(\"::: {.note}\") == [\n        Token(type='admonition_open', tag='div', nesting=1, attrs={}, map=[0, 1], level=0,\n              children=None, content='', markup=':::', info=' {.note}', meta={'kind': 'note'}, block=True,\n              hidden=False),\n        Token(type='admonition_close', tag='div', nesting=-1, attrs={}, map=None, level=0,\n              children=None, content='', markup=':::', info='', meta={}, block=True, hidden=False)\n    ]\n    assert c._parse(\"::: {.caution}\") == [",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_example",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_example() -> None:\n    c = Converter({})\n    assert c._parse(\"::: {.example}\\n# foo\") == [\n        Token(type='example_open', tag='div', nesting=1, attrs={}, map=[0, 2], level=0, children=None,\n              content='', markup=':::', info=' {.example}', meta={}, block=True, hidden=False),\n        Token(type='example_title_open', tag='h1', nesting=1, attrs={}, map=[1, 2], level=1, children=None,\n              content='', markup='#', info='', meta={}, block=True, hidden=False),\n        Token(type='inline', tag='', nesting=0, attrs={}, map=[1, 2], level=2,\n              content='foo', markup='', info='', meta={}, block=True, hidden=False,\n              children=[",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "test_footnotes",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "peekOfCode": "def test_footnotes() -> None:\n    c = Converter({})\n    assert c._parse(\"text [^foo]\\n\\n[^foo]: bar\") == [\n        Token(type='paragraph_open', tag='p', nesting=1, map=[0, 1], block=True),\n        Token(type='inline', tag='', nesting=0, map=[0, 1], level=1, content='text [^foo]', block=True,\n              children=[\n                  Token(type='text', tag='', nesting=0, content='text '),\n                  Token(type='footnote_ref', tag='', nesting=0, attrs={'id': 'foo.__back.0'},\n                        meta={'id': 0, 'subId': 0, 'label': 'foo', 'target': 'foo'})\n              ]),",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.nix.nixos-render-docs.src.tests.test_plugins",
        "documentation": {}
    },
    {
        "label": "find_latest_version",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "peekOfCode": "def find_latest_version(arch):\n    CHECK_URL = f'https://apt.enpass.io/dists/stable/main/binary-{arch}/Packages.gz'\n    packages = gzip.decompress(requests.get(CHECK_URL).content).decode()\n    # Loop every package to find the newest one!\n    version_selector = re.compile(\"Version: (?P<version>.+)\")\n    path_selector = re.compile(\"Filename: (?P<path>.+)\")\n    hash_selector = re.compile(\"SHA256: (?P<sha256>.+)\")\n    last_version = version.parse(\"0\")\n    for package in packages.split(\"\\n\\n\"):\n        matches = version_selector.search(package)",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "documentation": {}
    },
    {
        "label": "current_path",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "peekOfCode": "current_path = pathlib.Path(__file__).parent\nDATA_JSON = current_path.joinpath(\"data.json\").resolve()\nlogging.debug(f\"Path to version file: {DATA_JSON}\")\nlast_new_version = None\nwith open(DATA_JSON, \"r\") as versions_file:\n    versions = json.load(versions_file)\ndef find_latest_version(arch):\n    CHECK_URL = f'https://apt.enpass.io/dists/stable/main/binary-{arch}/Packages.gz'\n    packages = gzip.decompress(requests.get(CHECK_URL).content).decode()\n    # Loop every package to find the newest one!",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "documentation": {}
    },
    {
        "label": "DATA_JSON",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "peekOfCode": "DATA_JSON = current_path.joinpath(\"data.json\").resolve()\nlogging.debug(f\"Path to version file: {DATA_JSON}\")\nlast_new_version = None\nwith open(DATA_JSON, \"r\") as versions_file:\n    versions = json.load(versions_file)\ndef find_latest_version(arch):\n    CHECK_URL = f'https://apt.enpass.io/dists/stable/main/binary-{arch}/Packages.gz'\n    packages = gzip.decompress(requests.get(CHECK_URL).content).decode()\n    # Loop every package to find the newest one!\n    version_selector = re.compile(\"Version: (?P<version>.+)\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "documentation": {}
    },
    {
        "label": "last_new_version",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "peekOfCode": "last_new_version = None\nwith open(DATA_JSON, \"r\") as versions_file:\n    versions = json.load(versions_file)\ndef find_latest_version(arch):\n    CHECK_URL = f'https://apt.enpass.io/dists/stable/main/binary-{arch}/Packages.gz'\n    packages = gzip.decompress(requests.get(CHECK_URL).content).decode()\n    # Loop every package to find the newest one!\n    version_selector = re.compile(\"Version: (?P<version>.+)\")\n    path_selector = re.compile(\"Filename: (?P<path>.+)\")\n    hash_selector = re.compile(\"SHA256: (?P<sha256>.+)\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "documentation": {}
    },
    {
        "label": "commit_message",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "description": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "peekOfCode": "commit_message = f\"enpass: {last_current_version} -> {last_new_version['version']}\"\nsubprocess.run(['git', 'add', DATA_JSON], check=True)\nsubprocess.run(['git', 'commit', '--file=-'], input=commit_message.encode(), check=True)\nlogging.info(\"Done.\")",
        "detail": ".direnv.flake-inputs.ldcf0nwsjfwg4vbfd5d0r2dzb1f4wcrz-source.pkgs.tools.security.enpass.update_script",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-special-deps",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-special-deps",
        "peekOfCode": "def main(input, output, fields_to_remove):\n    data = tomlkit.loads(input.read())\n    try:\n        deps = data[\"tool\"][\"poetry\"][\"dependencies\"]\n    except KeyError:\n        pass\n    else:\n        for dep in deps.values():\n            if isinstance(dep, dict):\n                any_removed = False",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-special-deps",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-url-whl",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-url-whl",
        "peekOfCode": "def main(input, output):\n    data = tomlkit.loads(input.read())\n    try:\n        deps = data[\"tool\"][\"poetry\"][\"dependencies\"]\n    except KeyError:\n        pass\n    else:\n        for dep in deps.values():\n            if isinstance(dep, dict):\n                url = dep.get(\"url\", None)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.pyproject-without-url-whl",
        "documentation": {}
    },
    {
        "label": "Rewriter",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "peekOfCode": "class Rewriter(ast.NodeVisitor):\n    def __init__(self, *args, **kwargs):\n        super(Rewriter, self).__init__(*args, **kwargs)\n        self.modified = False\n    def visit_Call(self, node):\n        function_name = \"\"\n        if isinstance(node.func, ast.Name):\n            function_name = node.func.id\n        elif isinstance(node.func, ast.Attribute):\n            function_name = node.func.attr",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "documentation": {}
    },
    {
        "label": "astunparse",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "peekOfCode": "def astunparse(tree):\n    # Use bundled unparse by default\n    if hasattr(ast, \"unparse\"):\n        return ast.unparse(tree)\n    # Use example tool from Python sources for older interpreter versions\n    from poetry2nix_astunparse import Unparser\n    buf = io.StringIO()\n    up = Unparser(tree, buf)\n    return buf.getvalue()\nclass Rewriter(ast.NodeVisitor):",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.hooks.python-requires-patch-hook",
        "documentation": {}
    },
    {
        "label": "LibTransformer",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.overrides.shapely-rewrite",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.overrides.shapely-rewrite",
        "peekOfCode": "class LibTransformer(ast.NodeTransformer):\n    _lgeos_replaced = False\n    def visit_If(self, node):\n        if ast.unparse(node).startswith(\"if sys.platform.startswith('linux')\"):\n            return ast.parse(\n                dedent(\n                    \"\"\"\n            free = CDLL(%s).free\n            free.argtypes = [c_void_p]\n            free.restype = None",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.overrides.shapely-rewrite",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.dependency-environment.trivial",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.dependency-environment.trivial",
        "peekOfCode": "def app(environ, start_response):\n    \"\"\"Simplest possible application object\"\"\"\n    data = b\"Hello, World!\\n\"\n    status = \"200 OK\"\n    response_headers = [\n        (\"Content-type\", \"text/plain\"),\n        (\"Content-Length\", str(len(data))),\n    ]\n    start_response(status, response_headers)\n    return iter([data])",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.dependency-environment.trivial",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-extras.test_extras.test_simple",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-extras.test_extras.test_simple",
        "peekOfCode": "def test_simple():\n    import black  # noqa: F401",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-extras.test_extras.test_simple",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-group.test_group.test_simple",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-group.test_group.test_simple",
        "peekOfCode": "def test_simple():\n    assert True",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-group.test_group.test_simple",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-no-extras.test_no_extras.test_simple",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-no-extras.test_no_extras.test_simple",
        "peekOfCode": "def test_simple():\n    with pytest.raises(ImportError):\n        import black  # noqa: F401",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.test-no-extras.test_no_extras.test_simple",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-src.use_url_src.main",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-src.use_url_src.main",
        "peekOfCode": "def main():\n    pass",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-src.use_url_src.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-wheel.whl_test.main",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-wheel.whl_test.main",
        "peekOfCode": "def main():\n    nlp = de_core_news_sm.load()\n    print(nlp(\"Dies ist ein Testsatz.\"))",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tests.use-url-wheel.whl_test.main",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def normalize(name):\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\ndef find_known_systems() -> Dict[str, str]:\n    \"\"\"Create a map from attribute to drvPath for known build systems\"\"\"\n    expr = \"\"\"let\n      pkgs = import <nixpkgs> { };\n      py = pkgs.python3.pkgs;\n      attrs = [ %s ];\n    in builtins.foldl' (\n      acc: attr: acc // {",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "find_known_systems",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def find_known_systems() -> Dict[str, str]:\n    \"\"\"Create a map from attribute to drvPath for known build systems\"\"\"\n    expr = \"\"\"let\n      pkgs = import <nixpkgs> { };\n      py = pkgs.python3.pkgs;\n      attrs = [ %s ];\n    in builtins.foldl' (\n      acc: attr: acc // {\n        ${attr} = py.${attr}.drvPath;\n      }",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "yield_drvs",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def yield_drvs():\n    \"\"\"Yield all drvs from the python3 set\"\"\"\n    with tempfile.NamedTemporaryFile(mode=\"w\") as f:\n        f.write(\n            \"\"\"\n          let\n            pkgs = import <nixpkgs> { };\n            pythonPackages = pkgs.python3.pkgs;\n          in builtins.removeAttrs pythonPackages [\n            \"pkgs\"",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "get_build_systems",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def get_build_systems(known_systems) -> Dict[str, List[str]]:\n    def check_drv(drv_path) -> List[str]:\n        systems: List[str] = []\n        with open(drv_path) as f:\n            drv = pynixutil.drvparse(f.read())\n        input_drvs: Set[str] = set(drv.input_drvs.keys())\n        for attr, build_system in known_systems.items():\n            if build_system in input_drvs:\n                systems.append(attr)\n        return systems",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "merge_systems",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def merge_systems(s):\n    simple = {i for i in s if isinstance(i, str)}\n    complex = [i for i in s if isinstance(i, dict)]\n    complex_names = {i[\"buildSystem\"] for i in complex}\n    new_simple = simple - complex_names\n    return complex + sorted(list(new_simple))\ndef merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):\n        attr = normalize(attr)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "merge",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):\n        attr = normalize(attr)\n        s = content.setdefault(attr, [])\n        for system in systems:\n            s.append(system)\n    # Return with sorted data\n    return {\n        attr: merge_systems(content[attr])",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "def main():\n    outfile = sys.argv[1]\n    try:\n        with open(outfile) as f:\n            prev_content = json.load(f)\n    except FileNotFoundError:\n        prev_content = {}\n    known_systems = find_known_systems()\n    build_systems = get_build_systems(known_systems)\n    # Unlike nixpkgs we want overrides to be strictly additive by",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "SKIP_ATTRS",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "SKIP_ATTRS = {\n    \"typing-extensions\",\n    \"argon2-cffi\",\n    \"packaging\",\n    \"poetry\",\n    \"flit-core\",\n    \"jsonschema\",\n    \"platformdirs\",\n    \"traitlets\",\n}",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "BLOCKLIST",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "peekOfCode": "BLOCKLIST = {\"poetry\", \"poetry-core\"}\ndef merge_systems(s):\n    simple = {i for i in s if isinstance(i, str)}\n    complex = [i for i in s if isinstance(i, dict)]\n    complex_names = {i[\"buildSystem\"] for i in complex}\n    new_simple = simple - complex_names\n    return complex + sorted(list(new_simple))\ndef merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "Pep503",
        "kind": 6,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "class Pep503(HTMLParser):\n    def __init__(self) -> None:\n        super().__init__()\n        self.sources: dict[str, str] = {}\n        self.url: Optional[str] = None\n        self.name: Optional[str] = None\n    def handle_data(self, data: str) -> None:\n        if self.url is not None:\n            self.name = data\n    def handle_starttag(self, tag: str, attrs: list[tuple[str, Optional[str]]]) -> None:",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "url = sys.argv[1]\npackage_name = sys.argv[2]\nindex_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_name = sys.argv[2]\nindex_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present\n    if \":\" in host:",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_filename",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present\n    if \":\" in host:\n        host = host.split(\":\")[0]",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context = ssl.create_default_context()\ncontext.check_hostname = False\ncontext.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context.check_hostname",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context.check_hostname = False\ncontext.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context.verify_mode",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parsed_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "username",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "username = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "password",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "password = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "req",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "req = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "response = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_file",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)\n    if indicated_url.path.startswith(\"/\"):\n        # An absolute path within the index's domain.\n        path = parser.sources[package_filename]\n    else:\n        # A relative path.",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "indicated_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "indicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)\n    if indicated_url.path.startswith(\"/\"):\n        # An absolute path within the index's domain.\n        path = parser.sources[package_filename]\n    else:\n        # A relative path.\n        path = parsed_url.path + \"/\" + parser.sources[package_filename]\n    package_url = urlunparse(",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parsed_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parsed_url = urlparse(package_url)\nreal_package_url = urlunparse(\n    (\n        parsed_url.scheme,\n        parsed_url.netloc,\n        normpath(parsed_url.path),\n        parsed_url.params,\n        parsed_url.query,\n        parsed_url.fragment,\n    )",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "real_package_url",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "real_package_url = urlunparse(\n    (\n        parsed_url.scheme,\n        parsed_url.netloc,\n        normpath(parsed_url.path),\n        parsed_url.params,\n        parsed_url.query,\n        parsed_url.fragment,\n    )\n)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "req",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "req = urllib.request.Request(real_package_url)\nif username and password:\n    req.add_unredirected_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nwith response as r:\n    shutil.copyfileobj(r, package_file)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "response = urllib.request.urlopen(req, context=context)\nwith response as r:\n    shutil.copyfileobj(r, package_file)",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "EXT_FILE",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.generate",
        "description": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.generate",
        "peekOfCode": "EXT_FILE = \"extensions.json\"\nif __name__ == \"__main__\":\n    with open(EXT_FILE, \"w\") as f:\n        ext = set(ext.lstrip(\".\") for ext in SUPPORTED_EXTENSIONS)\n        ext.add(\"egg\")\n        f.write(json.dumps(sorted(ext), indent=2) + \"\\n\")",
        "detail": ".direnv.flake-inputs.papjgkg8lwdad6qrqys31hx2rq87vd1y-source.generate",
        "documentation": {}
    },
    {
        "label": "SCRIPT_DIR",
        "kind": 5,
        "importPath": ".direnv.flake-inputs.yn8an2j019983fh3fcvvx8skmmmd32rj-source.quickstart",
        "description": ".direnv.flake-inputs.yn8an2j019983fh3fcvvx8skmmmd32rj-source.quickstart",
        "peekOfCode": "SCRIPT_DIR = dirname(abspath(__file__))\nif __name__ == \"__main__\":\n    workflow_dir = path_join(SCRIPT_DIR, \".github/workflows\")\n    files = sorted([\n        path_join(workflow_dir, f)\n        for f in os.listdir(workflow_dir)\n        if f.endswith(\".yml\") and f != \"dependabot.yml\"\n    ])\n    print(\n        dedent(",
        "detail": ".direnv.flake-inputs.yn8an2j019983fh3fcvvx8skmmmd32rj-source.quickstart",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "hooks.pyproject-without-special-deps",
        "description": "hooks.pyproject-without-special-deps",
        "peekOfCode": "def main(input, output, fields_to_remove):\n    data = tomlkit.loads(input.read())\n    try:\n        deps = data[\"tool\"][\"poetry\"][\"dependencies\"]\n    except KeyError:\n        pass\n    else:\n        for dep in deps.values():\n            if isinstance(dep, dict):\n                any_removed = False",
        "detail": "hooks.pyproject-without-special-deps",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "hooks.pyproject-without-url-whl",
        "description": "hooks.pyproject-without-url-whl",
        "peekOfCode": "def main(input, output):\n    data = tomlkit.loads(input.read())\n    try:\n        deps = data[\"tool\"][\"poetry\"][\"dependencies\"]\n    except KeyError:\n        pass\n    else:\n        for dep in deps.values():\n            if isinstance(dep, dict):\n                url = dep.get(\"url\", None)",
        "detail": "hooks.pyproject-without-url-whl",
        "documentation": {}
    },
    {
        "label": "Rewriter",
        "kind": 6,
        "importPath": "hooks.python-requires-patch-hook",
        "description": "hooks.python-requires-patch-hook",
        "peekOfCode": "class Rewriter(ast.NodeVisitor):\n    def __init__(self, *args, **kwargs):\n        super(Rewriter, self).__init__(*args, **kwargs)\n        self.modified = False\n    def visit_Call(self, node):\n        function_name = \"\"\n        if isinstance(node.func, ast.Name):\n            function_name = node.func.id\n        elif isinstance(node.func, ast.Attribute):\n            function_name = node.func.attr",
        "detail": "hooks.python-requires-patch-hook",
        "documentation": {}
    },
    {
        "label": "astunparse",
        "kind": 2,
        "importPath": "hooks.python-requires-patch-hook",
        "description": "hooks.python-requires-patch-hook",
        "peekOfCode": "def astunparse(tree):\n    # Use bundled unparse by default\n    if hasattr(ast, \"unparse\"):\n        return ast.unparse(tree)\n    # Use example tool from Python sources for older interpreter versions\n    from poetry2nix_astunparse import Unparser\n    buf = io.StringIO()\n    up = Unparser(tree, buf)\n    return buf.getvalue()\nclass Rewriter(ast.NodeVisitor):",
        "detail": "hooks.python-requires-patch-hook",
        "documentation": {}
    },
    {
        "label": "LibTransformer",
        "kind": 6,
        "importPath": "overrides.shapely-rewrite",
        "description": "overrides.shapely-rewrite",
        "peekOfCode": "class LibTransformer(ast.NodeTransformer):\n    _lgeos_replaced = False\n    def visit_If(self, node):\n        if ast.unparse(node).startswith(\"if sys.platform.startswith('linux')\"):\n            return ast.parse(\n                dedent(\n                    \"\"\"\n            free = CDLL(%s).free\n            free.argtypes = [c_void_p]\n            free.restype = None",
        "detail": "overrides.shapely-rewrite",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 2,
        "importPath": "tests.dependency-environment.trivial",
        "description": "tests.dependency-environment.trivial",
        "peekOfCode": "def app(environ, start_response):\n    \"\"\"Simplest possible application object\"\"\"\n    data = b\"Hello, World!\\n\"\n    status = \"200 OK\"\n    response_headers = [\n        (\"Content-type\", \"text/plain\"),\n        (\"Content-Length\", str(len(data))),\n    ]\n    start_response(status, response_headers)\n    return iter([data])",
        "detail": "tests.dependency-environment.trivial",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": "tests.test-extras.test_extras.test_simple",
        "description": "tests.test-extras.test_extras.test_simple",
        "peekOfCode": "def test_simple():\n    import black  # noqa: F401",
        "detail": "tests.test-extras.test_extras.test_simple",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": "tests.test-group.test_group.test_simple",
        "description": "tests.test-group.test_group.test_simple",
        "peekOfCode": "def test_simple():\n    assert True",
        "detail": "tests.test-group.test_group.test_simple",
        "documentation": {}
    },
    {
        "label": "test_simple",
        "kind": 2,
        "importPath": "tests.test-no-extras.test_no_extras.test_simple",
        "description": "tests.test-no-extras.test_no_extras.test_simple",
        "peekOfCode": "def test_simple():\n    with pytest.raises(ImportError):\n        import black  # noqa: F401",
        "detail": "tests.test-no-extras.test_no_extras.test_simple",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tests.use-url-src.use_url_src.main",
        "description": "tests.use-url-src.use_url_src.main",
        "peekOfCode": "def main():\n    pass",
        "detail": "tests.use-url-src.use_url_src.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tests.use-url-wheel.whl_test.main",
        "description": "tests.use-url-wheel.whl_test.main",
        "peekOfCode": "def main():\n    nlp = de_core_news_sm.load()\n    print(nlp(\"Dies ist ein Testsatz.\"))",
        "detail": "tests.use-url-wheel.whl_test.main",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def normalize(name):\n    return re.sub(r\"[-_.]+\", \"-\", name).lower()\ndef find_known_systems() -> Dict[str, str]:\n    \"\"\"Create a map from attribute to drvPath for known build systems\"\"\"\n    expr = \"\"\"let\n      pkgs = import <nixpkgs> { };\n      py = pkgs.python3.pkgs;\n      attrs = [ %s ];\n    in builtins.foldl' (\n      acc: attr: acc // {",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "find_known_systems",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def find_known_systems() -> Dict[str, str]:\n    \"\"\"Create a map from attribute to drvPath for known build systems\"\"\"\n    expr = \"\"\"let\n      pkgs = import <nixpkgs> { };\n      py = pkgs.python3.pkgs;\n      attrs = [ %s ];\n    in builtins.foldl' (\n      acc: attr: acc // {\n        ${attr} = py.${attr}.drvPath;\n      }",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "yield_drvs",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def yield_drvs():\n    \"\"\"Yield all drvs from the python3 set\"\"\"\n    with tempfile.NamedTemporaryFile(mode=\"w\") as f:\n        f.write(\n            \"\"\"\n          let\n            pkgs = import <nixpkgs> { };\n            pythonPackages = pkgs.python3.pkgs;\n          in builtins.removeAttrs pythonPackages [\n            \"pkgs\"",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "get_build_systems",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def get_build_systems(known_systems) -> Dict[str, List[str]]:\n    def check_drv(drv_path) -> List[str]:\n        systems: List[str] = []\n        with open(drv_path) as f:\n            drv = pynixutil.drvparse(f.read())\n        input_drvs: Set[str] = set(drv.input_drvs.keys())\n        for attr, build_system in known_systems.items():\n            if build_system in input_drvs:\n                systems.append(attr)\n        return systems",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "merge_systems",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def merge_systems(s):\n    simple = {i for i in s if isinstance(i, str)}\n    complex = [i for i in s if isinstance(i, dict)]\n    complex_names = {i[\"buildSystem\"] for i in complex}\n    new_simple = simple - complex_names\n    return complex + sorted(list(new_simple))\ndef merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):\n        attr = normalize(attr)",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "merge",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):\n        attr = normalize(attr)\n        s = content.setdefault(attr, [])\n        for system in systems:\n            s.append(system)\n    # Return with sorted data\n    return {\n        attr: merge_systems(content[attr])",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "def main():\n    outfile = sys.argv[1]\n    try:\n        with open(outfile) as f:\n            prev_content = json.load(f)\n    except FileNotFoundError:\n        prev_content = {}\n    known_systems = find_known_systems()\n    build_systems = get_build_systems(known_systems)\n    # Unlike nixpkgs we want overrides to be strictly additive by",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "SKIP_ATTRS",
        "kind": 5,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "SKIP_ATTRS = {\n    \"typing-extensions\",\n    \"argon2-cffi\",\n    \"packaging\",\n    \"poetry\",\n    \"flit-core\",\n    \"jsonschema\",\n    \"platformdirs\",\n    \"traitlets\",\n}",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "BLOCKLIST",
        "kind": 5,
        "importPath": "tools.find-build-systems",
        "description": "tools.find-build-systems",
        "peekOfCode": "BLOCKLIST = {\"poetry\", \"poetry-core\"}\ndef merge_systems(s):\n    simple = {i for i in s if isinstance(i, str)}\n    complex = [i for i in s if isinstance(i, dict)]\n    complex_names = {i[\"buildSystem\"] for i in complex}\n    new_simple = simple - complex_names\n    return complex + sorted(list(new_simple))\ndef merge(prev_content, new_content):\n    content = {}\n    for attr, systems in chain(prev_content.items(), new_content.items()):",
        "detail": "tools.find-build-systems",
        "documentation": {}
    },
    {
        "label": "Pep503",
        "kind": 6,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "class Pep503(HTMLParser):\n    def __init__(self) -> None:\n        super().__init__()\n        self.sources: dict[str, str] = {}\n        self.url: Optional[str] = None\n        self.name: Optional[str] = None\n    def handle_data(self, data: str) -> None:\n        if self.url is not None:\n            self.name = data\n    def handle_starttag(self, tag: str, attrs: list[tuple[str, Optional[str]]]) -> None:",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "url = sys.argv[1]\npackage_name = sys.argv[2]\nindex_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_name = sys.argv[2]\nindex_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index_url = url + \"/\" + package_name + \"/\"\npackage_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present\n    if \":\" in host:",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_filename",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_filename = sys.argv[3]\n# Parse username and password for this host from the netrc file if given.\nusername: Optional[str] = None\npassword: Optional[str] = None\nif os.environ[\"NETRC\"]:\n    netrc_obj = netrc.netrc(os.environ[\"NETRC\"])\n    host = urlparse(index_url).netloc\n    # Strip port number if present\n    if \":\" in host:\n        host = host.split(\":\")[0]",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context = ssl.create_default_context()\ncontext.check_hostname = False\ncontext.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context.check_hostname",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context.check_hostname = False\ncontext.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "context.verify_mode",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "context.verify_mode = ssl.CERT_NONE\n# Extract out username/password from index_url, if present.\nparsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parsed_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parsed_url = urlparse(index_url)\nusername = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "username",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "username = parsed_url.username or username\npassword = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "password",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "password = parsed_url.password or password\nindex_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index_url = parsed_url._replace(netloc=parsed_url.netloc.rpartition(\"@\")[-1]).geturl()\nreq = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "req",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "req = urllib.request.Request(index_url)\nif username and password:\n    import base64\n    password_b64 = base64.b64encode(\":\".join((username, password)).encode()).decode(\"utf-8\")\n    req.add_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "response = urllib.request.urlopen(req, context=context)\nindex = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "index = response.read()\nparser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parser = Pep503()\nparser.feed(str(index, \"utf-8\"))\nif package_filename not in parser.sources:\n    print(\"The file %s has not be found in the index %s\" % (package_filename, index_url))\n    exit(1)\npackage_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "package_file",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "package_file = open(package_filename, \"wb\")\n# Sometimes the href is a relative or absolute path within the index's domain.\nindicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)\n    if indicated_url.path.startswith(\"/\"):\n        # An absolute path within the index's domain.\n        path = parser.sources[package_filename]\n    else:\n        # A relative path.",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "indicated_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "indicated_url = urlparse(parser.sources[package_filename])\nif indicated_url.netloc == \"\":\n    parsed_url = urlparse(index_url)\n    if indicated_url.path.startswith(\"/\"):\n        # An absolute path within the index's domain.\n        path = parser.sources[package_filename]\n    else:\n        # A relative path.\n        path = parsed_url.path + \"/\" + parser.sources[package_filename]\n    package_url = urlunparse(",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "parsed_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "parsed_url = urlparse(package_url)\nreal_package_url = urlunparse(\n    (\n        parsed_url.scheme,\n        parsed_url.netloc,\n        normpath(parsed_url.path),\n        parsed_url.params,\n        parsed_url.query,\n        parsed_url.fragment,\n    )",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "real_package_url",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "real_package_url = urlunparse(\n    (\n        parsed_url.scheme,\n        parsed_url.netloc,\n        normpath(parsed_url.path),\n        parsed_url.params,\n        parsed_url.query,\n        parsed_url.fragment,\n    )\n)",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "req",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "req = urllib.request.Request(real_package_url)\nif username and password:\n    req.add_unredirected_header(\"Authorization\", \"Basic {}\".format(password_b64))\nresponse = urllib.request.urlopen(req, context=context)\nwith response as r:\n    shutil.copyfileobj(r, package_file)",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "description": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "peekOfCode": "response = urllib.request.urlopen(req, context=context)\nwith response as r:\n    shutil.copyfileobj(r, package_file)",
        "detail": "vendor.pyproject.nix.fetchers.fetch-from-legacy",
        "documentation": {}
    },
    {
        "label": "EXT_FILE",
        "kind": 5,
        "importPath": "generate",
        "description": "generate",
        "peekOfCode": "EXT_FILE = \"extensions.json\"\nif __name__ == \"__main__\":\n    with open(EXT_FILE, \"w\") as f:\n        ext = set(ext.lstrip(\".\") for ext in SUPPORTED_EXTENSIONS)\n        ext.add(\"egg\")\n        f.write(json.dumps(sorted(ext), indent=2) + \"\\n\")",
        "detail": "generate",
        "documentation": {}
    }
]